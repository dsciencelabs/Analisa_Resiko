# Simulation and Resampling

# 6.3 Cross Validation    

Dalam bagian ini, kita akan mempelajari caranya:

* Membandingkan dan membedakan validasi silang dengan teknik simulasi dan metode bootstrap.

*	Menggunakan teknik validasi silang untuk pemilihan model

*	Menjelaskan metode jackknife sebagai kasus khusus validasi silang dan menghitung estimasi bias dan kesalahan standar jackknife

Validasi silang, yang diperkenalkan secara singkat pada Bagian 4.2.4, adalah teknik yang didasarkan pada hasil simulasi. Sekarang kita akan membandingkan dan membedakan validasi silang dengan teknik simulasi lain yang telah diperkenalkan dalam bab ini."

*	Simulasi, atau Monte-Carlo, yang diperkenalkan pada Bagian 6.1, memungkinkan kita untuk menghitung nilai ekspektasi dan rangkuman distribusi statistik lainnya, seperti nilai-p, dengan mudah.

* Bootstrap, dan metode resampling lainnya yang diperkenalkan pada Bagian 6.2, menyediakan estimator presisi, atau variabilitas, statistik.

*	Validasi silang penting ketika menilai seberapa akurat model prediktif akan bekerja dalam praktiknya.

Tumpang tindih memang ada, namun tetap saja akan sangat membantu untuk memikirkan tujuan luas yang terkait dengan setiap metode statistik.
    
Untuk membahas validasi silang, mari kita ingat kembali dari Bagian 4.2 beberapa ide kunci dari validasi model. Ketika menilai, atau memvalidasi, sebuah model, kita melihat kinerja yang diukur pada data baru, atau setidaknya bukan data yang digunakan untuk mencocokkan model. Pendekatan klasik, yang dijelaskan di Bagian 4.2.3, adalah membagi sampel menjadi dua: satu bagian (dataset pelatihan) digunakan untuk menyesuaikan model dan bagian lainnya (dataset pengujian) digunakan untuk memvalidasi. Namun, keterbatasan dari pendekatan ini adalah bahwa hasilnya bergantung pada pembagian; meskipun keseluruhan sampel tetap, pembagian antara sub-sampel pelatihan dan pengujian bervariasi secara acak. Sampel pelatihan yang berbeda berarti parameter estimasi model akan berbeda. Parameter model yang berbeda dan sampel uji yang berbeda berarti statistik validasi akan berbeda. Dua orang analis dapat menggunakan data yang sama dan model yang sama, namun mencapai kesimpulan yang berbeda tentang kelayakan suatu model (berdasarkan pembagian acak yang berbeda), sebuah situasi yang membuat frustasi.

## 6.3.1 k-Fold Cross-Validation

Untuk mengurangi kesulitan ini, biasanya digunakan pendekatan validasi silang seperti yang diperkenalkan di Bagian 4.2.4. Ide utamanya adalah meniru pendekatan pengujian/pelatihan dasar untuk validasi model dengan mengulanginya berkali-kali melalui rata-rata dari beberapa bagian data yang berbeda. Keuntungan utamanya adalah bahwa statistik validasi tidak terikat pada model parametrik (atau nonparametrik) tertentu - seseorang dapat menggunakan statistik nonparametrik atau statistik yang memiliki interpretasi ekonomi - sehingga dapat digunakan untuk membandingkan model yang tidak bersarang (tidak seperti prosedur rasio kemungkinan).

**Contoh 6.3.1. Dana Properti Wisconsin.** Untuk data dana properti 2010 yang diperkenalkan pada Bagian 1.3, kami mencocokkan distribusi gamma dan Pareto dengan 1.377 data klaim. Untuk rincian kecocokan terkait, lihat Lampiran Bagian 15.4.4. Sekarang kita mempertimbangkan statistik Kolmogorov-Smirnov yang diperkenalkan di Bagian 4.1.2.2. Ketika seluruh dataset telah sesuai, statistik kecocokan Kolmogorov-Smirnov untuk distribusi gamma adalah 0,2639 dan untuk distribusi Pareto adalah 0,0478. Nilai yang lebih rendah untuk distribusi Pareto menunjukkan bahwa distribusi ini lebih cocok daripada gamma.

Untuk melihat bagaimana validasi silang k-lipatan bekerja, kami membagi data secara acak menjadi $k=8$ kelompok, atau lipatan, yang masing-masing memiliki sekitar $1377/8≈172$ pengamatan. Kemudian, kami mencocokkan model gamma dan Pareto pada set data dengan tujuh lipatan pertama (sekitar $172⋅7 = 120$4 pengamatan), menentukan estimasi parameter, dan kemudian menggunakan model-model yang cocok dengan data yang ditahan untuk menentukan statistik Kolmogorov-Smirnov.

```{r, warning=FALSE}
library(VGAM)
library(MASS)
claim_lev <- read.csv("data/CLAIMLEVEL.csv", header = TRUE) 
claim_data <- subset(claim_lev, Year == 2010); 

# Randomly re-order the data - "shuffle it"
n <- nrow(claim_data)
set.seed(12347)
cvdata <- claim_data[sample(n), ]
# Number of folds
k <- 8
cvalvec <- matrix(0,2,k)
for (i in 1:k) {
  indices <- (((i-1) * round((1/k)*nrow(cvdata))) + 1):((i*round((1/k) * nrow(cvdata))))
# Pareto
  fit.pareto <- vglm(Claim ~ 1, paretoII, loc = 0, data = cvdata[-indices,])
  ksResultPareto <- ks.test(cvdata[indices,]$Claim, "pparetoII", loc = 0, shape = exp(coef(fit.pareto)[2]), 
        scale = exp(coef(fit.pareto)[1]))
  cvalvec[1,i] <- ksResultPareto$statistic
# Gamma
  fit.gamma <- glm(Claim ~ 1, data = cvdata[-indices,], family = Gamma(link = log)) 
  gamma_theta <- exp(coef(fit.gamma)) * gamma.dispersion(fit.gamma)  
  alpha <- 1 / gamma.dispersion(fit.gamma)
  ksResultGamma <- ks.test(cvdata[indices,]$Claim, "pgamma", shape = alpha, scale = gamma_theta)
  cvalvec[2,i] <- ksResultGamma$statistic
}
KScv <- rowSums(cvalvec)/k
```

Hasilnya tampak pada Gambar 6.12 di mana sumbu horizontal adalah Fold=1. Proses ini diulangi untuk tujuh lipatan lainnya. Hasil yang dirangkum dalam Gambar 6.12 menunjukkan bahwa Pareto secara konsisten memberikan distribusi prediktif yang lebih dapat diandalkan daripada gamma.

```{r}
# Plot the statistics
matplot(1:k,t(cvalvec),type="b", col=c(1,3), lty=1:2, 
        ylim=c(0,0.4), pch = 0, xlab="Fold", ylab="KS Statistic")
legend("left", c("Pareto", "Gamma"), col=c(1,3),lty=1:2, bty="n")
```
<p class="caption">
  "Figure 6.2: "
<strong> 
  Statistik Kolmogorov-Smirnov (KS) yang telah divalidasi silang untuk Data Klaim Dana Asuransi. 
</strong>
  Garis hitam solid untuk distribusi Pareto, garis putus-putus hijau untuk distribusi gamma. Statistik KS mengukur deviasi terbesar antara distribusi yang sesuai dengan distribusi empiris untuk masing-masing dari 8 kelompok, atau lipatan, data yang dipilih secara acak. 
</p>

## 6.3.2 Leave-One-Out Cross-Validation


Kasus khusus di mana $k=n$ dikenal sebagai validasi silang tinggalkan-satu-keluar. Kasus ini secara historis sangat menonjol dan terkait erat dengan jackknifestatistik yang merupakan pendahulu dari teknik bootstrap.

Meskipun kita menyajikannya sebagai kasus khusus validasi silang, akan sangat membantu jika kami memberikan definisi eksplisit. Pertimbangkan sebuah statistik umum $θˆ = t(x)$ yang merupakan penaksir untuk sebuah parameter yang diminati $θ$. Ide dari jackknife adalah menghitung n nilai $θˆ_{-i} = t(x-i)$, di mana $x-i$ adalah subsampel dari $x$ dengan nilai $ke-i$ dihilangkan. Rata-rata dari nilai-nilai ini dilambangkan sebagai

$$\overline{\widehat{\theta}}_{(\cdot)}=\frac{1}{n}\sum_{i=1}^n \widehat{\theta}_{-i} .$$

Nilai-nilai ini dapat digunakan untuk membuat estimasi bias dari statistik $\hatθ$

$$\begin{equation}
Bias_{jack} = (n-1) \left(\overline{\widehat{\theta}}_{(\cdot)} - \widehat{\theta}\right)
\tag{6.3}
\end{equation}$$

serta estimasi standar deviasi

$$\begin{equation}
s_{jack} =\sqrt{\frac{n-1}{n}\sum_{i=1}^n \left(\widehat{\theta}_{-i} -\overline{\widehat{\theta}}_{(\cdot)}\right)^2} ~.
\tag{6.4}
\end{equation}$$

**Contoh 6.3.2. Koefisien Variasi.** Sebagai ilustrasi, pertimbangkan sebuah sampel fiktif kecil $x = {x_1,...,x_n}$ dengan realisasi

```{r}
sample_x <- c(2.46,2.80,3.28,3.86,2.85,3.67,3.37,3.40,
              5.22,2.55,2.79,4.50,3.37,2.88,1.44,2.56,2.00,2.07,2.19,1.77)
```

Misalkan kita tertarik dengan $\theta = CV = \sqrt{\mathrm{Var~}[X]}/\mathrm{E~}[X]$

Dengan dataset ini, estimator koefisien variasi menjadi 0,31196. Namun, seberapa handalkah estimasi tersebut? Untuk menjawab pertanyaan ini, kita dapat menghitung estimator pisau lipat dari bias dan deviasi standarnya. Kode berikut ini menunjukkan bahwa penaksir jackknife untuk bias adalah $Bias_{jack} = -0,00627$ dan standar deviasi jackknife adalah $s_{jack} = 0,01293$.

```{r}
CVar <- function(x) sqrt(var(x))/mean(x)
JackCVar <- function(i) sqrt(var(sample_x[-i]))/mean(sample_x[-i])
JackTheta <- Vectorize(JackCVar)(1:length(sample_x))
BiasJack <- (length(sample_x)-1)*(mean(JackTheta) - CVar(sample_x))
sd(JackTheta)
```

**Contoh 6.3.3. Klaim Cidera Badan dan Rasio Eliminasi Kerugian.** Pada Contoh 6.2.1, kita telah menunjukkan bagaimana menghitung estimasi bootstrap dari bias dan deviasi standar untuk rasio eliminasi kerugian dengan menggunakan data klaim cedera badan pada Contoh 4.1.11. Sekarang kita menindaklanjuti dengan memberikan jumlah yang sebanding dengan menggunakan statistik jackknife.

Tabel 6.7 merangkum hasil estimasi jackknife. Tabel ini menunjukkan bahwa estimasi jackknife terhadap bias dan deviasi standar dari rasio eliminasi kerugian $E [min (X, d)]/E [X]$ sebagian besar konsisten dengan metodologi bootstrap. Selain itu, kita dapat menggunakan standar deviasi untuk membangun interval kepercayaan berbasis normal, yang berpusat di sekitar penaksir yang dikoreksi bias. Sebagai contoh, pada $d = 14000$, kita melihat pada Contoh 4.1.11 bahwa estimasi nonparametrik dari $LER$ adalah 0.97678. Estimasi ini memiliki bias sebesar 0,00010, sehingga menghasilkan estimator terkoreksi-bias sebesar 0,97688. Interval kepercayaan 95% dihasilkan dengan membuat interval dua kali panjang 1,96 deviasi standar jackknife, yang berpusat pada estimator terkoreksi bias (1,96 adalah perkiraan kuantil ke-97,5 dari distribusi normal standar).

```{r, warning=FALSE}
library(boot)
# Example from Derrig et al
BIData <- read.csv("data/DerrigResampling.csv", header =T)
BIData$Censored <- 1*(BIData$AmountPaid >= BIData$PolicyLimit)
BIDataUncensored <- subset(BIData, Censored == 0)
LER.boot <- function(ded, data, indices){
  resample.data <- data[indices,]
  sumClaims <- sum(resample.data$AmountPaid)
  sumClaims_d <- sum(pmin(resample.data$AmountPaid,ded))
  LER <-   sumClaims_d/sumClaims
  return(LER)  
}

x <- BIDataUncensored$AmountPaid
LER.jack<- function(ded,i){
  LER <-   sum(pmin(x[-i],ded))/sum(x[-i])
  return(LER)  
}
LER <- function(ded) sum(pmin(x,ded))/sum(x)
##Derrig et al
set.seed(2019)
dVec2 <- c(4000, 5000, 10500, 11500, 14000, 18500)
OutJack <- matrix(0,length(dVec2),8)
  for (j in 1:length(dVec2)) {
OutJack[j,1] <- dVec2[j]
results <- boot(data=BIDataUncensored, statistic=LER.boot, R=1000, ded=dVec2[j])
OutJack[j,2] <- results$t0
biasboot <- mean(results$t)-results$t0 -> OutJack[j,3]
sdboot <- sd(results$t) -> OutJack[j,4]
temp <- boot.ci(results)

LER.jack.ded<- function(i) LER.jack(ded=dVec2[j],i)
JackTheta.ded <- Vectorize(LER.jack.ded)(1:length(x))
OutJack[j,5] <- BiasJack.ded <- (length(x)-1)*(mean(JackTheta.ded) - LER(ded=dVec2[j]))
OutJack[j,6] <- sd(JackTheta.ded)
OutJack[j,7:8] <- mean(JackTheta.ded)+qt(c(0.025,0.975),length(x)-1)*OutJack[j,6]
  }
```

[Table 6.7]:\#tab:67

<a id=tab:67></a>

Table 6.7. **Estimasi Jackknife dari LER pada Deductible yang Dipilih**

```{r comment="", echo=FALSE,message=FALSE}
library(magrittr)
library(dplyr)
library(kableExtra)
OutJack.latex <- OutJack
colnames(OutJack) <- c("d","NP Estimate","Bootstrap Bias", "Bootstrap SD", 
                       "Jackknife Bias", "Jackknife SD","Lower Jackknife 95% CI", "Upper Jackknife 95% CI")
if (knitr::is_html_output()) {knitr::kable(OutJack, "html",digits=5) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"),
          font_size = 10)
}
if (knitr::is_latex_output()) {knitr::kable(OutJack.latex, "latex", booktabs = T, digits=5) %>%
  kable_styling(latex_options="scale_down") %>%
    add_header_above(c("","Estimate","Bias", "SD", 
                       "Bias", "SD","95% CI", "95% CI")) %>%
      add_header_above(c("d","NP","Bootstrap", "Bootstrap", 
                       "Jackknife", "Jackknife","Lower Jackknife", "Upper Jackknife"))
}
```

Diskusi. Salah satu dari banyak hal menarik tentang kasus khusus leave-one-out adalah kemampuan untuk mereplikasi estimasi dengan tepat. Artinya, ketika ukuran lipatan hanya satu, maka tidak ada ketidakpastian tambahan yang disebabkan oleh validasi silang. Ini berarti bahwa para analis dapat mereplikasi pekerjaan satu sama lain dengan tepat, sebuah pertimbangan yang penting.

Statistik Jackknife dikembangkan untuk memahami ketepatan estimator, menghasilkan estimator bias dan deviasi standar pada persamaan (6.3) dan (6.4). Hal ini sesuai dengan tujuan yang telah kita kaitkan dengan teknik bootstrap, bukan metode validasi silang. Hal ini menunjukkan bagaimana teknik statistik dapat digunakan untuk mencapai tujuan yang berbeda.

## 6.3.3 Cross-Validation and Bootstrap

Bootstrap berguna untuk memberikan estimator presisi, atau variabilitas, dari statistik. Hal ini juga berguna untuk validasi model. Pendekatan bootstrap untuk validasi model mirip dengan prosedur validasi leave-one-out dan *k*-fold:

* Buat sampel bootstrap dengan mengambil sampel ulang (dengan penggantian) $n$ indeks dalam ${1, ⋯, n}$. Ini akan menjadi sampel pelatihan kita. Perkirakan model yang sedang dipertimbangkan berdasarkan sampel ini.

* *Uji*, atau *sampel validasi*, terdiri dari pengamatan yang tidak dipilih untuk pelatihan. Mengevaluasi model yang cocok (berdasarkan data pelatihan) dengan menggunakan data uji.

Ulangi proses ini beberapa kali (katakanlah $B$). Ambil rata-rata dari hasil-hasilnya dan pilih model berdasarkan statistik evaluasi rata-rata.

**Contoh 6.3.4. Dana Properti Wisconsin**. Kembali ke Contoh 6.3.1 di mana kita menyelidiki kecocokan distribusi gamma dan Pareto pada data dana properti. Kita kembali membandingkan kinerja prediksi menggunakan statistik Kolmogorov-Smirnov (KS), namun kali ini menggunakan prosedur bootstrap untuk membagi data antara sampel pelatihan dan pengujian. Berikut ini adalah kode ilustrasinya.

```{r, warning=FALSE}
library(goftest)
n <- nrow(claim_data)
set.seed(12347)
indices <- 1:n
# Number of Bootstrap Samples
B <- 100
cvalvec <- matrix(0,2,B)
for (i in 1:B) {
  bootindex <- unique(sample(indices, size=n, replace= TRUE))
  traindata <- claim_data[bootindex,]
  testdata  <- claim_data[-bootindex,]
# Pareto
  fit.pareto <- vglm(Claim ~ 1, paretoII, loc = 0, data = traindata)
  ksResultPareto <- ks.test(testdata$Claim, "pparetoII", loc = 0, shape = exp(coef(fit.pareto)[2]), 
        scale = exp(coef(fit.pareto)[1]))
  cvalvec[1,i] <- ksResultPareto$statistic
# Gamma
  fit.gamma <- glm(Claim ~ 1, data = traindata, family = Gamma(link = log)) 
  gamma_theta <- exp(coef(fit.gamma)) * gamma.dispersion(fit.gamma)  
  alpha <- 1 / gamma.dispersion(fit.gamma)
  ksResultGamma <- ks.test(testdata$Claim, "pgamma", shape = alpha, scale = gamma_theta)
  cvalvec[2,i] <- ksResultGamma$statistic
}
KSBoot <- rowSums(cvalvec)/B
```

Kami melakukan pengambilan sampel dengan menggunakan B= 100 ulangan. Statistik KS rata-rata untuk distribusi Pareto adalah 0,058 dibandingkan dengan rata-rata untuk distribusi gamma, 0,262. Hal ini konsisten dengan hasil sebelumnya dan memberikan bukti lain bahwa Pareto adalah model yang lebih baik untuk data ini dibandingkan dengan gamma.

# 6.4 Importance Sampling

Bagian 6.1 memperkenalkan teknik Monte Carlo dengan menggunakan teknik inversi: untuk membangkitkan sebuah variabel acak $X$ dengan distribusi $F$, terapkan $F^{-1}$ pada pemanggilan sebuah generator acak (seragam pada interval satuan). Bagaimana jika kita ingin menggambar sesuai dengan $X$, dengan syarat $X∈[a,b]$?

Seseorang dapat menggunakan mekanisme terima-tolak: menarik $x$ dari distribusi $F$

* jika $x\in[a,b]$: simpan ("terima")

* jika $x\notin[a,b]$: gambar yang lain ("tolak")

Amati bahwa dari n nilai yang awalnya dihasilkan, kita simpan di sini hanya $[F(b)-F(a)] ⋅ n$ hasil imbang, rata-rata.

**Contoh 6.4.1. Penarikan dari Distribusi Normal.** Misalkan kita menggambar dari distribusi normal dengan rata-rata 2,5 dan varians 1, $N(2,5,1)$, tetapi hanya tertarik pada gambar yang lebih besar dari $a≥2$ dan kurang dari $b≤4$. Artinya, kita hanya dapat menggunakan $F(4)-F(2)=Φ(4-2.5)-Φ(2-2.5) = 0.9332 - 0.3085 = 0.6247$ proporsi undian. Gambar 6.13 menunjukkan bahwa beberapa hasil undian berada di dalam interval $(2,4)$ dan beberapa di luarnya.

```{r}
mu = 2.5
sigma = 1
a = 2
b = 4
Fa = pnorm(a,mu,sigma)
Fb = pnorm(b,mu,sigma)
pic_ani = function(){
  u=seq(0,5,by=.01)
  plot(u,pnorm(u,mu,sigma),col="white",ylab="",xlab="")
  rect(-1,-1,6,2,col=rgb(1,0,0,.2),border=NA)
  rect(a,Fa,b,Fb,col="white",border=NA)
  lines(u,pnorm(u,mu,sigma),lwd=2)
  abline(v=c(a,b),lty=2,col="red")
  ru <- runif(1)
  clr <- "red"
  if((qnorm(ru,mu,sigma)>=a)&(qnorm(ru,mu,sigma)<=b)) clr <- "blue"
  segments(-1,ru,qnorm(ru,mu,sigma),ru,col=clr,lwd=2)
  arrows(qnorm(ru,mu,sigma),ru,qnorm(ru,mu,sigma),0,col=clr,lwd=2,length = .1)
}
```

```{r, eval = FALSE}
for (i in 1:numAnimation) {pic_ani()}
```

<br>

<img src="images/sampleani1-.gif" alt="" width="400" height="300" align="middle">

Sebagai gantinya, seseorang dapat menggambar menurut distribusi bersyarat $F^⋆$ yang didefinisikan sebagai

$$F^{\star}(x) = \Pr(X \le x | a < X \le b) =\frac{F(x)-F(a)}{F(b)-F(a)}, \ \  \ \text{for } a < x \le b .$$
Dengan menggunakan metode inverse transform pada Bagian 6.1.2, kita mendapatkan hasil imbang

$$X^\star=F^{\star-1}\left( U \right) = F^{-1}\left(F(a)+U\cdot[F(b)-F(a)]\right)$$

memiliki distribusi $F⋆^$. Dinyatakan dengan cara lain, definisikan

$$\tilde{U} = (1-U)\cdot F(a)+U\cdot F(b)$$

dan kemudian gunakan $F^{-1}(\tilde{U})$. Dengan pendekatan ini, setiap undian dihitung.

Hal ini dapat dikaitkan dengan mekanisme pengambilan sampel kepentingan: kita menarik lebih sering di wilayah yang kita harapkan memiliki kuantitas yang memiliki kepentingan. Transformasi ini dapat dianggap sebagai "perubahan ukuran."

```{r}
pic_ani = function(){
  u=seq(0,5,by=.01)
  plot(u,pnorm(u,mu,sigma),col="white",ylab="",xlab="")
  rect(-1,-1,6,2,col=rgb(1,0,0,.2),border=NA)
  rect(a,Fa,b,Fb,col="white",border=NA)
  lines(u,pnorm(u,mu,sigma),lwd=2)
  abline(h=pnorm(c(a,b),mu,sigma),lty=2,col="red")
  ru <- runif(1)
  rutilde <- (1-ru)*Fa+ru*Fb
  segments(-1,rutilde,qnorm(rutilde,mu,sigma),rutilde,col="blue",lwd=2)
  arrows(qnorm(rutilde,mu,sigma),rutilde,qnorm(rutilde,mu,sigma),0,col="blue",lwd=2,length = .1)
}
```

```{r, eval = FALSE}
for (i in 1:numAnimation) {pic_ani()}
```

<br>

<img src="images/sampleani_IS_2-.gif" alt="" width="400" height="300" align="middle">

Pada Contoh 6.4.1., kebalikan dari distribusi normal sudah tersedia (dalam `R`, fungsinya adalah `qnorm`). Namun, untuk aplikasi lain, hal ini tidak terjadi. Kemudian, kita cukup menggunakan metode numerik untuk menentukan $X^⋆$ sebagai solusi dari persamaan $F(X^\star) =\tilde{U}$ di mana $\tilde{U}=(1-U)\cdot F(a)+U\cdot F(b)$). Lihat kode ilustrasi berikut ini.

```{r}
pic_ani = function(){
  u=seq(0,5,by=.01)
  plot(u,pnorm(u,mu,sigma),col="white",ylab="",xlab="")
  rect(-1,-1,6,2,col=rgb(1,0,0,.2),border=NA)
  rect(2,-1,4,2,col="white",border=NA)
  lines(u,pnorm(u,mu,sigma),lty=2)
  pnormstar <- Vectorize(function(x){
    y=(pnorm(x,mu,sigma)-Fa)/(Fb-Fa)
    if(x<=a) y <- 0
    if(x>=b) y <- 1
    return(y)
    })
  qnormstar <- function(u) as.numeric(uniroot((function (x) pnormstar(x) - u), lower = 2, upper = 4)[1])
  lines(u,pnormstar(u),lwd=2)
  abline(v=c(2,4),lty=2,col="red")
  ru <- runif(1)
  segments(-1,ru,qnormstar(ru),ru,col="blue",lwd=2)
  arrows(qnormstar(ru),ru,qnormstar(ru),0,col="blue",lwd=2,length = .1)
}
```

```{r, eval = FALSE}
for (i in 1:numAnimation) {pic_ani()}
```
<br>
<img src="images/sampleani_IS_1-.gif" alt="" width="400" height="300" align="middle">