<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Bab 4 Model Selection and Estimation | Analisis Resiko</title>
  <meta name="description" content="Loss Data Analytics adalah teks yang interaktif, online, tersedia secara bebas. - Versi online akan berisi banyak objek interaktif (kuis, demonstrasi komputer, grafik interaktif, video, dan sejenisnya) untuk mempromosikan pembelajaran yang lebih dalam. - Sebagian dari buku ini akan tersedia dalam format pdf untuk pencetakan dengan biaya rendah. - Teks online akan tersedia dalam berbagai bahasa untuk mempromosikan akses ke audiens di seluruh dunia." />
  <meta name="generator" content="bookdown 0.33 and GitBook 2.6.7" />

  <meta property="og:title" content="Bab 4 Model Selection and Estimation | Analisis Resiko" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="Loss Data Analytics adalah teks yang interaktif, online, tersedia secara bebas. - Versi online akan berisi banyak objek interaktif (kuis, demonstrasi komputer, grafik interaktif, video, dan sejenisnya) untuk mempromosikan pembelajaran yang lebih dalam. - Sebagian dari buku ini akan tersedia dalam format pdf untuk pencetakan dengan biaya rendah. - Teks online akan tersedia dalam berbagai bahasa untuk mempromosikan akses ke audiens di seluruh dunia." />
  <meta name="github-repo" content="dsciencelabs/Bookdown-Tempalate_R" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Bab 4 Model Selection and Estimation | Analisis Resiko" />
  
  <meta name="twitter:description" content="Loss Data Analytics adalah teks yang interaktif, online, tersedia secara bebas. - Versi online akan berisi banyak objek interaktif (kuis, demonstrasi komputer, grafik interaktif, video, dan sejenisnya) untuk mempromosikan pembelajaran yang lebih dalam. - Sebagian dari buku ini akan tersedia dalam format pdf untuk pencetakan dengan biaya rendah. - Teks online akan tersedia dalam berbagai bahasa untuk mempromosikan akses ke audiens di seluruh dunia." />
  

<meta name="author" content="Bakti Siregar, M.Sc" />


<meta name="date" content="2023-06-13" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="modeling-loss-severity.html"/>
<link rel="next" href="aggregate-loss-models.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />
<link href="libs/bsTable-3.3.7/bootstrapTable.min.css" rel="stylesheet" />
<script src="libs/bsTable-3.3.7/bootstrapTable.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><center><img src="images/Logo.png" alt="logo" width="50%" height="50%"style="margin: 15px 0 0 0"></center></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="kata-pengantar.html"><a href="kata-pengantar.html"><i class="fa fa-check"></i>Kata Pengantar</a>
<ul>
<li class="chapter" data-level="" data-path="kata-pengantar.html"><a href="kata-pengantar.html#deskripsi-buku"><i class="fa fa-check"></i>Deskripsi Buku</a>
<ul>
<li class="chapter" data-level="" data-path="kata-pengantar.html"><a href="kata-pengantar.html#petunjuk-penggunaan"><i class="fa fa-check"></i>Petunjuk Penggunaan</a></li>
<li class="chapter" data-level="" data-path="kata-pengantar.html"><a href="kata-pengantar.html#manfaat"><i class="fa fa-check"></i>Manfaat</a></li>
<li class="chapter" data-level="" data-path="kata-pengantar.html"><a href="kata-pengantar.html#mengapa-analisa-resiko"><i class="fa fa-check"></i>Mengapa Analisa Resiko?</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="kata-pengantar.html"><a href="kata-pengantar.html#ucapan-terima-kasih"><i class="fa fa-check"></i>Ucapan Terima Kasih</a></li>
<li class="chapter" data-level="" data-path="kata-pengantar.html"><a href="kata-pengantar.html#kontributor"><i class="fa fa-check"></i>Kontributor</a></li>
<li class="chapter" data-level="" data-path="kata-pengantar.html"><a href="kata-pengantar.html#kritik-saran"><i class="fa fa-check"></i>Kritik &amp; Saran</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="pengantar-analitika-data-kerugian.html"><a href="pengantar-analitika-data-kerugian.html"><i class="fa fa-check"></i><b>1</b> Pengantar Analitika Data Kerugian</a>
<ul>
<li class="chapter" data-level="1.1" data-path="pengantar-analitika-data-kerugian.html"><a href="pengantar-analitika-data-kerugian.html#relevansi-analitika-dalam-aktivitas-asuransi"><i class="fa fa-check"></i><b>1.1</b> Relevansi Analitika dalam Aktivitas Asuransi</a>
<ul>
<li class="chapter" data-level="1.1.1" data-path="pengantar-analitika-data-kerugian.html"><a href="pengantar-analitika-data-kerugian.html#sifat-dan-relevansi-asuransi"><i class="fa fa-check"></i><b>1.1.1</b> Sifat dan Relevansi Asuransi</a></li>
<li class="chapter" data-level="1.1.2" data-path="pengantar-analitika-data-kerugian.html"><a href="pengantar-analitika-data-kerugian.html#apa-itu-analitika"><i class="fa fa-check"></i><b>1.1.2</b> Apa itu Analitika?</a></li>
<li class="chapter" data-level="1.1.3" data-path="pengantar-analitika-data-kerugian.html"><a href="pengantar-analitika-data-kerugian.html#proses-asuransi"><i class="fa fa-check"></i><b>1.1.3</b> Proses Asuransi</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="pengantar-analitika-data-kerugian.html"><a href="pengantar-analitika-data-kerugian.html#operasi-perusahaan-asuransi"><i class="fa fa-check"></i><b>1.2</b> Operasi Perusahaan Asuransi</a>
<ul>
<li class="chapter" data-level="1.2.1" data-path="pengantar-analitika-data-kerugian.html"><a href="pengantar-analitika-data-kerugian.html#memulai-asuransi"><i class="fa fa-check"></i><b>1.2.1</b> Memulai Asuransi</a></li>
<li class="chapter" data-level="1.2.2" data-path="pengantar-analitika-data-kerugian.html"><a href="pengantar-analitika-data-kerugian.html#memperbarui-asuransi"><i class="fa fa-check"></i><b>1.2.2</b> Memperbarui Asuransi</a></li>
<li class="chapter" data-level="1.2.3" data-path="pengantar-analitika-data-kerugian.html"><a href="pengantar-analitika-data-kerugian.html#pengelolaan-klaim-dan-produk"><i class="fa fa-check"></i><b>1.2.3</b> Pengelolaan Klaim dan Produk</a></li>
<li class="chapter" data-level="1.2.4" data-path="pengantar-analitika-data-kerugian.html"><a href="pengantar-analitika-data-kerugian.html#penyisihan-klaim"><i class="fa fa-check"></i><b>1.2.4</b> Penyisihan Klaim</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="frequency-modeling.html"><a href="frequency-modeling.html"><i class="fa fa-check"></i><b>2</b> Frequency Modeling</a>
<ul>
<li class="chapter" data-level="2.1" data-path="frequency-modeling.html"><a href="frequency-modeling.html#frequency-distributions"><i class="fa fa-check"></i><b>2.1</b> Frequency Distributions</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="frequency-modeling.html"><a href="frequency-modeling.html#bagaimana-frekuensi-menambah-infromasi-pada-tingkat-keparahan-suatu-kejadian"><i class="fa fa-check"></i><b>2.1.1</b> Bagaimana Frekuensi menambah infromasi pada tingkat keparahan suatu kejadian</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="frequency-modeling.html"><a href="frequency-modeling.html#basic-frequency-distributions"><i class="fa fa-check"></i><b>2.2</b> Basic Frequency Distributions</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="frequency-modeling.html"><a href="frequency-modeling.html#formula"><i class="fa fa-check"></i><b>2.2.1</b> Formula</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="frequency-modeling.html"><a href="frequency-modeling.html#the-ab0-class"><i class="fa fa-check"></i><b>2.3</b> The <span class="math inline">\((a,b,0)\)</span> Class</a></li>
<li class="chapter" data-level="2.4" data-path="frequency-modeling.html"><a href="frequency-modeling.html#mengestimasi-distibusi-frekuensi"><i class="fa fa-check"></i><b>2.4</b> Mengestimasi Distibusi Frekuensi</a>
<ul>
<li class="chapter" data-level="2.4.1" data-path="frequency-modeling.html"><a href="frequency-modeling.html#estimasi-parameter"><i class="fa fa-check"></i><b>2.4.1</b> Estimasi Parameter</a></li>
<li class="chapter" data-level="2.4.2" data-path="frequency-modeling.html"><a href="frequency-modeling.html#distribusi-frekuensi-mle"><i class="fa fa-check"></i><b>2.4.2</b> Distribusi Frekuensi MLE</a></li>
<li class="chapter" data-level="2.4.3" data-path="frequency-modeling.html"><a href="frequency-modeling.html#zero-truncation-or-modification"><i class="fa fa-check"></i><b>2.4.3</b> Zero Truncation or Modification</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="frequency-modeling.html"><a href="frequency-modeling.html#distribusi-campuran"><i class="fa fa-check"></i><b>2.5</b> Distribusi Campuran</a>
<ul>
<li class="chapter" data-level="2.5.1" data-path="frequency-modeling.html"><a href="frequency-modeling.html#contoh-soal-ujian-aktuaria"><i class="fa fa-check"></i><b>2.5.1</b> Contoh Soal Ujian Aktuaria</a></li>
</ul></li>
<li class="chapter" data-level="2.6" data-path="frequency-modeling.html"><a href="frequency-modeling.html#goodnes-of-fit"><i class="fa fa-check"></i><b>2.6</b> Goodnes of Fit</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="modeling-loss-severity.html"><a href="modeling-loss-severity.html"><i class="fa fa-check"></i><b>3</b> Modeling Loss Severity</a>
<ul>
<li class="chapter" data-level="3.1" data-path="modeling-loss-severity.html"><a href="modeling-loss-severity.html#basic-distributional-quantities"><i class="fa fa-check"></i><b>3.1</b> Basic Distributional Quantities</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="modeling-loss-severity.html"><a href="modeling-loss-severity.html#moments"><i class="fa fa-check"></i><b>3.1.1</b> Moments</a></li>
<li class="chapter" data-level="3.1.2" data-path="modeling-loss-severity.html"><a href="modeling-loss-severity.html#quantiles"><i class="fa fa-check"></i><b>3.1.2</b> Quantiles</a></li>
<li class="chapter" data-level="3.1.3" data-path="modeling-loss-severity.html"><a href="modeling-loss-severity.html#moment-generating-function"><i class="fa fa-check"></i><b>3.1.3</b> Moment Generating Function</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="modeling-loss-severity.html"><a href="modeling-loss-severity.html#distribusi-kontinu-untuk-memodelkan-tingkat-keparahan-dari-kerugian"><i class="fa fa-check"></i><b>3.2</b> Distribusi Kontinu untuk Memodelkan Tingkat Keparahan dari Kerugian</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="modeling-loss-severity.html"><a href="modeling-loss-severity.html#gamma-distribution"><i class="fa fa-check"></i><b>3.2.1</b> Gamma Distribution</a></li>
<li class="chapter" data-level="3.2.2" data-path="modeling-loss-severity.html"><a href="modeling-loss-severity.html#distribusi-pareto"><i class="fa fa-check"></i><b>3.2.2</b> Distribusi Pareto</a></li>
<li class="chapter" data-level="3.2.3" data-path="modeling-loss-severity.html"><a href="modeling-loss-severity.html#distribusi-weibull"><i class="fa fa-check"></i><b>3.2.3</b> Distribusi Weibull</a></li>
<li class="chapter" data-level="3.2.4" data-path="modeling-loss-severity.html"><a href="modeling-loss-severity.html#distribusi-beta-umum-jenis-kedua"><i class="fa fa-check"></i><b>3.2.4</b> Distribusi Beta Umum Jenis Kedua</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="modeling-loss-severity.html"><a href="modeling-loss-severity.html#methods-of-creating-new-distributions"><i class="fa fa-check"></i><b>3.3</b> Methods of Creating New Distributions</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="modeling-loss-severity.html"><a href="modeling-loss-severity.html#functions-of-random-variables-and-their-distributions"><i class="fa fa-check"></i><b>3.3.1</b> Functions of Random Variables and their Distributions</a></li>
<li class="chapter" data-level="3.3.2" data-path="modeling-loss-severity.html"><a href="modeling-loss-severity.html#multiplication-by-a-constant"><i class="fa fa-check"></i><b>3.3.2</b> Multiplication by a Constant</a></li>
<li class="chapter" data-level="3.3.3" data-path="modeling-loss-severity.html"><a href="modeling-loss-severity.html#raising-to-a-power"><i class="fa fa-check"></i><b>3.3.3</b> Raising to a Power</a></li>
<li class="chapter" data-level="3.3.4" data-path="modeling-loss-severity.html"><a href="modeling-loss-severity.html#exponentiation"><i class="fa fa-check"></i><b>3.3.4</b> Exponentiation</a></li>
<li class="chapter" data-level="3.3.5" data-path="modeling-loss-severity.html"><a href="modeling-loss-severity.html#finite-mixtures"><i class="fa fa-check"></i><b>3.3.5</b> Finite Mixtures</a></li>
<li class="chapter" data-level="3.3.6" data-path="modeling-loss-severity.html"><a href="modeling-loss-severity.html#continuous-mixtures"><i class="fa fa-check"></i><b>3.3.6</b> Continuous Mixtures</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="modeling-loss-severity.html"><a href="modeling-loss-severity.html#modifikasi-pertanggungan"><i class="fa fa-check"></i><b>3.4</b> modifikasi pertanggungan</a>
<ul>
<li class="chapter" data-level="3.4.1" data-path="modeling-loss-severity.html"><a href="modeling-loss-severity.html#policy-deductibles"><i class="fa fa-check"></i><b>3.4.1</b> policy deductibles</a></li>
<li class="chapter" data-level="3.4.2" data-path="modeling-loss-severity.html"><a href="modeling-loss-severity.html#policy-limit"><i class="fa fa-check"></i><b>3.4.2</b> Policy Limit</a></li>
<li class="chapter" data-level="3.4.3" data-path="modeling-loss-severity.html"><a href="modeling-loss-severity.html#policy-deductible-and-policy-limit"><i class="fa fa-check"></i><b>3.4.3</b> policy deductible and policy limit</a></li>
<li class="chapter" data-level="3.4.4" data-path="modeling-loss-severity.html"><a href="modeling-loss-severity.html#coinsurance-and-inflation"><i class="fa fa-check"></i><b>3.4.4</b> Coinsurance and inflation</a></li>
<li class="chapter" data-level="3.4.5" data-path="modeling-loss-severity.html"><a href="modeling-loss-severity.html#reinsurance"><i class="fa fa-check"></i><b>3.4.5</b> Reinsurance</a></li>
<li class="chapter" data-level="3.4.6" data-path="modeling-loss-severity.html"><a href="modeling-loss-severity.html#coinsurance-and-reinsurance"><i class="fa fa-check"></i><b>3.4.6</b> Coinsurance and Reinsurance</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="modeling-loss-severity.html"><a href="modeling-loss-severity.html#maximum-likelihood-estimation"><i class="fa fa-check"></i><b>3.5</b> Maximum Likelihood Estimation</a>
<ul>
<li class="chapter" data-level="3.5.1" data-path="modeling-loss-severity.html"><a href="modeling-loss-severity.html#maximum-likelihood-estimators-for-complete-data"><i class="fa fa-check"></i><b>3.5.1</b> Maximum Likelihood Estimators for Complete Data</a></li>
<li class="chapter" data-level="3.5.2" data-path="modeling-loss-severity.html"><a href="modeling-loss-severity.html#maximum-likehood-estimators-using-modified-data"><i class="fa fa-check"></i><b>3.5.2</b> Maximum Likehood Estimators using Modified Data</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="model-selection-and-estimation.html"><a href="model-selection-and-estimation.html"><i class="fa fa-check"></i><b>4</b> Model Selection and Estimation</a>
<ul>
<li class="chapter" data-level="4.1" data-path="model-selection-and-estimation.html"><a href="model-selection-and-estimation.html#nonparametric-inference"><i class="fa fa-check"></i><b>4.1</b> Nonparametric Inference</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="model-selection-and-estimation.html"><a href="model-selection-and-estimation.html#estimasi-nonparametrik"><i class="fa fa-check"></i><b>4.1.1</b> Estimasi Nonparametrik</a></li>
<li class="chapter" data-level="4.1.2" data-path="model-selection-and-estimation.html"><a href="model-selection-and-estimation.html#alat-untuk-pemilihan-model-dan-diagnostik"><i class="fa fa-check"></i><b>4.1.2</b> Alat untuk Pemilihan Model dan Diagnostik</a></li>
<li class="chapter" data-level="4.1.3" data-path="model-selection-and-estimation.html"><a href="model-selection-and-estimation.html#nilai-awal"><i class="fa fa-check"></i><b>4.1.3</b> Nilai Awal</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="model-selection-and-estimation.html"><a href="model-selection-and-estimation.html#model-selection"><i class="fa fa-check"></i><b>4.2</b> Model Selection</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="model-selection-and-estimation.html"><a href="model-selection-and-estimation.html#pemilihan-model-iteratif"><i class="fa fa-check"></i><b>4.2.1</b> Pemilihan Model Iteratif</a></li>
<li class="chapter" data-level="4.2.2" data-path="model-selection-and-estimation.html"><a href="model-selection-and-estimation.html#model-selection-based-on-a-training-dataset"><i class="fa fa-check"></i><b>4.2.2</b> Model Selection Based on a Training Dataset</a></li>
<li class="chapter" data-level="4.2.3" data-path="model-selection-and-estimation.html"><a href="model-selection-and-estimation.html#model-selection-based-on-a-test-dataset"><i class="fa fa-check"></i><b>4.2.3</b> Model Selection Based on a Test Dataset</a></li>
<li class="chapter" data-level="4.2.4" data-path="model-selection-and-estimation.html"><a href="model-selection-and-estimation.html#model-selection-based-on-cross-validation"><i class="fa fa-check"></i><b>4.2.4</b> Model Selection Based on Cross-Validation</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="model-selection-and-estimation.html"><a href="model-selection-and-estimation.html#estimasi-menggunakan-data-modifikasi"><i class="fa fa-check"></i><b>4.3</b> Estimasi Menggunakan Data Modifikasi</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="model-selection-and-estimation.html"><a href="model-selection-and-estimation.html#estimasi-parametrik-menggunakan-data-modifikasi"><i class="fa fa-check"></i><b>4.3.1</b> Estimasi Parametrik menggunakan Data Modifikasi</a></li>
<li class="chapter" data-level="4.3.2" data-path="model-selection-and-estimation.html"><a href="model-selection-and-estimation.html#nonparametric-estimation-using-modified-data"><i class="fa fa-check"></i><b>4.3.2</b> Nonparametric Estimation using Modified Data</a></li>
<li class="chapter" data-level="4.3.3" data-path="model-selection-and-estimation.html"><a href="model-selection-and-estimation.html#example-4.3.5.-actuarial-exam-question."><i class="fa fa-check"></i><b>4.3.3</b> Example 4.3.5. Actuarial Exam Question.</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="model-selection-and-estimation.html"><a href="model-selection-and-estimation.html#bayesian-inference"><i class="fa fa-check"></i><b>4.4</b> Bayesian Inference</a>
<ul>
<li class="chapter" data-level="4.4.1" data-path="model-selection-and-estimation.html"><a href="model-selection-and-estimation.html#introduction-to-bayesian-inference"><i class="fa fa-check"></i><b>4.4.1</b> Introduction to Bayesian Inference</a></li>
<li class="chapter" data-level="4.4.2" data-path="model-selection-and-estimation.html"><a href="model-selection-and-estimation.html#bayesian-model"><i class="fa fa-check"></i><b>4.4.2</b> Bayesian Model</a></li>
<li class="chapter" data-level="4.4.3" data-path="model-selection-and-estimation.html"><a href="model-selection-and-estimation.html#bayesian-inference-1"><i class="fa fa-check"></i><b>4.4.3</b> Bayesian Inference</a></li>
<li class="chapter" data-level="4.4.4" data-path="model-selection-and-estimation.html"><a href="model-selection-and-estimation.html#conjugate-distributions"><i class="fa fa-check"></i><b>4.4.4</b> Conjugate Distributions</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="aggregate-loss-models.html"><a href="aggregate-loss-models.html"><i class="fa fa-check"></i><b>5</b> Aggregate Loss Models</a>
<ul>
<li class="chapter" data-level="5.1" data-path="aggregate-loss-models.html"><a href="aggregate-loss-models.html#introduction"><i class="fa fa-check"></i><b>5.1</b> Introduction</a></li>
<li class="chapter" data-level="5.2" data-path="aggregate-loss-models.html"><a href="aggregate-loss-models.html#moments-and-distribution"><i class="fa fa-check"></i><b>5.2</b> Moments and Distribution</a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="aggregate-loss-models.html"><a href="aggregate-loss-models.html#stop-loss-insurance"><i class="fa fa-check"></i><b>5.2.1</b> Stop-loss Insurance</a></li>
<li class="chapter" data-level="5.2.2" data-path="aggregate-loss-models.html"><a href="aggregate-loss-models.html#actuarial-exam-question---continued"><i class="fa fa-check"></i><b>5.2.2</b> Actuarial Exam Question - Continued</a></li>
<li class="chapter" data-level="5.2.3" data-path="aggregate-loss-models.html"><a href="aggregate-loss-models.html#analytic-results"><i class="fa fa-check"></i><b>5.2.3</b> Analytic Results</a></li>
<li class="chapter" data-level="5.2.4" data-path="aggregate-loss-models.html"><a href="aggregate-loss-models.html#tweedie-distribution"><i class="fa fa-check"></i><b>5.2.4</b> Tweedie Distribution</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="aggregate-loss-models.html"><a href="aggregate-loss-models.html#menghitung-distribusi-klaim-agregat"><i class="fa fa-check"></i><b>5.3</b> Menghitung Distribusi Klaim Agregat</a>
<ul>
<li class="chapter" data-level="5.3.1" data-path="aggregate-loss-models.html"><a href="aggregate-loss-models.html#metode-rekursif"><i class="fa fa-check"></i><b>5.3.1</b> metode rekursif</a></li>
<li class="chapter" data-level="5.3.2" data-path="aggregate-loss-models.html"><a href="aggregate-loss-models.html#simulasi"><i class="fa fa-check"></i><b>5.3.2</b> simulasi</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="simulation-and-resampling.html"><a href="simulation-and-resampling.html"><i class="fa fa-check"></i><b>6</b> Simulation and Resampling</a>
<ul>
<li class="chapter" data-level="6.1" data-path="simulation-and-resampling.html"><a href="simulation-and-resampling.html#dasar-dasar-simulasi"><i class="fa fa-check"></i><b>6.1</b> Dasar-Dasar Simulasi</a>
<ul>
<li class="chapter" data-level="6.1.1" data-path="simulation-and-resampling.html"><a href="simulation-and-resampling.html#menghasilkan-pengamatan-seragam-independen"><i class="fa fa-check"></i><b>6.1.1</b> Menghasilkan Pengamatan Seragam Independen</a></li>
<li class="chapter" data-level="6.1.2" data-path="simulation-and-resampling.html"><a href="simulation-and-resampling.html#metode-transformasi-invers"><i class="fa fa-check"></i><b>6.1.2</b> Metode Transformasi Invers</a></li>
<li class="chapter" data-level="6.1.3" data-path="simulation-and-resampling.html"><a href="simulation-and-resampling.html#presisi-simulasi"><i class="fa fa-check"></i><b>6.1.3</b> (6.1.3) Presisi Simulasi</a></li>
<li class="chapter" data-level="6.1.4" data-path="simulation-and-resampling.html"><a href="simulation-and-resampling.html#simulasi-dan-inferensi-statistik"><i class="fa fa-check"></i><b>6.1.4</b> Simulasi dan Inferensi Statistik</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="simulation-and-resampling.html"><a href="simulation-and-resampling.html#bootstrap-dan-resampling"><i class="fa fa-check"></i><b>6.2</b> Bootstrap dan Resampling</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="simulation-and-resampling.html"><a href="simulation-and-resampling.html#dasar-dasar-bootstrap"><i class="fa fa-check"></i><b>6.2.1</b> Dasar-dasar Bootstrap</a></li>
<li class="chapter" data-level="6.2.2" data-path="simulation-and-resampling.html"><a href="simulation-and-resampling.html#presisi-bootstrap-bias-standar-deviasi-dan-mean-square-error"><i class="fa fa-check"></i><b>6.2.2</b> Presisi Bootstrap: Bias, Standar Deviasi, dan Mean Square Error</a></li>
<li class="chapter" data-level="6.2.3" data-path="simulation-and-resampling.html"><a href="simulation-and-resampling.html#interval-keyakinan"><i class="fa fa-check"></i><b>6.2.3</b> Interval Keyakinan</a></li>
<li class="chapter" data-level="6.2.4" data-path="simulation-and-resampling.html"><a href="simulation-and-resampling.html#bootstrap-parametrik"><i class="fa fa-check"></i><b>6.2.4</b> Bootstrap Parametrik</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="simulation-and-resampling.html"><a href="simulation-and-resampling.html#cross-validation"><i class="fa fa-check"></i><b>6.3</b> Cross Validation</a>
<ul>
<li class="chapter" data-level="6.3.1" data-path="simulation-and-resampling.html"><a href="simulation-and-resampling.html#k-fold-cross-validation"><i class="fa fa-check"></i><b>6.3.1</b> k-Fold Cross-Validation</a></li>
<li class="chapter" data-level="6.3.2" data-path="simulation-and-resampling.html"><a href="simulation-and-resampling.html#leave-one-out-cross-validation"><i class="fa fa-check"></i><b>6.3.2</b> 6.3.2 Leave-One-Out Cross-Validation</a></li>
<li class="chapter" data-level="6.3.3" data-path="simulation-and-resampling.html"><a href="simulation-and-resampling.html#cross-validation-and-bootstrap"><i class="fa fa-check"></i><b>6.3.3</b> Cross-Validation and Bootstrap</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="simulation-and-resampling.html"><a href="simulation-and-resampling.html#importance-sampling"><i class="fa fa-check"></i><b>6.4</b> Importance Sampling</a></li>
<li class="chapter" data-level="6.5" data-path="simulation-and-resampling.html"><a href="simulation-and-resampling.html#metropolis-hastings"><i class="fa fa-check"></i><b>6.5</b> Metropolis Hastings</a></li>
<li class="chapter" data-level="6.6" data-path="simulation-and-resampling.html"><a href="simulation-and-resampling.html#gibbs-sampler"><i class="fa fa-check"></i><b>6.6</b> Gibbs Sampler</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="premium-foundations.html"><a href="premium-foundations.html"><i class="fa fa-check"></i><b>7</b> Premium Foundations</a>
<ul>
<li class="chapter" data-level="7.1" data-path="premium-foundations.html"><a href="premium-foundations.html#pengenalan-ratemaking"><i class="fa fa-check"></i><b>7.1</b> Pengenalan Ratemaking</a></li>
<li class="chapter" data-level="7.2" data-path="premium-foundations.html"><a href="premium-foundations.html#metode-penentuan-tarif-gabungan"><i class="fa fa-check"></i><b>7.2</b> Metode Penentuan Tarif Gabungan</a>
<ul>
<li class="chapter" data-level="7.2.1" data-path="premium-foundations.html"><a href="premium-foundations.html#metode-penghitungan-premi-murni"><i class="fa fa-check"></i><b>7.2.1</b> Metode Penghitungan Premi Murni</a></li>
<li class="chapter" data-level="7.2.2" data-path="premium-foundations.html"><a href="premium-foundations.html#metode-rasio-kerugian"><i class="fa fa-check"></i><b>7.2.2</b> Metode Rasio Kerugian</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="premium-foundations.html"><a href="premium-foundations.html#prinsip-prinsip-penetapan-harga"><i class="fa fa-check"></i><b>7.3</b> Prinsip-prinsip Penetapan Harga</a>
<ul>
<li class="chapter" data-level="7.3.1" data-path="premium-foundations.html"><a href="premium-foundations.html#prinsip-prinsip-premi"><i class="fa fa-check"></i><b>7.3.1</b> Prinsip-Prinsip Premi</a></li>
<li class="chapter" data-level="7.3.2" data-path="premium-foundations.html"><a href="premium-foundations.html#sifat-prinsip-premium"><i class="fa fa-check"></i><b>7.3.2</b> Sifat Prinsip Premium</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="premium-foundations.html"><a href="premium-foundations.html#risiko-heterogen"><i class="fa fa-check"></i><b>7.4</b> Risiko Heterogen</a>
<ul>
<li class="chapter" data-level="7.4.1" data-path="premium-foundations.html"><a href="premium-foundations.html#paparan-risiko"><i class="fa fa-check"></i><b>7.4.1</b> Paparan Risiko</a></li>
<li class="chapter" data-level="7.4.2" data-path="premium-foundations.html"><a href="premium-foundations.html#faktor-penilaian"><i class="fa fa-check"></i><b>7.4.2</b> Faktor Penilaian</a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="premium-foundations.html"><a href="premium-foundations.html#development-and-trending"><i class="fa fa-check"></i><b>7.5</b> Development and Trending</a>
<ul>
<li class="chapter" data-level="7.5.1" data-path="premium-foundations.html"><a href="premium-foundations.html#paparan-dan-premi"><i class="fa fa-check"></i><b>7.5.1</b> Paparan dan Premi</a></li>
<li class="chapter" data-level="7.5.2" data-path="premium-foundations.html"><a href="premium-foundations.html#kerugian-klaim-dan-pembayaran"><i class="fa fa-check"></i><b>7.5.2</b> Kerugian, Klaim, dan Pembayaran</a></li>
<li class="chapter" data-level="7.5.3" data-path="premium-foundations.html"><a href="premium-foundations.html#membandingkan-metode-premi-murni-dan-rasio-kerugian"><i class="fa fa-check"></i><b>7.5.3</b> Membandingkan Metode Premi Murni dan Rasio Kerugian</a></li>
</ul></li>
<li class="chapter" data-level="7.6" data-path="premium-foundations.html"><a href="premium-foundations.html#selecting-a-premium"><i class="fa fa-check"></i><b>7.6</b> Selecting a Premium</a>
<ul>
<li class="chapter" data-level="7.6.1" data-path="premium-foundations.html"><a href="premium-foundations.html#kurva-lorenz-klasik"><i class="fa fa-check"></i><b>7.6.1</b> Kurva Lorenz Klasik</a></li>
<li class="chapter" data-level="7.6.2" data-path="premium-foundations.html"><a href="premium-foundations.html#performance-curve-and-a-gini-statistic"><i class="fa fa-check"></i><b>7.6.2</b> Performance Curve and a Gini Statistic</a></li>
<li class="chapter" data-level="7.6.3" data-path="premium-foundations.html"><a href="premium-foundations.html#validasi-di-luar-sampel"><i class="fa fa-check"></i><b>7.6.3</b> Validasi di Luar Sampel</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="risk-classification.html"><a href="risk-classification.html"><i class="fa fa-check"></i><b>8</b> Risk Classification</a>
<ul>
<li class="chapter" data-level="8.1" data-path="risk-classification.html"><a href="risk-classification.html#introduction-1"><i class="fa fa-check"></i><b>8.1</b> Introduction</a></li>
<li class="chapter" data-level="8.2" data-path="risk-classification.html"><a href="risk-classification.html#poisson-regression-model"><i class="fa fa-check"></i><b>8.2</b> Poisson Regression Model</a>
<ul>
<li class="chapter" data-level="8.2.1" data-path="risk-classification.html"><a href="risk-classification.html#need-for-poisson-regression"><i class="fa fa-check"></i><b>8.2.1</b> Need for Poisson Regression</a></li>
<li class="chapter" data-level="8.2.2" data-path="risk-classification.html"><a href="risk-classification.html#poisson-regression"><i class="fa fa-check"></i><b>8.2.2</b> Poisson Regression</a></li>
<li class="chapter" data-level="8.2.3" data-path="risk-classification.html"><a href="risk-classification.html#incorporating-exposure"><i class="fa fa-check"></i><b>8.2.3</b> Incorporating Exposure</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="risk-classification.html"><a href="risk-classification.html#categorical-variables-and-multiplicative-tariff"><i class="fa fa-check"></i><b>8.3</b> Categorical Variables and Multiplicative Tariff</a>
<ul>
<li class="chapter" data-level="8.3.1" data-path="risk-classification.html"><a href="risk-classification.html#rating-factors-and-tariff"><i class="fa fa-check"></i><b>8.3.1</b> Rating Factors and Tariff</a></li>
<li class="chapter" data-level="8.3.2" data-path="risk-classification.html"><a href="risk-classification.html#multiplicative-tariff-model"><i class="fa fa-check"></i><b>8.3.2</b> Multiplicative Tariff Model</a></li>
<li class="chapter" data-level="8.3.3" data-path="risk-classification.html"><a href="risk-classification.html#poisson-regression-for-multiplicative-tariff"><i class="fa fa-check"></i><b>8.3.3</b> Poisson Regression for Multiplicative Tariff</a></li>
<li class="chapter" data-level="8.3.4" data-path="risk-classification.html"><a href="risk-classification.html#numerical-examples"><i class="fa fa-check"></i><b>8.3.4</b> Numerical Examples</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="risk-classification.html"><a href="risk-classification.html#further-resources-and-contributors"><i class="fa fa-check"></i><b>8.4</b> Further Resources and Contributors</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="experience-rating-using-credibility-theory.html"><a href="experience-rating-using-credibility-theory.html"><i class="fa fa-check"></i><b>9</b> Experience Rating Using Credibility Theory</a>
<ul>
<li class="chapter" data-level="9.1" data-path="experience-rating-using-credibility-theory.html"><a href="experience-rating-using-credibility-theory.html#pengantar-aplikasi-teori-kredibilitas"><i class="fa fa-check"></i><b>9.1</b> Pengantar Aplikasi Teori Kredibilitas</a></li>
<li class="chapter" data-level="9.2" data-path="experience-rating-using-credibility-theory.html"><a href="experience-rating-using-credibility-theory.html#limited-fluctuation-credibility"><i class="fa fa-check"></i><b>9.2</b> Limited Fluctuation Credibility</a>
<ul>
<li class="chapter" data-level="9.2.1" data-path="experience-rating-using-credibility-theory.html"><a href="experience-rating-using-credibility-theory.html#kredibilitas-penuh-untuk-frekuensi-klaim"><i class="fa fa-check"></i><b>9.2.1</b> Kredibilitas Penuh untuk Frekuensi Klaim</a></li>
<li class="chapter" data-level="9.2.2" data-path="experience-rating-using-credibility-theory.html"><a href="experience-rating-using-credibility-theory.html#kredibilitas-penuh-untuk-kerugian-agregat-dan-premi-murni"><i class="fa fa-check"></i><b>9.2.2</b> Kredibilitas Penuh untuk Kerugian Agregat dan Premi Murni</a></li>
<li class="chapter" data-level="9.2.3" data-path="experience-rating-using-credibility-theory.html"><a href="experience-rating-using-credibility-theory.html#kredibilitas-penuh-untuk-tingkat-keparahan"><i class="fa fa-check"></i><b>9.2.3</b> Kredibilitas Penuh untuk Tingkat Keparahan</a></li>
<li class="chapter" data-level="9.2.4" data-path="experience-rating-using-credibility-theory.html"><a href="experience-rating-using-credibility-theory.html#kredibilitas-parsial"><i class="fa fa-check"></i><b>9.2.4</b> Kredibilitas parsial</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="experience-rating-using-credibility-theory.html"><a href="experience-rating-using-credibility-theory.html#bühlmann-credibility"><i class="fa fa-check"></i><b>9.3</b> Bühlmann Credibility</a>
<ul>
<li class="chapter" data-level="9.3.1" data-path="experience-rating-using-credibility-theory.html"><a href="experience-rating-using-credibility-theory.html#credibility-z-epv-and-vhm"><i class="fa fa-check"></i><b>9.3.1</b> Credibility Z, EPV, and VHM</a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="experience-rating-using-credibility-theory.html"><a href="experience-rating-using-credibility-theory.html#bühlmann-straub-credibility"><i class="fa fa-check"></i><b>9.4</b> Bühlmann-Straub Credibility</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="insurance-portfolio-management-including-reinsurance.html"><a href="insurance-portfolio-management-including-reinsurance.html"><i class="fa fa-check"></i><b>10</b> Insurance Portfolio Management including Reinsurance</a>
<ul>
<li class="chapter" data-level="10.1" data-path="insurance-portfolio-management-including-reinsurance.html"><a href="insurance-portfolio-management-including-reinsurance.html#introduction-to-insurance-portfolios"><i class="fa fa-check"></i><b>10.1</b> Introduction to Insurance Portfolios</a></li>
<li class="chapter" data-level="10.2" data-path="insurance-portfolio-management-including-reinsurance.html"><a href="insurance-portfolio-management-including-reinsurance.html#tails-of-distributions"><i class="fa fa-check"></i><b>10.2</b> Tails of Distributions</a>
<ul>
<li class="chapter" data-level="10.2.1" data-path="insurance-portfolio-management-including-reinsurance.html"><a href="insurance-portfolio-management-including-reinsurance.html#classification-based-on-moments"><i class="fa fa-check"></i><b>10.2.1</b> Classification Based on Moments</a></li>
<li class="chapter" data-level="10.2.2" data-path="insurance-portfolio-management-including-reinsurance.html"><a href="insurance-portfolio-management-including-reinsurance.html#comparison-based-on-limiting-tail-behavior"><i class="fa fa-check"></i><b>10.2.2</b> Comparison Based on Limiting Tail Behavior</a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="insurance-portfolio-management-including-reinsurance.html"><a href="insurance-portfolio-management-including-reinsurance.html#risk-measures"><i class="fa fa-check"></i><b>10.3</b> Risk Measures</a>
<ul>
<li class="chapter" data-level="10.3.1" data-path="insurance-portfolio-management-including-reinsurance.html"><a href="insurance-portfolio-management-including-reinsurance.html#coherent-risk-measures"><i class="fa fa-check"></i><b>10.3.1</b> Coherent Risk Measures</a></li>
<li class="chapter" data-level="10.3.2" data-path="insurance-portfolio-management-including-reinsurance.html"><a href="insurance-portfolio-management-including-reinsurance.html#value-at-risk"><i class="fa fa-check"></i><b>10.3.2</b> Value-at-Risk</a></li>
<li class="chapter" data-level="10.3.3" data-path="insurance-portfolio-management-including-reinsurance.html"><a href="insurance-portfolio-management-including-reinsurance.html#example-10.3.2.-var-for-the-normal-distribution."><i class="fa fa-check"></i><b>10.3.3</b> Example 10.3.2. VaR for the normal distribution.</a></li>
<li class="chapter" data-level="10.3.4" data-path="insurance-portfolio-management-including-reinsurance.html"><a href="insurance-portfolio-management-including-reinsurance.html#tail-value-at-risk"><i class="fa fa-check"></i><b>10.3.4</b> Tail Value-at-Risk</a></li>
</ul></li>
<li class="chapter" data-level="10.4" data-path="insurance-portfolio-management-including-reinsurance.html"><a href="insurance-portfolio-management-including-reinsurance.html#reinsurance-1"><i class="fa fa-check"></i><b>10.4</b> Reinsurance</a>
<ul>
<li class="chapter" data-level="10.4.1" data-path="insurance-portfolio-management-including-reinsurance.html"><a href="insurance-portfolio-management-including-reinsurance.html#proportional-reinsurance"><i class="fa fa-check"></i><b>10.4.1</b> Proportional Reinsurance</a></li>
<li class="chapter" data-level="10.4.2" data-path="insurance-portfolio-management-including-reinsurance.html"><a href="insurance-portfolio-management-including-reinsurance.html#non-proportional-reinsurance"><i class="fa fa-check"></i><b>10.4.2</b> Non-Proportional Reinsurance</a></li>
<li class="chapter" data-level="10.4.3" data-path="insurance-portfolio-management-including-reinsurance.html"><a href="insurance-portfolio-management-including-reinsurance.html#additional-reinsurance-treaties"><i class="fa fa-check"></i><b>10.4.3</b> Additional Reinsurance Treaties</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="11" data-path="loss-reserving.html"><a href="loss-reserving.html"><i class="fa fa-check"></i><b>11</b> Loss Reserving</a>
<ul>
<li class="chapter" data-level="11.1" data-path="loss-reserving.html"><a href="loss-reserving.html#motivation"><i class="fa fa-check"></i><b>11.1</b> Motivation</a>
<ul>
<li class="chapter" data-level="11.1.1" data-path="loss-reserving.html"><a href="loss-reserving.html#closed-ibnr-and-rbns-claims"><i class="fa fa-check"></i><b>11.1.1</b> Closed, IBNR, and RBNS Claims</a></li>
<li class="chapter" data-level="11.1.2" data-path="loss-reserving.html"><a href="loss-reserving.html#why-reserving"><i class="fa fa-check"></i><b>11.1.2</b> Why Reserving?</a></li>
</ul></li>
<li class="chapter" data-level="11.2" data-path="loss-reserving.html"><a href="loss-reserving.html#loss-reserve-data"><i class="fa fa-check"></i><b>11.2</b> Loss Reserve Data</a>
<ul>
<li class="chapter" data-level="11.2.1" data-path="loss-reserving.html"><a href="loss-reserving.html#from-micro-to-macro"><i class="fa fa-check"></i><b>11.2.1</b> From Micro to Macro</a></li>
<li class="chapter" data-level="11.2.2" data-path="loss-reserving.html"><a href="loss-reserving.html#run-off-triangles"><i class="fa fa-check"></i><b>11.2.2</b> Run-off Triangles</a></li>
<li class="chapter" data-level="11.2.3" data-path="loss-reserving.html"><a href="loss-reserving.html#loss-reserve-notation"><i class="fa fa-check"></i><b>11.2.3</b> Loss Reserve Notation</a></li>
<li class="chapter" data-level="11.2.4" data-path="loss-reserving.html"><a href="loss-reserving.html#r-code-to-summarize-loss-reserve-data"><i class="fa fa-check"></i><b>11.2.4</b> R Code to Summarize Loss Reserve Data</a></li>
</ul></li>
<li class="chapter" data-level="11.3" data-path="loss-reserving.html"><a href="loss-reserving.html#the-chain-ladder-method"><i class="fa fa-check"></i><b>11.3</b> The Chain-Ladder Method</a>
<ul>
<li class="chapter" data-level="11.3.1" data-path="loss-reserving.html"><a href="loss-reserving.html#the-deterministic-chain-ladder"><i class="fa fa-check"></i><b>11.3.1</b> The Deterministic Chain-Ladder</a></li>
<li class="chapter" data-level="11.3.2" data-path="loss-reserving.html"><a href="loss-reserving.html#macks-distribution-free-chain-ladder-model"><i class="fa fa-check"></i><b>11.3.2</b> Mack’s Distribution-Free Chain-Ladder Model</a></li>
<li class="chapter" data-level="11.3.3" data-path="loss-reserving.html"><a href="loss-reserving.html#r-code-for-chain-ladder-predictions"><i class="fa fa-check"></i><b>11.3.3</b> R code for Chain-Ladder Predictions</a></li>
</ul></li>
<li class="chapter" data-level="11.4" data-path="loss-reserving.html"><a href="loss-reserving.html#glms-and-bootstrap-for-loss-reserves"><i class="fa fa-check"></i><b>11.4</b> GLMs and Bootstrap for Loss Reserves</a>
<ul>
<li class="chapter" data-level="11.4.1" data-path="loss-reserving.html"><a href="loss-reserving.html#model-specification"><i class="fa fa-check"></i><b>11.4.1</b> Model Specification</a></li>
<li class="chapter" data-level="11.4.2" data-path="loss-reserving.html"><a href="loss-reserving.html#model-estimation-and-prediction"><i class="fa fa-check"></i><b>11.4.2</b> Model Estimation and Prediction</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="12" data-path="experience-rating-using-bonus-malus.html"><a href="experience-rating-using-bonus-malus.html"><i class="fa fa-check"></i><b>12</b> Experience Rating using Bonus-Malus</a>
<ul>
<li class="chapter" data-level="12.1" data-path="experience-rating-using-bonus-malus.html"><a href="experience-rating-using-bonus-malus.html#introduction-2"><i class="fa fa-check"></i><b>12.1</b> Introduction</a></li>
<li class="chapter" data-level="12.2" data-path="experience-rating-using-bonus-malus.html"><a href="experience-rating-using-bonus-malus.html#sistem-ncd-di-beberapa-negara"><i class="fa fa-check"></i><b>12.2</b> Sistem NCD di Beberapa Negara</a>
<ul>
<li class="chapter" data-level="12.2.1" data-path="experience-rating-using-bonus-malus.html"><a href="experience-rating-using-bonus-malus.html#sistem-ncd-di-malaysia"><i class="fa fa-check"></i><b>12.2.1</b> Sistem NCD di Malaysia</a></li>
<li class="chapter" data-level="12.2.2" data-path="experience-rating-using-bonus-malus.html"><a href="experience-rating-using-bonus-malus.html#sistem-ncd-di-negara-lain"><i class="fa fa-check"></i><b>12.2.2</b> Sistem NCD di Negara Lain</a></li>
</ul></li>
<li class="chapter" data-level="12.3" data-path="experience-rating-using-bonus-malus.html"><a href="experience-rating-using-bonus-malus.html#model-rantai-bms-dan-markov"><i class="fa fa-check"></i><b>12.3</b> Model Rantai BMS dan Markov</a>
<ul>
<li class="chapter" data-level="12.3.1" data-path="experience-rating-using-bonus-malus.html"><a href="experience-rating-using-bonus-malus.html#probabilitas-transisi"><i class="fa fa-check"></i><b>12.3.1</b> Probabilitas Transisi</a></li>
</ul></li>
<li class="chapter" data-level="12.4" data-path="experience-rating-using-bonus-malus.html"><a href="experience-rating-using-bonus-malus.html#bms-dan-distribusi-stasioner"><i class="fa fa-check"></i><b>12.4</b> BMS dan Distribusi Stasioner</a>
<ul>
<li class="chapter" data-level="12.4.1" data-path="experience-rating-using-bonus-malus.html"><a href="experience-rating-using-bonus-malus.html#distribusi-stasioner"><i class="fa fa-check"></i><b>12.4.1</b> Distribusi Stasioner</a></li>
<li class="chapter" data-level="12.4.2" data-path="experience-rating-using-bonus-malus.html"><a href="experience-rating-using-bonus-malus.html#kode-untuk-distribusi-stasioner-r"><i class="fa fa-check"></i><b>12.4.2</b> Kode untuk Distribusi Stasioner <code>R</code></a></li>
<li class="chapter" data-level="12.4.3" data-path="experience-rating-using-bonus-malus.html"><a href="experience-rating-using-bonus-malus.html#evolusi-premium"><i class="fa fa-check"></i><b>12.4.3</b> Evolusi Premium</a></li>
<li class="chapter" data-level="12.4.4" data-path="experience-rating-using-bonus-malus.html"><a href="experience-rating-using-bonus-malus.html#program-untuk-evolusi-premium-r"><i class="fa fa-check"></i><b>12.4.4</b> Program untuk Evolusi Premium <code>R</code></a></li>
<li class="chapter" data-level="12.4.5" data-path="experience-rating-using-bonus-malus.html"><a href="experience-rating-using-bonus-malus.html#tingkat-konvergensi"><i class="fa fa-check"></i><b>12.4.5</b> Tingkat Konvergensi</a></li>
<li class="chapter" data-level="12.4.6" data-path="experience-rating-using-bonus-malus.html"><a href="experience-rating-using-bonus-malus.html#r-program-untuk-tingkat-konvergensi"><i class="fa fa-check"></i><b>12.4.6</b> <code>R</code> Program untuk Tingkat Konvergensi</a></li>
</ul></li>
<li class="chapter" data-level="12.5" data-path="experience-rating-using-bonus-malus.html"><a href="experience-rating-using-bonus-malus.html#bms-dan-peringkat-premium"><i class="fa fa-check"></i><b>12.5</b> BMS dan Peringkat Premium</a>
<ul>
<li class="chapter" data-level="12.5.1" data-path="experience-rating-using-bonus-malus.html"><a href="experience-rating-using-bonus-malus.html#peringkat-premium"><i class="fa fa-check"></i><b>12.5.1</b> Peringkat Premium</a></li>
<li class="chapter" data-level="12.5.2" data-path="experience-rating-using-bonus-malus.html"><a href="experience-rating-using-bonus-malus.html#klasifikasi-risiko-apriori"><i class="fa fa-check"></i><b>12.5.2</b> Klasifikasi Risiko Apriori</a></li>
<li class="chapter" data-level="12.5.3" data-path="experience-rating-using-bonus-malus.html"><a href="experience-rating-using-bonus-malus.html#pemodelan-heterogenitas-residual"><i class="fa fa-check"></i><b>12.5.3</b> Pemodelan Heterogenitas Residual</a></li>
<li class="chapter" data-level="12.5.4" data-path="experience-rating-using-bonus-malus.html"><a href="experience-rating-using-bonus-malus.html#distribusi-stasioner-yang-memungkinkan-heterogenitas-residual"><i class="fa fa-check"></i><b>12.5.4</b> Distribusi Stasioner yang Memungkinkan Heterogenitas Residual</a></li>
<li class="chapter" data-level="12.5.5" data-path="experience-rating-using-bonus-malus.html"><a href="experience-rating-using-bonus-malus.html#penentuan-relativitas-optimal"><i class="fa fa-check"></i><b>12.5.5</b> Penentuan Relativitas Optimal</a></li>
<li class="chapter" data-level="12.5.6" data-path="experience-rating-using-bonus-malus.html"><a href="experience-rating-using-bonus-malus.html#ilustrasi-numerik"><i class="fa fa-check"></i><b>12.5.6</b> Ilustrasi Numerik</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="13" data-path="aggregate-loss-models-1.html"><a href="aggregate-loss-models-1.html"><i class="fa fa-check"></i><b>13</b> Aggregate Loss Models</a>
<ul>
<li class="chapter" data-level="13.1" data-path="aggregate-loss-models-1.html"><a href="aggregate-loss-models-1.html#data"><i class="fa fa-check"></i><b>13.1</b> Data</a>
<ul>
<li class="chapter" data-level="13.1.1" data-path="aggregate-loss-models-1.html"><a href="aggregate-loss-models-1.html#tipe-data-dan-sumbernya"><i class="fa fa-check"></i><b>13.1.1</b> Tipe Data dan Sumbernya</a></li>
<li class="chapter" data-level="13.1.2" data-path="aggregate-loss-models-1.html"><a href="aggregate-loss-models-1.html#struktur-data-dan-penyimpanannya"><i class="fa fa-check"></i><b>13.1.2</b> Struktur Data dan Penyimpanannya</a></li>
<li class="chapter" data-level="13.1.3" data-path="aggregate-loss-models-1.html"><a href="aggregate-loss-models-1.html#kualitas-data"><i class="fa fa-check"></i><b>13.1.3</b> Kualitas Data</a></li>
<li class="chapter" data-level="13.1.4" data-path="aggregate-loss-models-1.html"><a href="aggregate-loss-models-1.html#data-cleaning"><i class="fa fa-check"></i><b>13.1.4</b> Data Cleaning</a></li>
</ul></li>
<li class="chapter" data-level="13.2" data-path="aggregate-loss-models-1.html"><a href="aggregate-loss-models-1.html#preliminari-analisis-data"><i class="fa fa-check"></i><b>13.2</b> Preliminari Analisis Data</a>
<ul>
<li class="chapter" data-level="13.2.1" data-path="aggregate-loss-models-1.html"><a href="aggregate-loss-models-1.html#proses-analisis-data"><i class="fa fa-check"></i><b>13.2.1</b> Proses Analisis Data</a></li>
<li class="chapter" data-level="13.2.2" data-path="aggregate-loss-models-1.html"><a href="aggregate-loss-models-1.html#exploratory-vs-confirmatory"><i class="fa fa-check"></i><b>13.2.2</b> Exploratory vs Confirmatory</a></li>
<li class="chapter" data-level="13.2.3" data-path="aggregate-loss-models-1.html"><a href="aggregate-loss-models-1.html#supervise-vs-unsupervised"><i class="fa fa-check"></i><b>13.2.3</b> Supervise vs Unsupervised</a></li>
<li class="chapter" data-level="13.2.4" data-path="aggregate-loss-models-1.html"><a href="aggregate-loss-models-1.html#parametrik-vs-nonparametrik"><i class="fa fa-check"></i><b>13.2.4</b> Parametrik vs Nonparametrik</a></li>
<li class="chapter" data-level="13.2.5" data-path="aggregate-loss-models-1.html"><a href="aggregate-loss-models-1.html#explanation-vs-prediction"><i class="fa fa-check"></i><b>13.2.5</b> Explanation vs Prediction</a></li>
<li class="chapter" data-level="13.2.6" data-path="aggregate-loss-models-1.html"><a href="aggregate-loss-models-1.html#data-modeling-vs-algorithmic-modeling"><i class="fa fa-check"></i><b>13.2.6</b> Data Modeling vs Algorithmic Modeling</a></li>
<li class="chapter" data-level="13.2.7" data-path="aggregate-loss-models-1.html"><a href="aggregate-loss-models-1.html#analisis-big-data"><i class="fa fa-check"></i><b>13.2.7</b> Analisis Big Data</a></li>
<li class="chapter" data-level="13.2.8" data-path="aggregate-loss-models-1.html"><a href="aggregate-loss-models-1.html#reproducible-analysis"><i class="fa fa-check"></i><b>13.2.8</b> Reproducible Analysis</a></li>
<li class="chapter" data-level="13.2.9" data-path="aggregate-loss-models-1.html"><a href="aggregate-loss-models-1.html#isu-etika"><i class="fa fa-check"></i><b>13.2.9</b> Isu Etika</a></li>
</ul></li>
<li class="chapter" data-level="13.3" data-path="aggregate-loss-models-1.html"><a href="aggregate-loss-models-1.html#teknik-analisis-data"><i class="fa fa-check"></i><b>13.3</b> Teknik Analisis Data</a>
<ul>
<li class="chapter" data-level="13.3.1" data-path="aggregate-loss-models-1.html"><a href="aggregate-loss-models-1.html#teknik-eksplorasi"><i class="fa fa-check"></i><b>13.3.1</b> Teknik Eksplorasi</a></li>
<li class="chapter" data-level="13.3.2" data-path="aggregate-loss-models-1.html"><a href="aggregate-loss-models-1.html#teknik-konfirmatori"><i class="fa fa-check"></i><b>13.3.2</b> Teknik Konfirmatori</a></li>
</ul></li>
<li class="chapter" data-level="13.4" data-path="aggregate-loss-models-1.html"><a href="aggregate-loss-models-1.html#r-function"><i class="fa fa-check"></i><b>13.4</b> R Function</a></li>
<li class="chapter" data-level="13.5" data-path="aggregate-loss-models-1.html"><a href="aggregate-loss-models-1.html#summary"><i class="fa fa-check"></i><b>13.5</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="dependence-modeling.html"><a href="dependence-modeling.html"><i class="fa fa-check"></i><b>14</b> Dependence Modeling</a>
<ul>
<li class="chapter" data-level="14.1" data-path="dependence-modeling.html"><a href="dependence-modeling.html#variable-types"><i class="fa fa-check"></i><b>14.1</b> Variable Types</a>
<ul>
<li class="chapter" data-level="14.1.1" data-path="dependence-modeling.html"><a href="dependence-modeling.html#quantitative-variables"><i class="fa fa-check"></i><b>14.1.1</b> Quantitative Variables</a></li>
<li class="chapter" data-level="14.1.2" data-path="dependence-modeling.html"><a href="dependence-modeling.html#multivariate-variables"><i class="fa fa-check"></i><b>14.1.2</b> Multivariate Variables</a></li>
</ul></li>
<li class="chapter" data-level="14.2" data-path="dependence-modeling.html"><a href="dependence-modeling.html#classic-measures-of-scalar-associations"><i class="fa fa-check"></i><b>14.2</b> Classic Measures of Scalar Associations</a>
<ul>
<li class="chapter" data-level="14.2.1" data-path="dependence-modeling.html"><a href="dependence-modeling.html#association-measures-for-quantitative-variables"><i class="fa fa-check"></i><b>14.2.1</b> Association Measures for Quantitative Variables</a></li>
<li class="chapter" data-level="14.2.2" data-path="dependence-modeling.html"><a href="dependence-modeling.html#rank-based-measures"><i class="fa fa-check"></i><b>14.2.2</b> Rank Based Measures</a></li>
<li class="chapter" data-level="14.2.3" data-path="dependence-modeling.html"><a href="dependence-modeling.html#nominal-variables"><i class="fa fa-check"></i><b>14.2.3</b> Nominal Variables</a></li>
<li class="chapter" data-level="14.2.4" data-path="dependence-modeling.html"><a href="dependence-modeling.html#ordinal-variables"><i class="fa fa-check"></i><b>14.2.4</b> Ordinal Variables</a></li>
<li class="chapter" data-level="14.2.5" data-path="dependence-modeling.html"><a href="dependence-modeling.html#interval-variables"><i class="fa fa-check"></i><b>14.2.5</b> Interval Variables</a></li>
<li class="chapter" data-level="14.2.6" data-path="dependence-modeling.html"><a href="dependence-modeling.html#discrete-and-continuous-variables"><i class="fa fa-check"></i><b>14.2.6</b> Discrete and Continuous Variables</a></li>
</ul></li>
<li class="chapter" data-level="14.3" data-path="dependence-modeling.html"><a href="dependence-modeling.html#introduction-to-copulas"><i class="fa fa-check"></i><b>14.3</b> Introduction to Copulas</a></li>
<li class="chapter" data-level="14.4" data-path="dependence-modeling.html"><a href="dependence-modeling.html#application-using-copulas"><i class="fa fa-check"></i><b>14.4</b> Application Using Copulas</a>
<ul>
<li class="chapter" data-level="14.4.1" data-path="dependence-modeling.html"><a href="dependence-modeling.html#data-description"><i class="fa fa-check"></i><b>14.4.1</b> Data Description</a></li>
<li class="chapter" data-level="14.4.2" data-path="dependence-modeling.html"><a href="dependence-modeling.html#marginal-models"><i class="fa fa-check"></i><b>14.4.2</b> Marginal Models</a></li>
<li class="chapter" data-level="14.4.3" data-path="dependence-modeling.html"><a href="dependence-modeling.html#probability-integral-transformation"><i class="fa fa-check"></i><b>14.4.3</b> Probability Integral Transformation</a></li>
<li class="chapter" data-level="14.4.4" data-path="dependence-modeling.html"><a href="dependence-modeling.html#joint-modeling-with-copula-function"><i class="fa fa-check"></i><b>14.4.4</b> Joint Modeling with Copula Function</a></li>
</ul></li>
<li class="chapter" data-level="14.5" data-path="dependence-modeling.html"><a href="dependence-modeling.html#types-of-copulas"><i class="fa fa-check"></i><b>14.5</b> Types of Copulas</a>
<ul>
<li class="chapter" data-level="14.5.1" data-path="dependence-modeling.html"><a href="dependence-modeling.html#normal-gaussian-copulas"><i class="fa fa-check"></i><b>14.5.1</b> Normal (Gaussian) Copulas</a></li>
<li class="chapter" data-level="14.5.2" data-path="dependence-modeling.html"><a href="dependence-modeling.html#t--and-elliptical-copulas"><i class="fa fa-check"></i><b>14.5.2</b> t- and Elliptical Copulas</a></li>
<li class="chapter" data-level="14.5.3" data-path="dependence-modeling.html"><a href="dependence-modeling.html#archimedean-copulas"><i class="fa fa-check"></i><b>14.5.3</b> Archimedean Copulas</a></li>
<li class="chapter" data-level="14.5.4" data-path="dependence-modeling.html"><a href="dependence-modeling.html#properties-of-copulas"><i class="fa fa-check"></i><b>14.5.4</b> Properties of Copulas</a></li>
</ul></li>
<li class="chapter" data-level="14.6" data-path="dependence-modeling.html"><a href="dependence-modeling.html#why-is-dependence-modeling-important"><i class="fa fa-check"></i><b>14.6</b> Why is Dependence Modeling Important?</a></li>
<li class="chapter" data-level="14.7" data-path="dependence-modeling.html"><a href="dependence-modeling.html#further-resources-and-contributors-1"><i class="fa fa-check"></i><b>14.7</b> Further Resources and Contributors</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="appendix-a-review-of-statistical-inference.html"><a href="appendix-a-review-of-statistical-inference.html"><i class="fa fa-check"></i><b>15</b> Appendix A: Review of Statistical Inference</a>
<ul>
<li class="chapter" data-level="15.1" data-path="appendix-a-review-of-statistical-inference.html"><a href="appendix-a-review-of-statistical-inference.html#konsep-dasar"><i class="fa fa-check"></i><b>15.1</b> konsep dasar</a>
<ul>
<li class="chapter" data-level="15.1.1" data-path="appendix-a-review-of-statistical-inference.html"><a href="appendix-a-review-of-statistical-inference.html#sampel-acak"><i class="fa fa-check"></i><b>15.1.1</b> Sampel Acak</a></li>
<li class="chapter" data-level="15.1.2" data-path="appendix-a-review-of-statistical-inference.html"><a href="appendix-a-review-of-statistical-inference.html#distribusi-sampel"><i class="fa fa-check"></i><b>15.1.2</b> Distribusi Sampel</a></li>
<li class="chapter" data-level="15.1.3" data-path="appendix-a-review-of-statistical-inference.html"><a href="appendix-a-review-of-statistical-inference.html#teorema-limit-sentral"><i class="fa fa-check"></i><b>15.1.3</b> Teorema Limit Sentral</a></li>
</ul></li>
<li class="chapter" data-level="15.2" data-path="appendix-a-review-of-statistical-inference.html"><a href="appendix-a-review-of-statistical-inference.html#estimasi-titik-dan-properti"><i class="fa fa-check"></i><b>15.2</b> Estimasi Titik dan Properti</a>
<ul>
<li class="chapter" data-level="15.2.1" data-path="appendix-a-review-of-statistical-inference.html"><a href="appendix-a-review-of-statistical-inference.html#estimasi-metode-momen"><i class="fa fa-check"></i><b>15.2.1</b> Estimasi Metode Momen</a></li>
<li class="chapter" data-level="15.2.2" data-path="appendix-a-review-of-statistical-inference.html"><a href="appendix-a-review-of-statistical-inference.html#estimasi-maksimum-likelihood"><i class="fa fa-check"></i><b>15.2.2</b> Estimasi Maksimum Likelihood</a></li>
</ul></li>
<li class="chapter" data-level="15.3" data-path="appendix-a-review-of-statistical-inference.html"><a href="appendix-a-review-of-statistical-inference.html#estimasi-interval"><i class="fa fa-check"></i><b>15.3</b> Estimasi Interval</a>
<ul>
<li class="chapter" data-level="15.3.1" data-path="appendix-a-review-of-statistical-inference.html"><a href="appendix-a-review-of-statistical-inference.html#distribusi-tepat-untuk-rata-rata-sampel-normal"><i class="fa fa-check"></i><b>15.3.1</b> Distribusi Tepat untuk Rata-rata Sampel Normal</a></li>
<li class="chapter" data-level="15.3.2" data-path="appendix-a-review-of-statistical-inference.html"><a href="appendix-a-review-of-statistical-inference.html#properti-sampel-besar-dari-estimasi-maksimum-likelihood"><i class="fa fa-check"></i><b>15.3.2</b> Properti Sampel Besar dari Estimasi Maksimum Likelihood</a></li>
<li class="chapter" data-level="15.3.3" data-path="appendix-a-review-of-statistical-inference.html"><a href="appendix-a-review-of-statistical-inference.html#interval-kepercayaan"><i class="fa fa-check"></i><b>15.3.3</b> Interval Kepercayaan</a></li>
</ul></li>
<li class="chapter" data-level="15.4" data-path="appendix-a-review-of-statistical-inference.html"><a href="appendix-a-review-of-statistical-inference.html#pengujian-hipotesis"><i class="fa fa-check"></i><b>15.4</b> Pengujian Hipotesis</a>
<ul>
<li class="chapter" data-level="15.4.1" data-path="appendix-a-review-of-statistical-inference.html"><a href="appendix-a-review-of-statistical-inference.html#konsep-dasar-1"><i class="fa fa-check"></i><b>15.4.1</b> Konsep Dasar</a></li>
<li class="chapter" data-level="15.4.2" data-path="appendix-a-review-of-statistical-inference.html"><a href="appendix-a-review-of-statistical-inference.html#uji-student-t-berdasarkan-estimasi-maksimum-likelihood-mle"><i class="fa fa-check"></i><b>15.4.2</b> Uji Student-t berdasarkan Estimasi Maksimum Likelihood (MLE)</a></li>
<li class="chapter" data-level="15.4.3" data-path="appendix-a-review-of-statistical-inference.html"><a href="appendix-a-review-of-statistical-inference.html#uji-rasio-kemungkinan-likelihood-ratio-test"><i class="fa fa-check"></i><b>15.4.3</b> Uji Rasio Kemungkinan (Likelihood Ratio Test)</a></li>
<li class="chapter" data-level="15.4.4" data-path="appendix-a-review-of-statistical-inference.html"><a href="appendix-a-review-of-statistical-inference.html#kriteria-informasi"><i class="fa fa-check"></i><b>15.4.4</b> Kriteria Informasi</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="16" data-path="appendix-b-iterated-expectations.html"><a href="appendix-b-iterated-expectations.html"><i class="fa fa-check"></i><b>16</b> Appendix B: Iterated Expectations</a>
<ul>
<li class="chapter" data-level="16.1" data-path="appendix-b-iterated-expectations.html"><a href="appendix-b-iterated-expectations.html#conditional-distribution-and-conditional-expectation"><i class="fa fa-check"></i><b>16.1</b> Conditional Distribution and Conditional Expectation</a>
<ul>
<li class="chapter" data-level="16.1.1" data-path="appendix-b-iterated-expectations.html"><a href="appendix-b-iterated-expectations.html#conditional-distribution"><i class="fa fa-check"></i><b>16.1.1</b> Conditional Distribution</a></li>
<li class="chapter" data-level="16.1.2" data-path="appendix-b-iterated-expectations.html"><a href="appendix-b-iterated-expectations.html#conditional-expectation-and-conditional-variance"><i class="fa fa-check"></i><b>16.1.2</b> Conditional Expectation and Conditional Variance</a></li>
</ul></li>
<li class="chapter" data-level="16.2" data-path="appendix-b-iterated-expectations.html"><a href="appendix-b-iterated-expectations.html#iterated-expectations-and-total-varians"><i class="fa fa-check"></i><b>16.2</b> Iterated Expectations and Total Varians</a>
<ul>
<li class="chapter" data-level="16.2.1" data-path="appendix-b-iterated-expectations.html"><a href="appendix-b-iterated-expectations.html#law-of-iterated-expectations"><i class="fa fa-check"></i><b>16.2.1</b> Law of Iterated Expectations</a></li>
<li class="chapter" data-level="16.2.2" data-path="appendix-b-iterated-expectations.html"><a href="appendix-b-iterated-expectations.html#law-of-total-variance"><i class="fa fa-check"></i><b>16.2.2</b> Law of Total Variance</a></li>
<li class="chapter" data-level="16.2.3" data-path="appendix-b-iterated-expectations.html"><a href="appendix-b-iterated-expectations.html#application"><i class="fa fa-check"></i><b>16.2.3</b> Application</a></li>
</ul></li>
<li class="chapter" data-level="16.3" data-path="appendix-b-iterated-expectations.html"><a href="appendix-b-iterated-expectations.html#conjugate-distributions-1"><i class="fa fa-check"></i><b>16.3</b> Conjugate Distributions</a>
<ul>
<li class="chapter" data-level="16.3.1" data-path="appendix-b-iterated-expectations.html"><a href="appendix-b-iterated-expectations.html#linear-exponential-family"><i class="fa fa-check"></i><b>16.3.1</b> Linear Exponential Family</a></li>
<li class="chapter" data-level="16.3.2" data-path="appendix-b-iterated-expectations.html"><a href="appendix-b-iterated-expectations.html#conjugate-distributions-2"><i class="fa fa-check"></i><b>16.3.2</b> Conjugate Distributions</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="17" data-path="appendix-c-maximum-likelihood-theory.html"><a href="appendix-c-maximum-likelihood-theory.html"><i class="fa fa-check"></i><b>17</b> Appendix C: Maximum Likelihood Theory</a>
<ul>
<li class="chapter" data-level="17.1" data-path="appendix-c-maximum-likelihood-theory.html"><a href="appendix-c-maximum-likelihood-theory.html#likelihood-function"><i class="fa fa-check"></i><b>17.1</b> Likelihood Function</a>
<ul>
<li class="chapter" data-level="17.1.1" data-path="appendix-c-maximum-likelihood-theory.html"><a href="appendix-c-maximum-likelihood-theory.html#likelihood-and-log-likelihood-functions"><i class="fa fa-check"></i><b>17.1.1</b> Likelihood and Log-likelihood Functions</a></li>
<li class="chapter" data-level="17.1.2" data-path="appendix-c-maximum-likelihood-theory.html"><a href="appendix-c-maximum-likelihood-theory.html#properties-of-likelihood-functions"><i class="fa fa-check"></i><b>17.1.2</b> Properties of Likelihood Functions</a></li>
</ul></li>
<li class="chapter" data-level="17.2" data-path="appendix-c-maximum-likelihood-theory.html"><a href="appendix-c-maximum-likelihood-theory.html#maximum-likelihood-estimators"><i class="fa fa-check"></i><b>17.2</b> Maximum Likelihood Estimators</a>
<ul>
<li class="chapter" data-level="17.2.1" data-path="appendix-c-maximum-likelihood-theory.html"><a href="appendix-c-maximum-likelihood-theory.html#definition-and-derivation-of-mle"><i class="fa fa-check"></i><b>17.2.1</b> Definition and Derivation of MLE</a></li>
<li class="chapter" data-level="17.2.2" data-path="appendix-c-maximum-likelihood-theory.html"><a href="appendix-c-maximum-likelihood-theory.html#asymptotic-properties-of-mle"><i class="fa fa-check"></i><b>17.2.2</b> Asymptotic Properties of MLE</a></li>
<li class="chapter" data-level="17.2.3" data-path="appendix-c-maximum-likelihood-theory.html"><a href="appendix-c-maximum-likelihood-theory.html#use-of-maximum-likelihood-estimation"><i class="fa fa-check"></i><b>17.2.3</b> Use of Maximum Likelihood Estimation</a></li>
</ul></li>
<li class="chapter" data-level="17.3" data-path="appendix-c-maximum-likelihood-theory.html"><a href="appendix-c-maximum-likelihood-theory.html#statistical-inference-based-on-maximum-likelihood-estimation"><i class="fa fa-check"></i><b>17.3</b> Statistical Inference Based on Maximum Likelihood Estimation</a>
<ul>
<li class="chapter" data-level="17.3.1" data-path="appendix-c-maximum-likelihood-theory.html"><a href="appendix-c-maximum-likelihood-theory.html#hypothesis-testing"><i class="fa fa-check"></i><b>17.3.1</b> Hypothesis Testing</a></li>
<li class="chapter" data-level="17.3.2" data-path="appendix-c-maximum-likelihood-theory.html"><a href="appendix-c-maximum-likelihood-theory.html#mle-and-model-validation"><i class="fa fa-check"></i><b>17.3.2</b> MLE and Model Validation</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="18" data-path="appendix-d-summary-of-distributions.html"><a href="appendix-d-summary-of-distributions.html"><i class="fa fa-check"></i><b>18</b> Appendix D: Summary of Distributions</a>
<ul>
<li class="chapter" data-level="18.1" data-path="appendix-d-summary-of-distributions.html"><a href="appendix-d-summary-of-distributions.html#distribusi-diskrit"><i class="fa fa-check"></i><b>18.1</b> Distribusi Diskrit</a>
<ul>
<li class="chapter" data-level="18.1.1" data-path="appendix-d-summary-of-distributions.html"><a href="appendix-d-summary-of-distributions.html#the-ab0-class-1"><i class="fa fa-check"></i><b>18.1.1</b> The <em>(a,b,0)</em> Class</a></li>
<li class="chapter" data-level="18.1.2" data-path="appendix-d-summary-of-distributions.html"><a href="appendix-d-summary-of-distributions.html#the-ab1-class"><i class="fa fa-check"></i><b>18.1.2</b> The <em>(a,b,1)</em> Class</a></li>
</ul></li>
<li class="chapter" data-level="18.2" data-path="appendix-d-summary-of-distributions.html"><a href="appendix-d-summary-of-distributions.html#continuous-distribution"><i class="fa fa-check"></i><b>18.2</b> Continuous Distribution</a>
<ul>
<li class="chapter" data-level="18.2.1" data-path="appendix-d-summary-of-distributions.html"><a href="appendix-d-summary-of-distributions.html#one-parameter-distributions"><i class="fa fa-check"></i><b>18.2.1</b> One Parameter Distributions</a></li>
<li class="chapter" data-level="18.2.2" data-path="appendix-d-summary-of-distributions.html"><a href="appendix-d-summary-of-distributions.html#two-parameter-distributions"><i class="fa fa-check"></i><b>18.2.2</b> Two Parameter Distributions</a></li>
<li class="chapter" data-level="18.2.3" data-path="appendix-d-summary-of-distributions.html"><a href="appendix-d-summary-of-distributions.html#three-parameter-distributions"><i class="fa fa-check"></i><b>18.2.3</b> Three Parameter Distributions</a></li>
<li class="chapter" data-level="18.2.4" data-path="appendix-d-summary-of-distributions.html"><a href="appendix-d-summary-of-distributions.html#four-parameter-distribution"><i class="fa fa-check"></i><b>18.2.4</b> Four Parameter Distribution</a></li>
<li class="chapter" data-level="18.2.5" data-path="appendix-d-summary-of-distributions.html"><a href="appendix-d-summary-of-distributions.html#other-distributions"><i class="fa fa-check"></i><b>18.2.5</b> Other Distributions</a></li>
<li class="chapter" data-level="18.2.6" data-path="appendix-d-summary-of-distributions.html"><a href="appendix-d-summary-of-distributions.html#distributions-with-finite-support"><i class="fa fa-check"></i><b>18.2.6</b> Distributions with Finite Support</a></li>
</ul></li>
<li class="chapter" data-level="18.3" data-path="appendix-d-summary-of-distributions.html"><a href="appendix-d-summary-of-distributions.html#limited-expected-values"><i class="fa fa-check"></i><b>18.3</b> Limited Expected Values</a></li>
</ul></li>
<li class="chapter" data-level="19" data-path="appendix-e-conventions-for-notation.html"><a href="appendix-e-conventions-for-notation.html"><i class="fa fa-check"></i><b>19</b> Appendix E: Conventions for Notation</a></li>
<li><a href="section.html#section" id="toc-section"></a></li>
<li class="chapter" data-level="" data-path="bibliography.html"><a href="bibliography.html"><i class="fa fa-check"></i>Bibliography</a></li>
<li class="divider"></li>
<li><a href="https://github.com/dsciencelabs/Analisa_Resiko" target="blank">Published with Bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Analisis Resiko</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="model-selection-and-estimation" class="section level1 hasAnchor" number="4">
<h1><span class="header-section-number">Bab 4</span> Model Selection and Estimation<a href="model-selection-and-estimation.html#model-selection-and-estimation" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<div id="nonparametric-inference" class="section level2 hasAnchor" number="4.1">
<h2><span class="header-section-number">4.1</span> Nonparametric Inference<a href="model-selection-and-estimation.html#nonparametric-inference" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Di bagian ini, Anda mempelajari cara:</p>
<ol style="list-style-type: decimal">
<li><p>Perkirakan momen, kuantil, dan distribusi tanpa mengacu pada distribusi parametrik</p></li>
<li><p>Ringkas data secara grafis tanpa mengacu pada distribusi parametrik</p></li>
<li><p>Tentukan ukuran yang meringkas penyimpangan parametrik dari kecocokan nonparametrik</p></li>
<li><p>Gunakan estimator nonparametrik untuk memperkirakan parameter yang dapat digunakan untuk memulai prosedur estimasi parametrik</p></li>
</ol>
<div id="estimasi-nonparametrik" class="section level3 hasAnchor" number="4.1.1">
<h3><span class="header-section-number">4.1.1</span> Estimasi Nonparametrik<a href="model-selection-and-estimation.html#estimasi-nonparametrik" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Pada bagian pembahasan sebelumnya telah mempelajari cara meringkas distribusi dengan cara menghitung, varians, kuantil/persentil, dan sebagainya. Untuk memperkirakan langkah-langkah ringkasan menggunakan kumpulan data, salah satu strateginya adalah:</p>
<ol style="list-style-type: decimal">
<li><p>menganggap bentuk parametrik untuk distribusi, seperti binomial negatif untuk frekuensi atau distribusi gamma untuk tingkat keparahan,</p></li>
<li><p>memperkirakan parameter distribusi itu,</p></li>
<li><p>gunakan distribusi dengan estimasi parameter untuk menghitung ukuran ringkasan yang diinginkan.</p></li>
</ol>
<p>Ini adalah <em>pendekatan parametrik</em> . Strategi lain adalah memperkirakan ukuran ringkasan yang diinginkan langsung dari pengamatan tanpa mengacu pada model parametrik. Tidak mengherankan, ini dikenal sebagai pendekatan nonparametrik</p>
<p>mempertimbangkan jenis skema pengambilan sampel yang paling dasar dan mengasumsikan bahwa observasi adalah realisasi dari serangkaian variabel acak <span class="math inline">\(X_1, \ldots, X_n\)</span> yang iid menarik dari distribusi populasi yang tidak diketahui <span class="math inline">\(F( ⋅ )\)</span>. Cara yang setara untuk mengatakan ini adalah itu <span class="math inline">\(X_1, \ldots, X_n\)</span>, adalah sampel acak (dengan penggantian) dari F( ⋅) .Kemudian menjelaskan estimator nonparametrik dari banyak ukuran penting yang meringkas sebuah distribusi.</p>
<div id="estimator-momen" class="section level4 hasAnchor" number="4.1.1.1">
<h4><span class="header-section-number">4.1.1.1</span> Estimator Momen<a href="model-selection-and-estimation.html#estimator-momen" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Pada bagian 2.2.2. telah mendefinisikan momen untuk frekuensi dan pada bagian 3.1.1 untuk keparahan. Secara khusus, k -momen ke-, <span class="math inline">\(\mathrm{E~}[X^k] = \mu^{\prime}_k\)</span> , merangkum banyak aspek distribusi untuk berbagai pilihan k . Di Sini, μ′k kadang-kadang disebut k th momen populasi untuk membedakannya dari k momen sampel,</p>
<p><span class="math display">\[\frac{1}{n} \sum_{i=1}^n X_i^k ,\]</span></p>
<p>yang merupakan estimator nonparametrik yang sesuai. Dalam aplikasi tipikal, k adalah bilangan bulat positif, meskipun tidak perlu dalam teori.</p>
<p>Kasus khusus yang penting adalah momen pertama di mana <span class="math inline">\(k = 1\)</span> . Dalam hal ini, simbol prima ( <span class="math inline">\(\prime\)</span> ) dan 1 subskrip biasanya dijatuhkan dan satu digunakan <span class="math inline">\(\mu=\mu^{\prime}_1\)</span> untuk menunjukkan mean populasi, atau hanya mean . Estimator sampel yang sesuai untuk <span class="math inline">\(μ\)</span> disebut rata-rata sampel , dilambangkan dengan bilah di atas variabel acak:</p>
<p><span class="math display">\[\overline{X} =\frac{1}{n} \sum_{i=1}^n X_i .\]</span></p>
<p>Jenis ringkasan ukuran minat lainnya adalah k -momen pusat ke- , <span class="math inline">\(\mathrm{E~} [(X-\mu)^k] = \mu_k\)</span> . (Kadang-kadang, <span class="math inline">\(\mu^{\prime}_k\)</span> disebut k -th momen mentah untuk membedakannya dari momen sentral μk .). Estimator nonparametrik, atau sampel, dari <span class="math inline">\(\mu_k\)</span> adalah</p>
<p><span class="math display">\[\frac{1}{n} \sum_{i=1}^n \left(X_i - \overline{X}\right)^k .\]</span></p>
<p>Momen pusat kedua ( <span class="math inline">\(k = 2\)</span> ) adalah kasus penting yang biasanya akan diberikan simbol baru, <span class="math inline">\(\sigma^2 = \mathrm{E~} [(X-\mu)^2]\)</span> , dikenal sebagai varians . Sifat penduga momen sampel dari varians seperti <span class="math inline">\(n^{-1}\sum_{i=1}^n \left(X_i - \overline{X}\right)^2\)</span> telah dipelajari secara ekstensif tetapi bukan satu-satunya estimator yang mungkin. Versi yang paling banyak digunakan adalah versi di mana ukuran sampel efektif dikurangi satu, jadi kami mendefinisikannya</p>
<p><span class="math display">\[s^2 = \frac{1}{n-1} \sum_{i=1}^n \left(X_i - \overline{X}\right)^2.\]</span></p>
<p>Membagi dengan <span class="math inline">\(n − 1\)</span> alih-alih N masalah kecil ketika Anda memiliki ukuran sampel yang besar <span class="math inline">\(N\)</span> seperti yang umum dalam aplikasi asuransi. Estimator varians sampel <span class="math inline">\(s^2\)</span> tidak memihak dalam arti bahwa <span class="math inline">\(\mathrm{E~} [s^2] = \sigma^2\)</span> , properti yang diinginkan terutama saat menginterpretasikan hasil analisis.</p>
</div>
<div id="fungsi-distribusi-empiris" class="section level4 hasAnchor" number="4.1.1.2">
<h4><span class="header-section-number">4.1.1.2</span> Fungsi Distribusi Empiris<a href="model-selection-and-estimation.html#fungsi-distribusi-empiris" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Kita telah melihat bagaimana menghitung estimator nonparametrik dari k saat ini <span class="math inline">\(\mathrm{E~} [X^k]\)</span> . Dengan cara yang sama, untuk fungsi apa pun yang diketahui g (⋅) , kita dapat memperkirakan <span class="math inline">\(\mathrm{E~} [\mathrm{g}(X)]\)</span> menggunakan<span class="math inline">\(n^{-1}\sum_{i=1}^n \mathrm{g}(X_i)\)</span></p>
<p>Sekarang perhatikan fungsinya <span class="math inline">\(\mathrm{g}(X) = I(X \le x)\)</span> untuk tetap <span class="math inline">\(X\)</span> . Di sini, notasi $I( ⋅ <span class="math inline">\() adalah fungsi indikator ; itu mengembalikan 1 jika acara ( ⋅ ) benar dan 0 sebaliknya. Perhatikan bahwa sekarang variabel acak\)</span> g (X$) memiliki distribusi Bernoulli (distribusi binomial dengan <span class="math inline">\(n = 1\)</span> ). Kita dapat menggunakan distribusi ini untuk dengan mudah menghitung jumlah seperti rata-rata dan varians. Misalnya, untuk pilihan ini <span class="math inline">\(g (⋅)\)</span> , nilai harapannya adalah <span class="math inline">\(\mathrm{E~} [I(X \le x)] = \Pr(X \le x) = F(x)\)</span> , fungsi distribusi dievaluasi pada <span class="math inline">\(X\)</span> . Menggunakan prinsip analog , kami mendefinisikan estimator nonparametrik dari fungsi distribusi</p>
<p><span class="math display">\[
\begin{aligned}
F_n(x)
&amp;=  \frac{1}{n} \sum_{i=1}^n I\left(X_i \le x\right) \\
&amp;=  \frac{\text{number of observations less than or equal to }x}{n} .
\end{aligned}
\]</span></p>
<p>Sebagai $F_N( ⋅ $) didasarkan hanya pada pengamatan dan tidak mengasumsikan keluarga parametrik untuk distribusi, itu nonparametrik dan juga dikenal sebagai fungsi distribusi empiris . Ia juga dikenal sebagai fungsi distribusi kumulatif empiris dan, dalam <em>R</em>, seseorang dapat menggunakan <em>ecdf(.)</em> fungsi tersebut untuk menghitungnya.</p>
<p><em>Contoh 4.1.1.</em> Kumpulan Data Mainan . Sebagai ilustrasi, pertimbangkan kumpulan data fiktif, atau “mainan”. <span class="math inline">\(n = 10\)</span>
observasi. Tentukan fungsi distribusi empiris.</p>
<p><span class="math display">\[
{\small
\begin{array}{c|cccccccccc}
\hline
i &amp;1&amp;2&amp;3&amp;4&amp;5&amp;6&amp;7&amp;8&amp;9&amp;10 \\
X_i&amp; 10 &amp;15 &amp;15 &amp;15 &amp;20 &amp;23 &amp;23 &amp;23 &amp;23 &amp;30\\
\hline
\end{array}
}\]</span></p>
<p>Kemudian memeriksa bahwa rata-rata sampel adalah <span class="math inline">\(\overline{X} = 19.7\)</span> dan bahwa varians sampel adalah <span class="math inline">\(S^2= 34,45556\)</span> . Fungsi distribusi empiris yang sesuai adalah</p>
<p><span class="math display">\[
\begin{aligned}
F_n(x) &amp;=
\left\{
\begin{array}{ll}
0 &amp; \text{ for }\ x&lt;10 \\
0.1 &amp; \text{ for }\ 10 \leq x&lt;15 \\
0.4 &amp; \text{ for }\ 15 \leq x&lt;20 \\
0.5 &amp; \text{ for }\ 20 \leq x&lt;23 \\
0.9 &amp; \text{ for }\ 23 \leq x&lt;30 \\
1 &amp; \text{ for }\ x \geq 30,
\end{array}
\right.\end{aligned}\]</span></p>
<div class="sourceCode" id="cb9"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb9-1"><a href="model-selection-and-estimation.html#cb9-1" aria-hidden="true" tabindex="-1"></a>(xExample <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">10</span>,<span class="fu">rep</span>(<span class="dv">15</span>,<span class="dv">3</span>),<span class="dv">20</span>,<span class="fu">rep</span>(<span class="dv">23</span>,<span class="dv">4</span>),<span class="dv">30</span>))</span>
<span id="cb9-2"><a href="model-selection-and-estimation.html#cb9-2" aria-hidden="true" tabindex="-1"></a>PercentilesxExample <span class="ot">&lt;-</span> <span class="fu">ecdf</span>(xExample)</span>
<span id="cb9-3"><a href="model-selection-and-estimation.html#cb9-3" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(PercentilesxExample, <span class="at">main=</span><span class="st">&quot;&quot;</span>,<span class="at">xlab=</span><span class="st">&quot;x&quot;</span>)</span></code></pre></div>
</div>
<div id="quartiles-percentiles-and-quantiles" class="section level4 hasAnchor" number="4.1.1.3">
<h4><span class="header-section-number">4.1.1.3</span> Quartiles, Percentiles and Quantiles<a href="model-selection-and-estimation.html#quartiles-percentiles-and-quantiles" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Pada bagian 3.1.1 median , yaitu angka yang kira-kira setengah dari kumpulan data berada di bawah (atau di atasnya) . Kuartil pertama adalah angka yang kira-kira 25% datanya berada di bawahnya dan kuartil ketiga adalah angka yang kira-kira 75% datanya berada di bawahnya. 100 hal persentil adalah angka sehingga <span class="math inline">\(100×p\)</span> persen dari data di bawahnya.</p>
<p>Untuk menggeneralisasi konsep ini, pertimbangkan fungsi distribusi <span class="math inline">\(F(⋅\)</span>) , yang mungkin kontinu atau tidak, dan biarkan Q menjadi pecahan sehingga <span class="math inline">\(0 &lt; q&lt; 1\)</span> . Kami ingin mendefinisikan quantile , katakanlah <span class="math inline">\(q_F\)</span> , menjadi bilangan sedemikian sehingga <span class="math inline">\(F(q_F) \approx q\)</span> . Perhatikan bahwa ketika <span class="math inline">\(q=0.5\)</span> , <span class="math inline">\(q_F\)</span> adalah median; Kapan <span class="math inline">\(q=0.25\)</span> , <span class="math inline">\(q_F\)</span> adalah kuartil pertama, dan seterusnya. Dengan cara yang sama, ketika <span class="math inline">\(q = 0, 0.01, 0.02, \ldots, 0.99, 1.00\)</span> , yang dihasilkan QF adalah persentil. Jadi, kuantil menggeneralisasikan konsep median, kuartil, dan persentil.</p>
<p>Lebih tepatnya, untuk diberikan <span class="math inline">\(0 &lt; q&lt; 1\)</span> , tentukan q kuantil <span class="math inline">\(q_F\)</span> untuk menjadi nomor yang memenuhi:</p>
<p><span class="math display">\[
\begin{equation}
F(q_F-) \le q \le F(q_F)
\tag{4.1}
\end{equation}\]</span></p>
<p>Untuk mendapatkan pemahaman yang lebih baik tentang definisi ini, mari kita lihat beberapa kasus khusus. Pertama, pertimbangkan kasus di mana X adalah variabel acak kontinu sehingga fungsi distribusi <span class="math inline">\(F(⋅)\)</span> tidak memiliki titik lompatan, seperti yang diilustrasikan pada Gambar 4.2 . Pada gambar ini, beberapa pecahan, Q1 , Q2 , Dan Q3 ditunjukkan dengan kuantil yang sesuai <span class="math inline">\(q_{F,1} , q_{F,2} , dan q_{F,3}\)</span> . Dalam setiap kasus, dapat dilihat bahwa <span class="math inline">\(F(q_F-)= F(q_F)\)</span> sehingga ada kuantil unik. Karena kita dapat menemukan invers unik dari fungsi distribusi di mana saja <span class="math inline">\(0 &lt; q&lt; 1\)</span> , kita bisa menulis <span class="math inline">\(q_F= F^{-1}(q)\)</span></p>
<p>Gambar 4.3 menunjukkan tiga kasus untuk fungsi distribusi. Panel kiri sesuai dengan kasus kontinu yang baru saja dibahas. Panel tengah menampilkan titik lompatan yang serupa dengan yang telah kita lihat dalam fungsi distribusi empiris Gambar 4.1 . Untuk nilai <span class="math inline">\(q\)</span> ditampilkan di panel ini, kami masih memiliki nilai kuantil yang unik <span class="math inline">\(q_F\)</span> . Meskipun ada banyak nilai Q seperti yang <span class="math inline">\(F(q_F-) \le q \le F(q_F)\)</span> , untuk nilai tertentu dari <span class="math inline">\(q\)</span> , hanya ada satu solusi untuk persamaan (4.1) . Panel kanan menggambarkan situasi di mana kuantil tidak dapat ditentukan secara unik untuk <span class="math inline">\(q\)</span> ditampilkan karena ada berbagai <span class="math inline">\(q_F\)</span> persamaan yang memuaskan (4.1) .</p>
<p><em>Contoh 4.1.2. Kumpulan Data Mainan: Lanjutan.</em> Tentukan kuantil yang sesuai dengan persentil ke-20, ke-50, dan ke-95.</p>
<p>Solusi . Perhatikan Gambar 4.1 . Kasus <span class="math inline">\(q=0.20\)</span> sesuai dengan panel tengah Gambar Gambar 4.3 , jadi persentil ke-20 adalah 15. Kasus <span class="math inline">\(q=0.50\)</span> sesuai dengan panel kanan, jadi mediannya adalah angka antara 20 dan 23 inklusif. Banyak paket perangkat lunak menggunakan rata-rata 21,5 (misalnya R, seperti yang terlihat di bawah). Untuk persentil ke-95, solusinya adalah 30. Kita dapat melihat dari Gambar 4.1 bahwa 30 juga sesuai dengan persentil ke-99 dan ke-99,99.</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb10-1"><a href="model-selection-and-estimation.html#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="fu">quantile</span>(xExample, <span class="at">probs=</span><span class="fu">c</span>(<span class="fl">0.2</span>, <span class="fl">0.5</span>, <span class="fl">0.95</span>), <span class="at">type=</span><span class="dv">6</span>)</span></code></pre></div>
<p>Dengan mengambil rata-rata tertimbang antara pengamatan data, kuantil empiris yang dihaluskan dapat menangani kasus seperti panel kanan pada Gambar 4.3 . Itu Q kuantil empiris yang dihaluskan didefinisikan sebagai</p>
<p><span class="math display">\[\hat{\pi}_q = (1-h) X_{(j)} + h X_{(j+1)}\]</span></p>
<p>Di mana <span class="math inline">\(j=\lfloor(n+1)q\rfloor\)</span> , Dan<span class="math inline">\(X_{(1)}, \ldots, X_{(n)}\)</span> adalah nilai yang diurutkan (dikenal sebagai statistik urutan ) yang sesuai dengan <span class="math inline">\(X_1, \ldots, X_n\)</span>. (Ingat bahwa tanda kurung ⌊ ⋅ ⌋ adalah fungsi lantai yang menunjukkan nilai bilangan bulat terbesar.) Perhatikan bah wa <span class="math inline">\(\hat{\pi}_q\)</span>$ hanyalah sebuah interpolasi linear antara <span class="math inline">\(X_{( j )}\)</span> dan <span class="math inline">\(X_{(j+1)}\)</span>.</p>
<p><em>Contoh 4.1.3. Kumpulan Data Mainan: Lanjutan.</em> Tentukan persentil yang dihaluskan ke-50 dan ke-20.</p>
<p>Solusi Ambil <span class="math inline">\(n = 10\)</span> Dan <span class="math inline">\(q= 0,5\)</span>. Kemudian, <span class="math inline">\(j=\lfloor(11)(0.5) \rfloor= \lfloor 5.5 \rfloor=5\)</span>, . Maka kuantil empiris yang dihaluskan ke-0,5 adalah</p>
<p><span class="math display">\[\hat{\pi}_{0.5} = (1-0.5) X_{(5)} + (0.5) X_{(6)} = 0.5 (20) + (0.5)(23) = 21.5.\]</span></p>
<p>Sekarang ambil <span class="math inline">\(n = 10\)</span> Dan <span class="math inline">\(q= 0,2\)</span> . Pada kasus ini, <span class="math inline">\(j=\lfloor(11)(0.2)\rfloor=\lfloor 2.2 \rfloor=2\)</span> . Maka kuantil empiris yang dihaluskan ke-0,2 adalah</p>
<p><span class="math display">\[\hat{\pi}_{0.2} = (1-0.2) X_{(2)} + (0.2) X_{(3)} = 0.8 (15) + (0.2)(15) = 15.\]</span></p>
</div>
<div id="penduga-kepadatan" class="section level4 hasAnchor" number="4.1.1.4">
<h4><span class="header-section-number">4.1.1.4</span> Penduga Kepadatan<a href="model-selection-and-estimation.html#penduga-kepadatan" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p><em>Variabel Diskrit</em>. Ketika variabel acak adalah diskrit, memperkirakan fungsi massa probabilitas <span class="math inline">\(f(x) = \Pr(X=x)\)</span> mudah. Kami hanya menggunakan rata-rata sampel, yang didefinisikan sebagai</p>
<p><span class="math display">\[f_n(x) = \frac{1}{n} \sum_{i=1}^n I(X_i = x),\]</span></p>
<p>yang merupakan proporsi sampel sama dengan X</p>
<p><em>Variabel Berkelanjutan dalam Grup.</em> Untuk variabel acak kontinu, pertimbangkan formulasi diskrit di mana domain dari F( ⋅ ) dipartisi oleh konstanta <span class="math inline">\(\{c_0 &lt; c_1 &lt; \cdots &lt; c_k\}\)</span> ke dalam interval bentuk <span class="math inline">\([c_{j-1}, c_j)\)</span> , untuk <span class="math inline">\(j=1, \ldots, k\)</span> . Pengamatan data dengan demikian “dikelompokkan” berdasarkan interval di mana mereka jatuh. Kemudian, kita dapat menggunakan definisi dasar dari fungsi massa empiris, atau variasi seperti</p>
<p><span class="math display">\[f_n(x) = \frac{n_j}{n \times (c_j - c_{j-1})}  \ \ \ \ \ \ c_{j-1} \le x &lt; c_j,\]</span></p>
<p>Di mana <span class="math inline">\(N_J\)</span> adalah jumlah pengamatan ( <span class="math inline">\(X_i\)</span> ) yang termasuk dalam interval <span class="math inline">\([c_{j-1}, c_j)\)</span>.</p>
<p>Variabel Berkelanjutan (tidak dikelompokkan). Memperluas gagasan ini ke contoh di mana kami mengamati data individual, perhatikan bahwa kami selalu dapat membuat pengelompokan arbitrer dan menggunakan rumus ini. Lebih formal, biarkan <span class="math inline">\(b &gt; 0\)</span> menjadi konstanta positif kecil, yang dikenal sebagai bandwidth , dan menentukan penaksir kepadatan menjadi</p>
<p><span class="math display">\[\begin{equation}
f_n(x) = \frac{1}{2nb} \sum_{i=1}^n I(x-b &lt; X_i \le x + b)
\tag{4.2}
\end{equation}\]</span></p>
<p>Secara lebih umum, tentukan penaksir kerapatan kernel dari pdf di X sebagai</p>
<p><span class="math display">\[\begin{equation}
f_n(x) = \frac{1}{nb} \sum_{i=1}^n w\left(\frac{x-X_i}{b}\right) ,
\tag{4.3}
\end{equation}\]</span></p>
<p>Di mana w adalah fungsi kerapatan probabilitas yang berpusat di sekitar 0. Perhatikan bahwa persamaan (4.2) adalah kasus khusus penduga kerapatan kernel di mana <span class="math inline">\(w(x) = \frac{1}{2}I(-1 &lt; x \le 1)\)</span> , juga dikenal sebagai kernel seragam . Pilihan populer lainnya ditunjukkan pada Tabel 4.1 .</p>
<p><span class="math display">\[{\small
\begin{matrix}
\begin{array}{l|cc}
\hline
\text{Kernel} &amp;  w(x) \\
\hline
\text{Uniform } &amp;  \frac{1}{2}I(-1 &lt; x \le 1) \\
\text{Triangle} &amp;  (1-|x|)\times I(|x| \le 1) \\
\text{Epanechnikov} &amp; \frac{3}{4}(1-x^2) \times I(|x| \le 1) \\
\text{Gaussian} &amp; \phi(x) \\
\hline
\end{array}\end{matrix}
}\]</span></p>
<p>Di Sini, <span class="math inline">\(\phi(\cdot)\)</span> adalah fungsi kepadatan normal standar. Seperti yang akan kita lihat pada contoh berikut, pilihan bandwidth <span class="math inline">\(B\)</span> hadir dengan tradeoff bias-varians antara mencocokkan fitur distribusi lokal dan mengurangi volatilitas.</p>
<p><em>Contoh 4.1.4. Dana Properti.</em> Gambar 4.4 menunjukkan histogram (dengan persegi panjang abu-abu yang diarsir) dari klaim properti logaritmik dari tahun 2010. Kurva tebal (biru) mewakili kerapatan kernel Gaussian di mana bandwidth dipilih secara otomatis menggunakan aturan ad hoc berdasarkan ukuran sampel dan volatilitas data ini . Untuk dataset ini, bandwidth ternyata b = 0,3255 . Sebagai perbandingan, kurva putus-putus (merah) menunjukkan penaksir densitas dengan lebar pita sama dengan 0,1 dan kurva halus berwarna hijau menggunakan lebar pita 1. Sebagaimana diantisipasi, lebar pita yang lebih kecil (0,1) menunjukkan mengambil rata-rata lokal dengan data yang lebih sedikit sehingga kita mendapatkan ide yang lebih baik dari rata-rata lokal, tetapi dengan harga volatilitas yang lebih tinggi. Sebaliknya, bandwidth yang lebih besar (1) memperhalus fluktuasi lokal, menghasilkan kurva yang lebih halus yang mungkin melewatkan gangguan pada rata-rata lokal. Untuk aplikasi aktuaria, kami terutama menggunakan estimator densitas kernel untuk mendapatkan kesan visual cepat dari data. Dari perspektif ini, Anda cukup menggunakan aturan ad hoc default untuk pemilihan bandwidth, mengetahui bahwa Anda memiliki kemampuan untuk mengubahnya tergantung pada situasi yang dihadapi.</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb11-1"><a href="model-selection-and-estimation.html#cb11-1" aria-hidden="true" tabindex="-1"></a>ClaimLev <span class="ot">&lt;-</span> <span class="fu">read.csv</span>(<span class="st">&quot;Data/CLAIMLEVEL.csv&quot;</span>, <span class="at">header=</span><span class="cn">TRUE</span>); <span class="co">#nrow(ClaimLev); # 6258</span></span>
<span id="cb11-2"><a href="model-selection-and-estimation.html#cb11-2" aria-hidden="true" tabindex="-1"></a>ClaimData<span class="ot">&lt;-</span><span class="fu">subset</span>(ClaimLev,Year<span class="sc">==</span><span class="dv">2010</span>);     <span class="co">#2010 subset</span></span>
<span id="cb11-3"><a href="model-selection-and-estimation.html#cb11-3" aria-hidden="true" tabindex="-1"></a><span class="co">#Density Comparison</span></span>
<span id="cb11-4"><a href="model-selection-and-estimation.html#cb11-4" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span>(<span class="fu">log</span>(ClaimData<span class="sc">$</span>Claim), <span class="at">main=</span><span class="st">&quot;&quot;</span>, <span class="at">ylim=</span><span class="fu">c</span>(<span class="dv">0</span>,.<span class="dv">35</span>),<span class="at">xlab=</span><span class="st">&quot;Log Expenditures&quot;</span>, <span class="at">freq=</span><span class="cn">FALSE</span>, <span class="at">col=</span><span class="st">&quot;lightgray&quot;</span>)</span>
<span id="cb11-5"><a href="model-selection-and-estimation.html#cb11-5" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(<span class="fu">density</span>(<span class="fu">log</span>(ClaimData<span class="sc">$</span>Claim)), <span class="at">col=</span><span class="st">&quot;blue&quot;</span>,<span class="at">lwd=</span><span class="fl">2.5</span>)</span>
<span id="cb11-6"><a href="model-selection-and-estimation.html#cb11-6" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(<span class="fu">density</span>(<span class="fu">log</span>(ClaimData<span class="sc">$</span>Claim), <span class="at">bw=</span><span class="dv">1</span>), <span class="at">col=</span><span class="st">&quot;green&quot;</span>)</span>
<span id="cb11-7"><a href="model-selection-and-estimation.html#cb11-7" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(<span class="fu">density</span>(<span class="fu">log</span>(ClaimData<span class="sc">$</span>Claim), <span class="at">bw=</span>.<span class="dv">1</span>), <span class="at">col=</span><span class="st">&quot;red&quot;</span>, <span class="at">lty=</span><span class="dv">3</span>)</span>
<span id="cb11-8"><a href="model-selection-and-estimation.html#cb11-8" aria-hidden="true" tabindex="-1"></a><span class="fu">legend</span>(<span class="st">&quot;topright&quot;</span>, <span class="fu">c</span>(<span class="st">&quot;b=0.3255 (default)&quot;</span>, <span class="st">&quot;b=0.1&quot;</span>, <span class="st">&quot;b=1.0&quot;</span>), <span class="at">lty=</span><span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">3</span>,<span class="dv">1</span>), <span class="at">lwd=</span><span class="fu">c</span>(<span class="fl">2.5</span>,<span class="dv">1</span>,<span class="dv">1</span>),</span>
<span id="cb11-9"><a href="model-selection-and-estimation.html#cb11-9" aria-hidden="true" tabindex="-1"></a>       <span class="at">col=</span><span class="fu">c</span>(<span class="st">&quot;blue&quot;</span>, <span class="st">&quot;red&quot;</span>, <span class="st">&quot;green&quot;</span>), <span class="at">cex=</span><span class="dv">1</span>)</span>
<span id="cb11-10"><a href="model-selection-and-estimation.html#cb11-10" aria-hidden="true" tabindex="-1"></a><span class="co">#density(log(ClaimData$Claim))$bw   ##default bandwidth</span></span></code></pre></div>
<p>Estimator densitas nonparametrik, seperti estimator kernel, sering digunakan dalam praktik. Konsep ini juga dapat diperluas untuk memberikan versi halus dari fungsi distribusi empiris. Mengingat definisi penaksir densitas kernel, penaksir kernel dari fungsi distribusi dapat ditemukan sebagai</p>
<p><span class="math display">\[\begin{aligned}
\tilde{F}_n(x) = \frac{1}{n} \sum_{i=1}^n W\left(\frac{x-X_i}{b}\right).\end{aligned}\]</span></p>
<p>Di mana <span class="math inline">\(W\)</span> adalah fungsi distribusi yang terkait dengan densitas kernel <span class="math inline">\(w\)</span> . Sebagai ilustrasi, untuk kernel yang seragam, kita punya <span class="math inline">\(w(y) = \frac{1}{2}I(-1 &lt; y \le 1)\)</span> , Jadi</p>
<p><span class="math display">\[\begin{aligned}
W(y) =
\begin{cases}
0 &amp;            y&lt;-1\\
\frac{y+1}{2}&amp; -1 \le y &lt; 1 \\
1 &amp; y \ge 1 \\
\end{cases}\end{aligned} .\]</span></p>
<p><em>Contoh 4.1.5. Soal Ujian Aktuaria.</em> Anda mempelajari lima nyawa untuk memperkirakan waktu dari timbulnya penyakit hingga kematian. Waktu kematian adalah:</p>
<p><span class="math display">\[\begin{array}{ccccc}
2 &amp; 3 &amp; 3 &amp; 3 &amp; 7  \\
\end{array}\]</span></p>
<p>Menggunakan kernel segitiga dengan bandwidth 2 , hitung taksiran fungsi densitas pada 2,5. Solusi. Untuk perkiraan kepadatan kernel, kami punya</p>
<p><span class="math display">\[f_n(x) = \frac{1}{nb} \sum_{i=1}^n w\left(\frac{x-X_i}{b}\right),\]</span></p>
<p>Di mana <span class="math inline">\(n = 5\)</span> , <span class="math inline">\(b = 2\)</span> , Dan <span class="math inline">\(x = 2,5\)</span> . Untuk inti segitiga, <span class="math inline">\(w(x) = (1-|x|)\times I(|x| \le 1)\)</span> . Dengan demikian,</p>
<p><span class="math display">\[\begin{array}{c|c|c}
\hline
X_i &amp; \frac{x-X_i}{b} &amp; w\left(\frac{x-X_i}{b} \right) \\
\hline
2 &amp; \frac{2.5-2}{2}=\frac{1}{4} &amp;  (1-\frac{1}{4})(1) = \frac{3}{4} \\
\hline
3 &amp; &amp; \\
3 &amp; \frac{2.5-3}{2}=\frac{-1}{4} &amp; \left(1-\left| \frac{-1}{4} \right| \right)(1) = \frac{3}{4} \\
3 &amp; &amp; \\
\hline
7 &amp; \frac{2.5-7}{2}=-2.25 &amp; (1-|-2.25|)(0) = 0\\
\hline
\end{array}\]</span></p>
<p>Kemudian perkiraan densitas kernel di <span class="math inline">\(x = 2,5\)</span> adalah</p>
<p><span class="math display">\[f_n(2.5) = \frac{1}{5(2)}\left( \frac{3}{4} + (3) \frac{3}{4} + 0 \right) = \frac{3}{10}\]</span></p>
</div>
<div id="prinsip-pengaya" class="section level4 hasAnchor" number="4.1.1.5">
<h4><span class="header-section-number">4.1.1.5</span> Prinsip Pengaya<a href="model-selection-and-estimation.html#prinsip-pengaya" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Salah satu cara untuk membuat penaksir nonparametrik dari beberapa kuantitas adalah dengan menggunakan prinsip analog atau plug-in di mana seseorang menggantikan cdf yang tidak diketahui <span class="math inline">\(F\)</span> dengan estimasi yang diketahui seperti cdf empiris <span class="math inline">\(F_N\)</span> . Jadi, jika kita mencoba memperkirakan <span class="math inline">\(\mathrm{E}~[\mathrm{g}(X)]=\mathrm{E}_F~[\mathrm{g}(X)]\)</span> untuk fungsi generik g , maka kami mendefinisikan estimator nonparametrik menjadi <span class="math inline">\(\mathrm{E}_{F_n}~[\mathrm{g}(X)]=n^{-1}\sum_{i=1}^n \mathrm{g}(X_i)\)</span>.</p>
<p>Untuk melihat cara kerjanya, sebagai kasus khusus dari g , kami menganggap kerugian per variabel acak pembayaran <span class="math inline">\(Y = (X-d)_+\)</span> dan rasio eliminasi kerugian yang diperkenalkan di Bagian 3.4.1. Kita dapat mengungkapkan ini sebagai</p>
<p><span class="math display">\[LER(d) = \frac{\mathrm{E~}[X - (X-d)_+]}{\mathrm{E~}[X]} =\frac{\mathrm{E~}[\min(X,d)]}{\mathrm{E~}[X]} ,\]</span></p>
<p><em>Contoh. 4.1.6. Klaim Cidera Tubuh dan Rasio Penghapusan Kerugian</em> Kami menggunakan sampel 432 klaim mobil tertutup dari Boston dari Derrig, Ostaszewski, dan Rempala ( 2001 ) . Kerugian dicatat untuk pembayaran karena cedera tubuh dalam kecelakaan mobil. Kerugian tidak dapat dikurangkan tetapi dibatasi oleh berbagai jumlah pertanggungan maksimum yang juga tersedia dalam data. Ternyata hanya 17 dari 432 ( ≈ 4%) tunduk pada batasan kebijakan ini sehingga kami mengabaikan data ini untuk ilustrasi ini.</p>
<p>Kerugian rata-rata yang dibayarkan adalah 6906 dalam dolar AS. Gambar 4.5 menunjukkan aspek lain dari distribusi. Secara khusus, panel sebelah kiri menunjukkan fungsi distribusi empiris, panel sebelah kanan memberikan plot kepadatan nonparametrik.</p>
<p>Dampak kerugian cedera tubuh dapat dikurangi dengan pengenaan limit atau pembelian polis reasuransi (lihat Bagian 10.3). Untuk mengukur dampak dari alat mitigasi risiko ini, biasanya menghitung rasio eliminasi kerugian (LER) seperti yang diperkenalkan di Bagian 3.4.1. Fungsi distribusi tidak tersedia sehingga harus diestimasi dengan cara tertentu. Menggunakan prinsip plug-in, estimator nonparametrik dapat didefinisikan sebagai</p>
<p><span class="math display">\[LER_n(d) = \frac{n^{-1} \sum_{i=1}^n \min(X_i,d)}{n^{-1} \sum_{i=1}^n X_i} = \frac{\sum_{i=1}^n \min(X_i,d)}{\sum_{i=1}^n X_i} .\]</span></p>
<p>Gambar 4.6 menunjukkan estimator <span class="math inline">\(LER_n(d)\)</span> untuk berbagai pilihan <span class="math inline">\(d\)</span> . Misalnya, di <span class="math inline">\(d= 1.000\)</span> dan punya <span class="math inline">\(LER_n( 1000 ) ≈ 0,1442\)</span>. Dengan demikian, memberlakukan batas 1.000 berarti ekspektasi klaim yang ditahan 14,42 persen lebih rendah bila dibandingkan dengan ekspektasi klaim dengan deductible nol.</p>
</div>
</div>
<div id="alat-untuk-pemilihan-model-dan-diagnostik" class="section level3 hasAnchor" number="4.1.2">
<h3><span class="header-section-number">4.1.2</span> Alat untuk Pemilihan Model dan Diagnostik<a href="model-selection-and-estimation.html#alat-untuk-pemilihan-model-dan-diagnostik" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Bagian sebelumnya memperkenalkan estimator nonparametrik di mana tidak ada bentuk parametrik yang diasumsikan tentang distribusi yang mendasarinya. Namun, dalam banyak aplikasi aktuaria, analis berusaha menggunakan kecocokan parametrik dari distribusi untuk kemudahan penjelasan dan kemampuan untuk memperluasnya ke situasi yang lebih kompleks seperti memasukkan variabel penjelas dalam pengaturan regresi. Saat memasang distribusi parametrik, seorang analis mungkin mencoba menggunakan distribusi gamma untuk mewakili sekumpulan data kerugian. Namun, analis lain mungkin lebih suka menggunakan distribusi Pareto. Bagaimana cara menentukan model mana yang akan dipilih?</p>
<p>Alat nonparametrik dapat digunakan untuk menguatkan pemilihan model parametrik. Pada dasarnya, pendekatannya adalah untuk menghitung langkah-langkah ringkasan yang dipilih di bawah model parametrik yang dipasang dan membandingkannya dengan kuantitas yang sesuai di bawah model nonparametrik. Karena model nonparametrik tidak mengasumsikan distribusi tertentu dan hanya merupakan fungsi dari data, model ini digunakan sebagai tolok ukur untuk menilai seberapa baik distribusi/model parametrik mewakili data. Juga, ketika ukuran sampel meningkat, distribusi empiris hampir pasti menyatu dengan distribusi populasi yang mendasarinya (berdasarkan hukum jumlah besar yang kuat). Dengan demikian distribusi empiris adalah proksi yang baik untuk populasi. Perbandingan estimator parametrik dengan nonparametrik dapat mengingatkan analis akan kekurangan dalam model parametrik dan terkadang menunjukkan cara untuk meningkatkan spesifikasi parametrik. Prosedur diarahkan menilai validitas model yang dikenal sebagaidiagnostik model .</p>
<div id="perbandingan-grafik-distribusi" class="section level4 hasAnchor" number="4.1.2.1">
<h4><span class="header-section-number">4.1.2.1</span> Perbandingan Grafik Distribusi<a href="model-selection-and-estimation.html#perbandingan-grafik-distribusi" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Kita telah melihat teknik overlay grafik untuk tujuan perbandingan. Untuk memperkuat penerapan teknik ini, Gambar 4.7membandingkan distribusi empiris dengan dua distribusi pas parametrik. Panel kiri menunjukkan fungsi distribusi distribusi klaim. Titik-titik yang membentuk kurva “berbentuk S” mewakili fungsi distribusi empiris pada setiap pengamatan. Kurva biru tebal memberikan nilai yang sesuai untuk distribusi gamma yang pas dan ungu muda untuk distribusi Pareto yang pas. Karena Pareto lebih dekat dengan fungsi distribusi empiris daripada gamma, ini memberikan bukti bahwa Pareto adalah model yang lebih baik untuk kumpulan data ini. Panel kanan memberikan informasi serupa untuk fungsi kerapatan dan memberikan pesan yang konsisten. Berdasarkan (hanya) angka-angka ini, distribusi Pareto adalah pilihan yang jelas bagi analis.</p>
<p>Untuk cara lain untuk membandingkan kesesuaian dua model yang cocok, pertimbangkan plot probabilitas-probabilitas (<span class="math inline">\(pp\)</span>) . A <span class="math display">\[pp\]</span> plot membandingkan probabilitas kumulatif di bawah dua model. Untuk tujuan kami, kedua model ini adalah fungsi distribusi empiris nonparametrik dan model pas parametrik. Gambar 4.8 menunjukkan <span class="math inline">\(pp\)</span> plot untuk data Dana Properti yang diperkenalkan di Bagian 1.3 . Gamma yang dipasang di sebelah kiri dan Pareto yang dipasang di sebelah kanan, dibandingkan dengan fungsi distribusi data empiris yang sama. Garis lurus mewakili kesetaraan antara dua distribusi yang dibandingkan, sehingga titik yang dekat dengan garis diinginkan. Seperti yang terlihat pada demonstrasi sebelumnya, Pareto jauh lebih dekat dengan distribusi empiris daripada gamma, memberikan bukti tambahan bahwa Pareto adalah model yang lebih baik.</p>
<p>Itu QQ plot membandingkan dua model yang dipasang melalui kuantilnya. Seperti hal hal plot, kami membandingkan nonparametrik dengan model pas parametrik. Kuantil dapat dievaluasi pada setiap titik kumpulan data, atau pada kisi (misalnya, di 0 , 0,001 , 0,002 , … , 0,999 , 1,000 ), tergantung aplikasinya. Pada Gambar 4.9 , untuk setiap titik pada kisi tersebut, sumbu horizontal menampilkan kuantil empiris dan sumbu vertikal menampilkan kuantil parametrik yang sesuai (gamma untuk dua panel atas, Pareto untuk dua panel bawah). Kuantil diplot pada skala asli di panel kiri dan pada skala log di panel kanan untuk memungkinkan kita melihat di mana kekurangan distribusi yang pas. Garis lurus mewakili kesetaraan antara distribusi empiris dan distribusi pas. Dari plot ini, kita sekali lagi melihat bahwa Pareto secara keseluruhan lebih cocok daripada gamma. Selain itu, panel kanan bawah menunjukkan bahwa distribusi Pareto bekerja dengan baik dengan klaim besar, tetapi memberikan kecocokan yang lebih buruk untuk klaim kecil.</p>
<p><em>Contoh 4.1.7. Soal Ujian Aktuaria.</em> Grafik di bawah ini menunjukkan <span class="math inline">\(pp\)</span> plot distribusi pas dibandingkan dengan sampel.</p>
<p>Solusi. Ekor dari distribusi yang pas terlalu tebal di sebelah kiri, terlalu tipis di sebelah kanan, dan distribusi yang pas memiliki probabilitas yang lebih kecil di sekitar median daripada sampel. Untuk melihat ini, ingat bahwa hal hal plot grafik distribusi kumulatif dari dua distribusi pada sumbunya (empiris pada sumbu x dan dipasang pada sumbu y dalam kasus ini). Untuk nilai kecil dari X , model yang dipasang memberikan probabilitas yang lebih besar untuk berada di bawah nilai itu daripada yang terjadi dalam sampel (mis F( x ) &gt;FN( x ) ). Ini menunjukkan bahwa model memiliki ekor kiri yang lebih berat daripada datanya. Untuk nilai besar dari X , model kembali memberikan probabilitas yang lebih besar untuk berada di bawah nilai itu dan dengan demikian lebih kecil kemungkinannya untuk berada di atas nilai itu (mis S( x ) &lt;SN( x ) ). Hal ini menunjukkan bahwa model memiliki ekor kanan yang lebih ringan dari pada data. Selain itu, saat kita mulai dari 0,4 hingga 0,6 pada sumbu horizontal (dengan demikian melihat 20% tengah data), hal hal plot meningkat dari sekitar 0,3 menjadi 0,4. Ini menunjukkan bahwa model hanya menempatkan sekitar 10% dari probabilitas dalam kisaran ini.</p>
</div>
<div id="perbandingan-statistik-distribusi" class="section level4 hasAnchor" number="4.1.2.2">
<h4><span class="header-section-number">4.1.2.2</span> Perbandingan Statistik Distribusi<a href="model-selection-and-estimation.html#perbandingan-statistik-distribusi" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Saat memilih model, akan sangat membantu untuk menampilkan tampilan grafis. Namun, untuk melaporkan hasil, melengkapi tampilan grafis dengan statistik terpilih yang meringkas kebaikan kesesuaian model dapat efektif. Tabel 4.2 menyediakan tiga statistik kebaikan yang umum digunakan . Dalam tabel ini, <span class="math inline">\(F_N\)</span> adalah distribusi empiris, <span class="math inline">\(F\)</span> adalah distribusi pas atau hipotesis, dan <span class="math inline">\(F_i^* = F(x_i)\)</span> .</p>
<p><span class="math display">\[{\small
\begin{matrix}
\begin{array}{l|cc}
\hline
\text{Statistic} &amp; \text{Definition} &amp; \text{Computational Expression} \\
\hline
\text{Kolmogorov-} &amp; \max_x |F_n(x) - F(x)| &amp; \max(D^+, D^-) \text{ where } \\
~~~\text{Smirnov} &amp;&amp; D^+ = \max_{i=1, \ldots, n} \left|\frac{i}{n} - F_i^*\right| \\
&amp;&amp; D^- = \max_{i=1, \ldots, n} \left| F_i^* - \frac{i-1}{n} \right| \\
\text{Cramer-von Mises} &amp; n \int (F_n(x) - F(x))^2 f(x) dx &amp; \frac{1}{12n} + \sum_{i=1}^n \left(F_i^* - (2i-1)/n\right)^2 \\
\text{Anderson-Darling} &amp; n \int \frac{(F_n(x) - F(x))^2}{F(x)(1-F(x))} f(x) dx &amp; -n-\frac{1}{n} \sum_{i=1}^n (2i-1) \log\left(F_i^*(1-F_{n+1-i})\right)^2 \\
\hline
\end{array} \\
\end{matrix}
}\]</span></p>
<p>Statistik Kolmogorov-Smirnov adalah perbedaan absolut maksimum antara fungsi distribusi yang dipasang dan fungsi distribusi empiris. Alih-alih membandingkan perbedaan antara titik tunggal, statistik Cramer-von Mises mengintegrasikan perbedaan antara fungsi distribusi empiris dan pas pada seluruh rentang nilai. Statistik Anderson-Darling juga mengintegrasikan perbedaan ini pada rentang nilai, meskipun diboboti oleh kebalikan dari varian. Oleh karena itu lebih menekankan pada ekor distribusi (yaitu kapan <span class="math inline">\(F( x )\)</span> atau <span class="math inline">\(1-F(x)=S(x)\)</span> kecil).</p>
<p><em>Contoh 4.1.8. Soal Ujian Aktuaria (dimodifikasi)</em>. Contoh pembayaran klaim adalah:</p>
<p><span class="math display">\[\begin{array}{ccccc}
29 &amp; 64 &amp; 90 &amp; 135 &amp; 182  \\
\end{array}\]</span></p>
<p>Bandingkan distribusi klaim empiris dengan distribusi eksponensial dengan rata-rata 100 dengan menghitung nilai statistik uji Kolmogorov-Smirnov.</p>
<p>Solusi. Untuk distribusi eksponensial dengan rata-rata 100 , fungsi distribusi kumulatif adalah <span class="math inline">\(F(x)=1-e^{-x/100}\)</span> . Dengan demikian,</p>
<p><span class="math display">\[\begin{array}{ccccc}
\hline
x &amp; F(x) &amp; F_n(x) &amp; F_n(x-) &amp; \max(|F(x)-F_n(x)|,|F(x)-F_n(x-)|) \\
\hline
29  &amp; 0.2517 &amp; 0.2 &amp; 0   &amp; \max(0.0517, 0.2517) = 0.2517 \\
64  &amp; 0.4727 &amp; 0.4 &amp; 0.2 &amp; \max(0.0727, 0.2727) = 0.2727 \\
90  &amp; 0.5934 &amp; 0.6 &amp; 0.4 &amp; \max(0.0066, 0.1934) = 0.1934 \\
135 &amp; 0.7408 &amp; 0.8 &amp; 0.6 &amp; \max(0.0592, 0.1408) = 0.1408 \\
182 &amp; 0.8380 &amp; 1   &amp; 0.8 &amp; \max(0.1620, 0.0380) = 0.1620 \\
\hline
\end{array}\]</span></p>
<p>Oleh karena itu, statistik uji Kolmogorov-Smirnov adalah</p>
<p><span class="math display">\[KS = \max(0.2517, 0.2727, 0.1934, 0.1408, 0.1620) = 0.2727 .\]</span></p>
</div>
</div>
<div id="nilai-awal" class="section level3 hasAnchor" number="4.1.3">
<h3><span class="header-section-number">4.1.3</span> Nilai Awal<a href="model-selection-and-estimation.html#nilai-awal" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Metode pencocokan momen dan persentil merupakan metode estimasi nonparametrik yang memberikan alternatif kemungkinan maksimum. Umumnya, kemungkinan maksimum adalah teknik yang lebih disukai karena menggunakan data secara lebih efisien. (Lihat Lampiran Bab 17 untuk definisi efisiensi yang tepat.) Namun, metode pencocokan momen dan persentil berguna karena lebih mudah diinterpretasikan dan karena itu memungkinkan aktuaris atau analis untuk menjelaskan prosedur kepada orang lain. Selain itu, prosedur estimasi numerik (misalnya jika dilakukan di <em>R</em>) untuk kemungkinan maksimum adalah iteratif dan membutuhkan nilai awal untuk memulai proses rekursif. Meskipun banyak masalah yang kuat untuk pemilihan nilai awal, untuk beberapa situasi kompleks, penting untuk memiliki nilai awal yang mendekati nilai optimal (tidak diketahui). Metode momen dan pencocokan persentil adalah teknik yang dapat menghasilkan perkiraan yang diinginkan tanpa investasi komputasi yang serius dan dengan demikian dapat digunakan sebagai nilai awal untuk menghitung kemungkinan maksimum.</p>
<div id="metode-momen" class="section level4 hasAnchor" number="4.1.3.1">
<h4><span class="header-section-number">4.1.3.1</span> Metode Momen<a href="model-selection-and-estimation.html#metode-momen" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Metode ini merupakan estimasi parameter populasi dengan pendekatan momen parametrik menggunakan momen sampel empiris. pada momen ini, momen distribusi parametrik menggunakan momen empiris atau nonparametrik kemudian dapat dipecahkan secara aljabar untuk estimasi parameter.</p>
<p><em>Contoh 4.1.9. Dana Properti.</em> Untuk dana properti 2010, ada <span class="math inline">\(n = 1 , 377\)</span> klaim individu (dalam ribuan dolar) dengan</p>
<p><span class="math display">\[m_1 = \frac{1}{n} \sum_{i=1}^n X_i = 26.62259 \ \ \ \
\text{and} \ \ \ \
m_2 = \frac{1}{n} \sum_{i=1}^n X_i^2 = 136154.6 .\]</span></p>
<p>Sesuaikan parameter distribusi gamma dan Pareto menggunakan metode momen.</p>
<p>Solusi. Agar sesuai dengan distribusi gamma, kami memiliki <span class="math inline">\(\mu_1 = \alpha \theta\)</span> Dan <span class="math inline">\(\mu_2^{\prime} = \alpha(\alpha+1) \theta^2\)</span> . Menyamakan keduanya menghasilkan metode penaksir momen, aljabar mudah menunjukkannya</p>
<p><span class="math display">\[\alpha = \frac{\mu_1^2}{\mu_2^{\prime}-\mu_1^2}  \ \ \ \text{and} \ \ \  \theta = \frac{\mu_2^{\prime}-\mu_1^2}{\mu_1}.\]</span></p>
<p>Jadi, metode penduga momen adalah</p>
<p><span class="math display">\[\begin{aligned}
\hat{\alpha} &amp;=  \frac{26.62259^2}{136154.6-26.62259^2} = 0.005232809 \\
\hat{\theta} &amp;=  \frac{136154.6-26.62259^2}{26.62259} = 5,087.629.
\end{aligned}\]</span></p>
<p>Sebagai perbandingan, nilai kemungkinan maksimum berubah menjadi <span class="math inline">\(\hat{\alpha}_{MLE} = 0.2905959\)</span> Dan <span class="math inline">\(\hat{\theta}_{MLE} = 91.61378\)</span> , jadi ada perbedaan besar antara dua prosedur estimasi. Ini adalah salah satu indikasi, seperti yang telah kita lihat sebelumnya, bahwa model gamma kurang cocok.</p>
<p>Sebaliknya, sekarang asumsikan distribusi Pareto sehingga <span class="math inline">\(\mu_1 = \theta/(\alpha -1)\)</span> Dan <span class="math inline">\(\mu_2^{\prime} = 2\theta^2/((\alpha-1)(\alpha-2) )\)</span> . Perhatikan bahwa ungkapan ini untuk μ′2 hanya berlaku untuk α &gt; 2 . Pertunjukan aljabar yang mudah</p>
<p><span class="math display">\[\alpha = 1+ \frac{\mu_2^{\prime}}{\mu_2^{\prime}-\mu_1^2} \ \ \ \
\text{and} \ \ \ \ \
\theta = (\alpha-1)\mu_1.\]</span></p>
<p>Jadi, metode penduga momen adalah</p>
<p><span class="math display">\[ \begin{aligned}
\hat{\alpha} &amp;=  1+ \frac{136154.6}{136154.6-26,62259^2} = 2.005233 \\
\hat{\theta} &amp;=  (2.005233-1) \cdot 26.62259 = 26.7619
\end{aligned}\]</span></p>
<p>Nilai kemungkinan maksimum berubah menjadi <span class="math inline">\(\hat{\alpha}_{MLE} = 0.9990936\)</span> Dan <span class="math inline">\(\hat{\theta}_{MLE} = 2.2821147\)</span> . Sangat menarik bahwa <span class="math inline">\(\hat{\alpha}_{MLE}&lt;1\)</span> ; untuk distribusi Pareto, ingat itu <span class="math inline">\(α &lt; 1\)</span> berarti rata-ratanya tak terhingga. Ini adalah indikasi lain bahwa kumpulan data klaim properti adalah distribusi ekor panjang.</p>
<p>Seperti contoh di atas, ada fleksibilitas dengan metode momen. Misalnya, kita dapat mencocokkan momen kedua dan ketiga alih-alih yang pertama dan kedua, menghasilkan estimator yang berbeda. Selain itu, tidak ada jaminan bahwa solusi akan ada untuk setiap masalah. Untuk data yang disensor atau terpotong, momen pencocokan dimungkinkan untuk beberapa masalah, tetapi secara umum, ini adalah skenario yang lebih sulit. Terakhir, untuk distribusi di mana momen tidak ada atau tidak terbatas, metode momen tidak tersedia. Sebagai alternatif, seseorang dapat menggunakan teknik pencocokan persentil.</p>
</div>
<div id="pencocokan-persentil" class="section level4 hasAnchor" number="4.1.3.2">
<h4><span class="header-section-number">4.1.3.2</span> Pencocokan Persentil<a href="model-selection-and-estimation.html#pencocokan-persentil" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Di bawah pencocokan persentil , kami memperkirakan kuantil atau persentil dari distribusi parametrik menggunakan kuantil atau persentil empiris (nonparametrik) yang dijelaskan di Bagian 4.1.1.3 .</p>
<p><em>Contoh 4.1.10. Dana Properti.</em> Untuk dana properti 2010, kami mengilustrasikan pencocokan pada kuantil. Secara khusus, distribusi Pareto secara intuitif menyenangkan karena solusi bentuk tertutup untuk kuantil. Ingatlah bahwa fungsi distribusi untuk distribusi Pareto adalah</p>
<p><span class="math display">\[F(x) = 1 - \left(\frac{\theta}{x+\theta}\right)^{\alpha}.\]</span></p>
<p>Aljabar mudah menunjukkan bahwa kita dapat menyatakan kuantil sebagai</p>
<p><span class="math display">\[F^{-1}(q) = \theta \left( (1-q)^{-1/\alpha} -1 \right).\]</span></p>
<p>untuk sebagian kecil q , <span class="math inline">\(0 &lt; q&lt; 1\)</span>.</p>
<p>Tentukan estimasi parameter distribusi Pareto menggunakan kuantil empiris ke-25 dan ke-95.</p>
<p>Solusi. Persentil ke-25 (kuartil pertama) ternyata adalah 0,78853 dan persentil ke-95 adalah 50.98293 (keduanya dalam ribuan dolar). Dengan dua persamaan</p>
<p><span class="math display">\[0.78853 = \theta \left( 1- (1-.25)^{-1/\alpha} \right) \ \ \ \ \text{and} \ \ \ \ 50.98293 = \theta \left( 1- (1-.75)^{-1/\alpha} \right)\]</span></p>
<p>dan dua yang tidak diketahui, solusinya adalah</p>
<p><span class="math display">\[\hat{\alpha} = 0.9412076 \ \ \ \ \ \text{and} \ \ \ \
\hat{\theta} = 2.205617 .\]</span></p>
<p>Sehingga kesimpulannya adalah rutin numerik diperlukan untuk solusi ini karena tidak ada solusi analitik yang tersedia. Selanjutnya, ingatlah perkiraan kemungkinan maksimumadalah α^ML E= 0,9990936 Dan θ^ML E= 2,2821147 , sehingga pencocokan persentil memberikan perkiraan yang lebih baik untuk distribusi Pareto daripada metode momen.</p>
<p><em>Contoh 4.1.11. Soal Ujian Aktuaria. Anda diberikan:</em></p>
<ol style="list-style-type: lower-roman">
<li>Kerugian mengikuti distribusi loglogistik dengan fungsi distribusi kumulatif:</li>
</ol>
<p><span class="math display">\[F(x) = \frac{\left(x/\theta\right)^{\gamma}}{1+\left(x/\theta\right)^{\gamma}}\]</span></p>
<ol start="2" style="list-style-type: lower-roman">
<li>Contoh kerugiannya adalah:</li>
</ol>
<p><span class="math display">\[\begin{array}{ccccccccccc}
10 &amp;35 &amp;80 &amp;86 &amp;90 &amp;120 &amp;158 &amp;180 &amp;200 &amp;210 &amp;1500 \\
\end{array}\]</span></p>
<p>Hitung estimasi dari <span class="math inline">\(θ\)</span> dengan pencocokan persentil, menggunakan perkiraan persentil ke-40 dan ke-80 yang dihaluskan secara empiris.</p>
<p>Solusi. Dengan 11 pengamatan, kami memiliki <span class="math inline">\(j=\lfloor(n+1)q\rfloor = \lfloor 12(0.4) \rfloor = \lfloor 4.8\rfloor=4\)</span>. Dengan interpolasi, perkiraan persentil ke-40 yang dihaluskan secara empiris adalah <span class="math inline">\(\hat{\pi}_{0.4} = (1-h) X_{(j)} + h X_{(j+1)} = 0.2(86)+0.8(90)=89.2\)</span>.</p>
<p>Demikian pula, untuk perkiraan persentil yang dihaluskan secara empiris ke-80, kami memiliki <span class="math inline">\(12 ( 0,8 ) = 9,6\)</span> jadi perkiraannya <span class="math inline">\(\hat{\pi}_{0.8} = 0.4(200)+0.6(210)=206\)</span>.</p>
<p>Dengan menggunakan distribusi kumulatif loglogistik, kita perlu menyelesaikan dua persamaan berikut untuk parameter <span class="math inline">\({\hat{\theta}}\)</span> Dan <span class="math inline">\({\hat{\gamma}}\)</span> :</p>
<p><span class="math display">\[0.4=\frac{(89.2/{\hat{\theta}})^{\hat{\gamma}}}{1+(89.2/{\hat{\theta}})^{\hat{\gamma}}} \ \ \ \text{and} \ \ \ \   0.8=\frac{(206/{\hat{\theta}})^{\hat{\gamma}}}{1+(206/{\hat{\theta}})^{\hat{\gamma}}} .\]</span></p>
<p>Pemecahan untuk setiap ekspresi kurung memberi <span class="math inline">\(\frac{2}{3}=(89.2/\theta)^{\hat{\gamma}}\)</span> Dan <span class="math inline">\(4=(206/{\hat{\theta}})^{\hat{\gamma}}\)</span> . Mengambil rasio persamaan kedua dengan yang pertama memberi <span class="math inline">\(6=(206/89.2)^{\hat{\gamma}}\Rightarrow {\hat{\gamma}}=\frac{\log(6)}{\log(206/89.2)} = 2.1407\)</span>. Kemudian <span class="math inline">\(4^{1/2.1407}=206/{\hat{\theta}} \Rightarrow {\hat{\theta}}=107.8\)</span>.</p>
<p>Seperti metode momen, pencocokan persentil hampir terlalu fleksibel dalam arti bahwa estimator dapat bervariasi tergantung pada persentil berbeda yang dipilih. Misalnya, seorang aktuaris dapat menggunakan estimasi pada persentil ke-25 dan ke-95 sedangkan yang lain menggunakan persentil ke-20 dan ke-80. Secara umum estimasi parameter akan berbeda dan tidak ada alasan kuat untuk memilih salah satu dari yang lain. Seperti halnya metode momen, pencocokan persentil menarik karena memberikan teknik yang dapat diterapkan dengan mudah dalam situasi tertentu dan memiliki dasar intuitif. Meskipun sebagian besar aplikasi aktuaria menggunakan estimator kemungkinan maksimum, akan lebih mudah untuk memiliki pendekatan alternatif seperti metode momen dan pencocokan persentil yang tersedia.</p>
</div>
</div>
</div>
<div id="model-selection" class="section level2 hasAnchor" number="4.2">
<h2><span class="header-section-number">4.2</span> Model Selection<a href="model-selection-and-estimation.html#model-selection" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Menjelaskan proses pemilihan model berdasarkan:</p>
<ul>
<li>dataset dalam sampel atau pelatihan,</li>
<li>dataset out -of-sampel atau uji, dan</li>
<li>metode yang menggabungkan pendekatan ini dikenal sebagai cross-validation .</li>
</ul>
<div id="pemilihan-model-iteratif" class="section level3 hasAnchor" number="4.2.1">
<h3><span class="header-section-number">4.2.1</span> Pemilihan Model Iteratif<a href="model-selection-and-estimation.html#pemilihan-model-iteratif" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Dalam memeriksa data secara grafis, membuat hipotesis struktur model, dan membandingkan data dengan model kandidat untuk merumuskan model yang lebih baik. Box ( 1980 ) menggambarkan ini sebagai proses berulang yang ditunjukkan pada Gambar dibawah ini</p>
<p><img src="https://github.com/dsciencelabs/Analisa_Resiko/blob/main/images/4.2.1-1png?raw=true" width="300" height="300" style="display: block; margin-left: auto; margin-right: auto; margin-top: 10px;"></p>
<p>Proses berulang ini memberikan resep yang berguna untuk menyusun tugas menentukan model untuk mewakili satu set data.</p>
<p>Langkah pertama, tahap perumusan model, dilakukan dengan memeriksa data secara grafis dan menggunakan pengetahuan hubungan sebelumnya, seperti dari teori ekonomi atau praktik industri.
Langkah kedua dalam iterasi adalah fitting berdasarkan asumsi model yang ditentukan. Asumsi ini harus konsisten dengan data untuk menggunakan model secara valid.
Langkah ketiga adalah pemeriksaan diagnostik ; data dan model harus konsisten satu sama lain sebelum kesimpulan tambahan dapat dibuat. Pengecekan diagnostik adalah bagian penting dari formulasi model; itu dapat mengungkapkan kesalahan yang dilakukan pada langkah sebelumnya dan memberikan cara untuk memperbaiki kesalahan ini.</p>
</div>
<div id="model-selection-based-on-a-training-dataset" class="section level3 hasAnchor" number="4.2.2">
<h3><span class="header-section-number">4.2.2</span> Model Selection Based on a Training Dataset<a href="model-selection-and-estimation.html#model-selection-based-on-a-training-dataset" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Biasanya merujuk ke kumpulan data yang digunakan untuk analisis sebagai kumpulan data dalam sampel atau pelatihan . Teknik yang tersedia untuk memilih model tergantung pada apakah hasilnya X diskrit, kontinu, atau campuran dari keduanya, meskipun prinsipnya sama.</p>
<p>Grafik dan Tindakan Ringkasan Dasar lainnya. Mulailah dengan meringkas data secara grafis dan dengan statistik yang tidak bergantung pada bentuk parametrik tertentu.</p>
<p>Tes Rasio Kemungkinan. Untuk membandingkan kecocokan model, jika satu model merupakan bagian dari model lainnya, maka uji rasio kemungkinan dapat digunakan; pendekatan umum untuk pengujian rasio kemungkinan</p>
<p>Kebaikan Statistik Fit. Secara umum, model bukan himpunan bagian yang tepat satu sama lain sehingga statistik kecocokan secara keseluruhan sangat membantu untuk membandingkan model. Kriteria informasi adalah salah satu jenis kebaikan statistik.</p>
<p>Untuk memilih distribusi yang sesuai, statistik yang membandingkan kecocokan parametrik dengan alternatif nonparametrik.</p>
</div>
<div id="model-selection-based-on-a-test-dataset" class="section level3 hasAnchor" number="4.2.3">
<h3><span class="header-section-number">4.2.3</span> Model Selection Based on a Test Dataset<a href="model-selection-and-estimation.html#model-selection-based-on-a-test-dataset" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Validasi model adalah proses konfirmasi bahwa model yang diusulkan sesuai, terutama mengingat tujuan penyelidikan. Keterbatasan penting dari proses pemilihan model hanya berdasarkan data dalam sampel adalah bahwa hal itu dapat rentan terhadap data-snooping , yaitu menyesuaikan sejumlah besar model ke satu set data. Memilih model hanya berdasarkan data dalam sampel juga tidak mendukung tujuan inferensi prediktif .</p>
</div>
<div id="model-selection-based-on-cross-validation" class="section level3 hasAnchor" number="4.2.4">
<h3><span class="header-section-number">4.2.4</span> Model Selection Based on Cross-Validation<a href="model-selection-and-estimation.html#model-selection-based-on-cross-validation" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Meskipun validasi out-of-sample adalah standar emas dalam pemodelan prediktif, tidak selalu praktis untuk melakukannya. Alasan utamanya adalah kita memiliki ukuran sampel yang terbatas dan kriteria pemilihan model di luar sampel dalam persamaan (4.4) bergantung pada pemisahan data secara acak . Ini berarti bahwa analis yang berbeda, bahkan ketika mengerjakan kumpulan data yang sama dan pendekatan pemodelan yang sama, dapat memilih model yang berbeda.</p>
<p>Prosedur Validasi Silang. Sebagai alternatif, seseorang dapat menggunakan cross-validation , sebagai berikut.</p>
<ul>
<li>Prosedur dimulai dengan menggunakan mekanisme acak untuk membagi data menjadi K himpunan bagian dengan ukuran yang kira-kira sama yang dikenal sebagai lipatan , di mana analis biasanya menggunakan 5 hingga 10.</li>
<li>Selanjutnya, yang satu menggunakan yang pertama K-1 subsampel untuk memperkirakan parameter model. Kemudian, “prediksi” hasil untuk K th subsampel dan gunakan ukuran seperti pada persamaan (4.4) untuk meringkas kecocokan.</li>
<li>Sekarang, ulangi ini dengan menahan masing-masing K
subsampel, meringkas dengan statistik out-of-sample. Jadi, rangkumlah ini K statistik, biasanya dengan rata-rata, untuk memberikan satu statistik keseluruhan untuk tujuan perbandingan.</li>
</ul>
<p>Ulangi langkah-langkah ini untuk beberapa model kandidat dan pilih model dengan statistik validasi silang terendah secara keseluruhan.</p>
</div>
</div>
<div id="estimasi-menggunakan-data-modifikasi" class="section level2 hasAnchor" number="4.3">
<h2><span class="header-section-number">4.3</span> Estimasi Menggunakan Data Modifikasi<a href="model-selection-and-estimation.html#estimasi-menggunakan-data-modifikasi" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Penjelasan pada subbab ini:</p>
<ul>
<li>Mendeskripsikan data yang dikelompokkan, disensor, dan terpotong</li>
<li>Perkirakan distribusi parametrik berdasarkan data yang dikelompokkan, disensor, dan terpotong</li>
<li>Perkirakan distribusi secara nonparametrik berdasarkan data yang dikelompokkan, disensor, dan terpotong</li>
</ul>
<div id="estimasi-parametrik-menggunakan-data-modifikasi" class="section level3 hasAnchor" number="4.3.1">
<h3><span class="header-section-number">4.3.1</span> Estimasi Parametrik menggunakan Data Modifikasi<a href="model-selection-and-estimation.html#estimasi-parametrik-menggunakan-data-modifikasi" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Seperti yang kita ketahui bahwa Estimasi parametrik bersifat kuantitatif dan menggunakan statistik untuk menghitung perkiraan jumlah sumber daya yang dibutuhkan untuk menyelesaikan proyek Anda, baik itu biaya atau waktu, atau bahkan sumber daya manusia. Bagian 3.5 memperkenalkan konsep observasi yang “ dimodifikasi ” karena dua jenis batasan umum: penyensoran dan pemotongan. Misalnya, adalah umum untuk berpikir tentang asuransi yang dapat dikurangkan sebagai menghasilkan data yang terpotong (dari kiri) atau batasan polis sebagai menghasilkan data yang disensor (dari kanan). Sudut pandang ini dari perusahaan asuransi utama (penjual asuransi). Secara khusus, bagian ini akan membahas metode estimasi parametrik untuk tiga alternatif data individual, lengkap, dan tidak dimodifikasi: data dengan sensor interval hanya tersedia dalam kelompok, data yang terbatas ataudisensor , dan data yang tidak dapat diamati karena pemotongan .</p>
<div id="estimasi-parametrik-menggunakan-data-yang-dikelompokkan" class="section level4 hasAnchor" number="4.3.1.1">
<h4><span class="header-section-number">4.3.1.1</span> Estimasi Parametrik menggunakan Data yang Dikelompokkan<a href="model-selection-and-estimation.html#estimasi-parametrik-menggunakan-data-yang-dikelompokkan" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Pertimbangkan sampel ukuran N diamati dari distribusinya <span class="math inline">\(F( ⋅ )\)</span>, tetapi dalam kelompok sehingga kita hanya mengetahui kelompok tempat setiap pengamatan jatuh, bukan nilai pastinya. Ini disebut sebagai data yang dikelompokkan atau disensor interval .</p>
<p>Memformalkan ide ini, misalkan ada k kelompok atau interval yang dibatasi oleh batas <span class="math inline">\(C_0&lt;C_1&lt; ⋯ &lt;C_k.\)</span> Untuk setiap pengamatan, kami hanya mengamati interval jatuhnya <span class="math inline">\(((C_{j − 1},C_J))\)</span>, bukan nilai yang tepat. Dengan demikian, kita hanya mengetahui jumlah observasi pada setiap interval. Konstanta <span class="math inline">\({C_0&lt;C_1&lt; ⋯ &lt;C_k}\)</span> membentuk beberapa partisi dari domain <span class="math inline">\(F( ⋅ )\)</span>. Kemudian probabilitas pengamatan <span class="math inline">\(X_i\)</span> jatuh di <span class="math inline">\(J\)</span>th interval ke- adalah</p>
<p><span class="math display">\[
Pr(X_i \in (c_{j-1},c_j])=F(c_j)-F(c_{j-1})
\]</span></p>
<p>Fungsi massa probabilitas yang sesuai untuk pengamatan adalah</p>
<p><img src="https://github.com/dsciencelabs/Analisa_Resiko/blob/main/images/4.3.1-1.png?raw=true" width="300" height="300" style="display: block; margin-left: auto; margin-right: auto; margin-top: 10px;"></p>
<p>Sekarang, tentukan <span class="math inline">\(N_J\)</span> menjadi jumlah pengamatan yang termasuk dalam <span class="math inline">\(J\)</span>th interval, <span class="math inline">\((C_{j − 1},C_J]\)</span>. Jadi, fungsi kemungkinan (sehubungan dengan parameter) <span class="math inline">\(θ\)</span>) adalah</p>
<p><img src="https://github.com/dsciencelabs/Analisa_Resiko/blob/main/images/4.3.1-2.png?raw=true" width="300" height="300" style="display: block; margin-left: auto; margin-right: auto; margin-top: 10px;"></p>
<p>Dan fungsi log-kemungkinan adalah</p>
<p><img src="https://github.com/dsciencelabs/Analisa_Resiko/blob/main/images/4.3.1-3.png?raw=true" width="300" height="300" style="display: block; margin-left: auto; margin-right: auto; margin-top: 10px;"></p>
<p>Diberikan data :
1. Kerugian mengikuti distribusi eksponensial dengan rata-rata <span class="math inline">\(θ\)</span>.
2. Sebuah sampel acak dari 20 kerugian didistribusikan sebagai berikut:</p>
<p><img src="https://github.com/dsciencelabs/Analisa_Resiko/blob/main/images/example4.3-1.png?raw=true" width="300" height="300" style="display: block; margin-left: auto; margin-right: auto; margin-top: 10px;"></p>
<p>Hitung estimasi kemungkinan maksimum dari <span class="math inline">\(θ\)</span></p>
<p><span class="math display">\[
\begin{aligned}
L(\theta) &amp;= F(1000)^7[F(2000)-F(1000)]^6[1-F(2000)]^7 \\
&amp;= (1-e^{-1000/\theta})^7(e^{-1000/\theta} - e^{-2000/\theta})^6(e^{-2000/\theta})^7 \\
&amp;= (1-p)^7(p-p^2)^6(p^2)^7 \\
&amp;= p^{20}(1-p)^{13}
\end{aligned}
\]</span></p>
<p>di mana <span class="math inline">\(p = e^{-1000/θ}\)</span>. Memaksimalkan ekspresi ini sehubungan dengan <span class="math inline">\(p\)</span> setara dengan memaksimalkan kemungkinan terhadap <span class="math inline">\(θ\)</span>. Maksimum terjadi pada <span class="math inline">\(p=\frac{20}{33}\)</span>. sehingga <span class="math inline">\(\hat{\theta}=\frac{-1000}{\log(20/33)}= 1996.90\)</span></p>
</div>
<div id="cencored-data" class="section level4 hasAnchor" number="4.3.1.2">
<h4><span class="header-section-number">4.3.1.2</span> Cencored Data<a href="model-selection-and-estimation.html#cencored-data" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Penyensoran terjadi ketika kita hanya mencatat nilai yang terbatas dari sebuah observasi. Bentuk yang paling umum adalah penyensoran kanan, di mana kita mencatat nilai yang lebih kecil dari variabel dependen “benar” dan nilai penyensoran. Dengan menggunakan notasi, dengan <code>X</code> mewakili hasil yang diminati, seperti kerugian akibat kejadian yang diasuransikan atau waktu hingga kejadian. Dengan <span class="math inline">\(C_U\)</span> menyatakan jumlah penyensoran. Dengan pengamatan tersensor kanan, mencatat <span class="math inline">\(X_U^* = min(X, C_U) = X∧C_U\)</span>. Lalu juga mencatat apakah penyensoran telah terjadi atau tidak. <span class="math inline">\(δ_U = I(X≤C_U)\)</span> adalah variabel biner yang bernilai 0 jika penyensoran terjadi dan 1 jika tidak, yaitu, <span class="math inline">\(δ_U\)</span> menunjukkan apakah X tidak disensor atau tidak.</p>
<p>Sebagai contoh <span class="math inline">\(C_U\)</span> dapat merepresentasikan batas atas pertanggungan sebuah polis asuransi. Kerugian dapat melebihi jumlah <span class="math inline">\(C_U\)</span> tetapi perusahaan asuransi hanya memiliki <span class="math inline">\(C_U\)</span> dalam catatannya sebagai jumlah yang dibayarkan dan tidak memiliki jumlah kerugian aktual <span class="math inline">\(X\)</span> dalam catatannya.</p>
<p>Sama halnya dengan penyensoran kiri, dapat mencatat yang lebih besar dari variabel yang diminati dan variabel yang disensor. Jika <span class="math inline">\(C_L\)</span> digunakan untuk merepresentasikan jumlah penyensoran, maka mencatat <span class="math inline">\(X_L^*=max(X,C_L)\)</span> bersama dengan indikator penyensoran <span class="math inline">\(δ_L=I(X&gt;C_L)\)</span>.</p>
<p>Sebagai contoh, reasuradur akan menanggung kerugian penanggung yang lebih besar dari <span class="math inline">\(C_L\)</span> ini berarti reasuradur bertanggung jawab atas kelebihan <span class="math inline">\(X_L^*\)</span> pada <span class="math inline">\(C_L\)</span>. Dengan menggunakan notasi, kerugian reasuradur adalah <span class="math inline">\(Y = X_L^*L-C_L\)</span> Untuk melihat hal ini, pertama-tama pertimbangkan kasus di mana pemegang polis mengalami kerugian <span class="math inline">\(X &lt; C_L\)</span>. Kemudian, penanggung akan membayar seluruh klaim dan <span class="math inline">\(Y=C_L-C_L=0\)</span> tidak ada kerugian bagi reasuradur. Sebaliknya, jika kerugian <span class="math inline">\(X≥C_L\)</span> maka <span class="math inline">\(Y = X-C_L\)</span> merupakan klaim yang ditahan oleh reasuradur. Dengan kata lain, jika terjadi kerugian, reasuradur mencatat jumlah sebenarnya jika melebihi batas <span class="math inline">\(C_L\)</span> dan jika tidak, hanya mencatat akan mengalami kerugian sebesar 0.</p>
</div>
<div id="truncated-data" class="section level4 hasAnchor" number="4.3.1.3">
<h4><span class="header-section-number">4.3.1.3</span> Truncated data<a href="model-selection-and-estimation.html#truncated-data" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Pengamatan yang disensor dicatat untuk studi, meskipun dalam bentuk yang terbatas. Sebaliknya, hasil yang terpotong adalah jenis data yang hilang. Sebuah hasil berpotensi terpotong ketika ketersediaan pengamatan bergantung pada hasil.</p>
<p>Dalam asuransi, biasanya pengamatan terpotong kiri pada <span class="math inline">\(C_L\)</span> ketika jumlahnya adalah</p>
<p><span class="math display">\[
\begin{aligned}
Y &amp;=
\left\{
\begin{array}{cl}
\text{we do not observe }X &amp; X \le C_L \\
X &amp; X &gt; C_L
\end{array}
\right.\end{aligned}
\]</span></p>
<p>Dengan kata lain, jika X kurang dari ambang batas <span class="math inline">\(C_L\)</span> maka ia tidak teramati.</p>
<p><span class="math inline">\(C_L\)</span> dapat merepresentasikan deductible dari sebuah polis asuransi. Jika kerugian yang diasuransikan kurang dari deductible, maka perusahaan asuransi mungkin tidak mengamati atau mencatat kerugian sama sekali. Jika kerugian melebihi deductible, maka kelebihan <span class="math inline">\(X-C_L\)</span> adalah klaim yang ditanggung oleh penanggung. Dimana dapat didefinisikan kerugian per pembayaran sebagai</p>
<p><span class="math display">\[
\begin{aligned}
Y^{P} = \left\{ \begin{matrix}
\text{Undefined} &amp; X \le d \\
X - d &amp; X &gt; d
\end{matrix} \right.
\end{aligned}
\]</span></p>
<p>sehingga jika kerugian melebihi deductible, kami mencatat jumlah kelebihan <span class="math inline">\(X-d\)</span>. Hal ini sangat penting ketika mempertimbangkan jumlah yang akan dibayarkan oleh perusahaan asuransi. Namun, untuk tujuan estimasi pada bagian ini, tidak terlalu penting jika kita mengurangkan konstanta yang diketahui seperti <span class="math inline">\(C_L = d\)</span>. Sehingga, untuk variabel terpotong <span class="math inline">\(Y\)</span> kita menggunakan konvensi yang lebih sederhana dan tidak mengurangkan <span class="math inline">\(d\)</span>.</p>
<p>Demikian pula untuk data terpotong kanan, jika X melebihi ambang batas <span class="math inline">\(C_U\)</span> maka data tersebut tidak diobservasi. Dalam hal ini, jumlahnya adalah</p>
<p><span class="math display">\[
\begin{aligned}
Y &amp;=
\left\{
\begin{array}{cl}
X &amp; X \le C_U \\
\text{we do not observe }X &amp; X &gt; C_U.
\end{array}
\right.\end{aligned}
\]</span></p>
<p>Contoh klasik dari pemotongan dari kanan termasuk X sebagai ukuran jarak ke bintang. Ketika jaraknya melebihi tingkat tertentu <span class="math inline">\(C_U\)</span> maka bintang tersebut tidak lagi dapat diamati.</p>
<p>Gambar dibawah ini membandingkan pengamatan yang terpotong dan tersensor. Nilai-nilai X yang lebih besar dari batas penyensoran “atas” <span class="math inline">\(C_U\)</span> tidak teramati sama sekali (tersensor kanan), sedangkan nilai X yang lebih kecil dari batas pemotongan “bawah” <span class="math inline">\(C_L\)</span> tetap diamati, tetapi diamati sebagai <span class="math inline">\(C_L\)</span> daripada nilai X yang sebenarnya (tersensor kiri).</p>
</div>
<div id="parametric-estimation-using-cencored-and-truncated-data" class="section level4 hasAnchor" number="4.3.1.4">
<h4><span class="header-section-number">4.3.1.4</span> Parametric Estimation using Cencored and Truncated data<a href="model-selection-and-estimation.html#parametric-estimation-using-cencored-and-truncated-data" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Untuk mempermudah, dapat diasumsikan jumlah penyensoran tidak acak dan hasil yang kontinu X . Sebagai permulaan, pertimbangkan kasus data tersensor kanan di mana merekam <span class="math inline">\(X_U^* = min(X, C_U) = X∧C_U\)</span>) dan indikator penyensoran <span class="math inline">\(δ = I(X≤C_U)\)</span> . Jika penyensoran terjadi sehingga <span class="math inline">\(δ=0\)</span> maka <span class="math inline">\(X&gt;C_U\)</span> dan peluangnya adalah <span class="math inline">\(Pr(X&gt;C_U)=1-F(C_U)\)</span>. Jika penyensoran tidak terjadi sehingga <span class="math inline">\(δ = 1\)</span> maka <span class="math inline">\(X≤C_U\)</span> dan likelihoodnya adalah <span class="math inline">\(f(x)\)</span> . Ringkasnya, didapatkan likelihood dari sebuah pengamatan tunggal sebagai</p>
<p><span class="math display">\[
\begin{aligned}
\left\{
\begin{array}{ll}
1-F(C_U) &amp; \text{if }\delta=0 \\
f(x) &amp; \text{if } \delta = 1
\end{array}
\right. = \left\{ f(x)\right\}^{\delta} \left\{1-F(C_U)\right\}^{1-\delta} .
\end{aligned}
\]</span></p>
<p>Ekspresi ruas kanan memungkinkan dalam menyajikan peluang dengan lebih ringkas. Sekarang, untuk sampel ke-i dengan ukuran n , peluangnya adalah</p>
<p><span class="math display">\[
\begin{aligned}
L(\theta) =
\prod_{i=1}^n \left\{ f(x_i)\right\}^{\delta_i} \left\{1-F(C_{Ui})\right\}^{1-\delta_i} = \prod_{\delta_i=1} f(x_i) \prod_{\delta_i=0} \{1-F(C_{Ui})\}
\end{aligned}
\]</span></p>
<p>dengan waktu penyensoran potensial <span class="math inline">\({(C_{U1},...,C_{Un})}\)</span> . Di sini, notasi “<span class="math inline">\(∏{δi} = 1\)</span>” berarti mengambil hasil kali dari pengamatan yang tidak disensor, dan demikian pula untuk “<span class="math inline">\(∏{δi} = 0\)</span>”</p>
<p>Di sisi lain, data terpotong ditangani dalam inferensi kemungkinan melalui probabilitas bersyarat. Secara khusus, kontribusi likelihood dapat disesuaikan dengan membaginya dengan probabilitas bahwa variabel tersebut diamati. Sebagai rangkuman, kami memiliki kontribusi berikut pada fungsi likelihood untuk enam jenis hasil:</p>
<p><img src="https://github.com/dsciencelabs/Analisa_Resiko/blob/main/images/table4-1.png?raw=true" width="300" height="300" style="display: block; margin-left: auto; margin-right: auto; margin-top: 10px;"></p>
<p>Untuk hasil yang diketahui dan data yang disensor, kemungkinannya adalah</p>
<p><span class="math display">\[
\begin{aligned}
L(\theta) = \prod_{E} f(x_i) \prod_{R} \{1-F(C_{Ui})\} \prod_{L}
F(C_{Li}) \prod_{I} (F(C_{Ui})-F(C_{Li})),
\end{aligned}
\]</span></p>
<p>di mana <span class="math inline">\(&quot;∏_E&quot;\)</span> adalah hasil kali pengamatan dengan nilai Exact, dan demikian pula untuk Right-,Left-
and Interval-censoring.</p>
<p>Untuk data yang disensor kanan dan terpotong kiri, kemungkinannya adalah</p>
<p><span class="math display">\[
\begin{aligned}
L(\theta) = \prod_{E} \frac{f(x_i)}{1-F(C_{Li})} \prod_{R} \frac{1-F(C_{Ui})}{1-F(C_{Li})},
\end{aligned}
\]</span>
dan juga untuk kombinasi lainnya.</p>
<p>Example 4.3.2. Actuarial Exam Question</p>
<p>Diberikan data :</p>
<ol style="list-style-type: lower-roman">
<li>Sebuah contoh kerugian adalah: 600 700 900</li>
<li>Tidak ada informasi yang tersedia mengenai kerugian sebesar 500 atau kurang.</li>
<li>Kerugian diasumsikan mengikuti distribusi eksponensial dengan rata-rata <span class="math inline">\(θ\)</span>.</li>
</ol>
<p>Hitung estimasi kemungkinan maksimum dari <span class="math inline">\(θ\)</span></p>
<p>Pengamatan ini terpotong pada angka 500. Kontribusi dari setiap pengamatan terhadap fungsi likelihood adalah</p>
<p><span class="math inline">\(\frac{f(x)}{1-F(500)} = \frac{\theta^{-1}e^{-x/\theta}}{e^{-500/\theta}}\)</span></p>
<p>Lalu Fungsi Likelihoodnya adalah</p>
<p><span class="math inline">\(L(\theta)= \frac{\theta^{-1} e^{-600/\theta} \theta^{-1} e^{-700/\theta} \theta^{-1} e^{-900/\theta}}{(e^{-500/\theta})^3} = \theta^{-3}e^{-700/\theta}\)</span></p>
<p>Log-Likehoodnya adalah</p>
<p><span class="math inline">\(l(\theta) = \log L(\theta) = -3 \log \theta - 700 \theta^{-1}\)</span></p>
<p>Memaksimalkan ekspresi ini dengan menetapkan turunan terhadap θ sama dengan 0, Maka memiliki</p>
<p><span class="math inline">\(L&#39;(\theta) = -3 \theta^{-1} + 700 \theta^{-2} = 0 \ \Rightarrow \ \hat{\theta} = \frac{700}{3} = 233.33 .\)</span></p>
</div>
</div>
<div id="nonparametric-estimation-using-modified-data" class="section level3 hasAnchor" number="4.3.2">
<h3><span class="header-section-number">4.3.2</span> Nonparametric Estimation using Modified Data<a href="model-selection-and-estimation.html#nonparametric-estimation-using-modified-data" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Estimator nonparametrik memberikan tolok ukur yang berguna, sehingga akan sangat membantu untuk memahami prosedur estimasi untuk data yang dikelompokkan, disensor, dan dipotong</p>
<div id="grouped-data" class="section level4 hasAnchor" number="4.3.2.1">
<h4><span class="header-section-number">4.3.2.1</span> Grouped Data<a href="model-selection-and-estimation.html#grouped-data" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Pengamatan dapat dikelompokkan (juga disebut sebagai interval tersensor) dalam arti bahwa pengamatan sebagai bagian dari salah satu dari k interval dalam bentuk <span class="math inline">\((c_{j-1},c_j)\)</span> , untuk <span class="math inline">\(j = 1,...,k\)</span> . Pada batas-batasnya, fungsi distribusi empiris didefinisikan dengan cara yang biasa:</p>
<p><span class="math display">\[
\begin{aligned}
F_n(c_j) = \frac{\text{number of observations } \le c_j}{n}
\end{aligned}
\]</span></p>
<p><em>Ogive Estimator</em></p>
<p>Untuk nilai lain dari <span class="math inline">\(x∈(c_{j-1},c_j)\)</span> dapat mengestimasi fungsi distribusi dengan ogive estimator yang menginterpolasi secara linear antara <span class="math inline">\(F_n(c_{j-1})\)</span> dan <span class="math inline">\(Fn_(c_j)\)</span> yaitu nilai dari batas-batas <span class="math inline">\(F_n(c_{j-1})\)</span> dan <span class="math inline">\(Fn_(c_j)\)</span> dihubungkan dengan sebuah garis lurus. Hal ini secara formal dapat dinyatakan sebagai</p>
<p><span class="math display">\[
\begin{aligned}
F_n(x) = \frac{c_j-x}{c_j-c_{j-1}} F_n(c_{j-1}) + \frac{x-c_{j-1}}{c_j-c_{j-1}} F_n(c_j) \ \ \ \text{for } c_{j-1} \le x &lt; c_j
\end{aligned}
\]</span></p>
<p>Sehinga Densitas yang sesuai adalah</p>
<p><span class="math display">\[
\begin{aligned}
f_n(x) = F^{\prime}n(x) = \frac{F_n(c_j)-F_n(c{j-1})}{c_j - c_{j-1}} \ \ \  \text{for } c_{j-1} &lt; x &lt; c_j .
\end{aligned}
\]</span></p>
<p>Example 4.3.4. Actuarial Exam Question</p>
<p>Diberikan informasi berikut ini mengenai jumlah klaim untuk 100 klaim:</p>
<p><img src="https://github.com/dsciencelabs/Analisa_Resiko/blob/main/images/example4.3.4-1.png?raw=true" width="300" height="300" style="display: block; margin-left: auto; margin-right: auto; margin-top: 10px;"></p>
<p>Dengan menggunakan ogive, hitunglah estimasi probabilitas bahwa klaim yang dipilih secara acak adalah antara 2000 dan 6000.</p>
<p>Pada batas-batasnya, fungsi distribusi empiris didefinisikan dengan cara yang biasa, sehingga memiliki</p>
<p><span class="math inline">\(F_{100}(1000) = 0.16, \ F_{100}(3000)=0.38, \ F_{100}(5000)=0.63, \ F_{100}(10000)=0.81\)</span></p>
<p>Untuk ukuran klaim lainnya, penaksir ogive melakukan interpolasi linier di antara nilai-nilai ini:</p>
<p><span class="math display">\[
\begin{array}{ll}
F_{100}(2000) &amp;= 0.5F_{100}(1000) + 0.5F_{100}(3000) = 0.5(0.16)+0.5(0.38)=0.27 \\
F_{100}(6000) &amp;=0.8F_{100}(5000)+0.2F_{100}(10000) = 0.8(0.63)+0.2(0.81)=0.666
\end{array}
\]</span></p>
<p>Dengan demikian, probabilitas klaim antara 2000 dan 6000 adalah</p>
<p><span class="math inline">\(F_{100}(6000) - F_{100}(2000) = 0.666-0.27 = 0.396\)</span></p>
</div>
<div id="right-censored-empirical-distribution-function" class="section level4 hasAnchor" number="4.3.2.2">
<h4><span class="header-section-number">4.3.2.2</span> Right-Censored Empirical Distribution Function<a href="model-selection-and-estimation.html#right-censored-empirical-distribution-function" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Akan sangat berguna untuk mengkalibrasi penaksir parametrik dengan metode nonparametrik yang tidak bergantung pada bentuk parametrik distribusi. Penaksir batas produk menurut (Kaplan dan Meier 1958) merupakan penaksir yang terkenal untuk fungsi distribusi dengan adanya penyensoran.</p>
<p><em>Motivasi untuk Penaksir Batas Produk Kaplan-Meier</em></p>
<p>Untuk menjelaskan mengapa product-limit bekerja dengan sangat baik dengan observasi tersensor, pertama-tama dapat melihat ke kasus tanpa penyensoran. Di sini, fungsi distribusi empiris <span class="math inline">\(F_n(x)\)</span> adalah penaksir tak bias dari fungsi distribusi <span class="math inline">\(F(x)\)</span> . Hal ini karena <span class="math inline">\(F_n(x)\)</span> adalah rata-rata dari variabel indikator yang masing-masing tidak bias, yaitu, <span class="math inline">\(E [I(X_i≤x)]=Pr(X_i≤x)=F(x)\)</span></p>
<p>Sekarang misalkan hasil acak disensor di sebelah kanan dengan jumlah yang membatasi, katakanlah, CU sehingga dapat mencatat yang lebih kecil dari keduanya, <span class="math inline">\(X^* = min(X, C_U)\)</span> . Untuk nilai-nilai <span class="math inline">\(x\)</span> yang lebih kecil dari <span class="math inline">\(C_U\)</span>, variabel indikator masih memberikan penaksir yang tidak bias terhadap fungsi distribusi sebelum kita mencapai batas penyensoran. Artinya, <span class="math inline">\(E [I(X^∗≤x)]=F(x)\)</span> karena <span class="math inline">\(I(X^∗≤x)=I(X≤x)\)</span> untuk <span class="math inline">\(x&lt;C_U\)</span> . Dengan cara yang sama, <span class="math inline">\(E[I(X^∗&gt;x)]=1-F(x)=S(x)\)</span> . Tetapi, untuk <span class="math inline">\(x&gt;C_U\)</span> , <span class="math inline">\(I(X^∗≤x)\)</span> secara umum bukan merupakan penaksir tak bias dari F(x). Sebagai alternatif, pertimbangkan dua peubah acak yang memiliki batas penyensoran yang berbeda. Sebagai ilustrasi, misalkan kita mengamati <span class="math inline">\(X^∗1=min(X_1,5)\)</span> dan <span class="math inline">\(X^∗2 = min(X_2,10)\)</span> di mana <span class="math inline">\(X_1\)</span> dan <span class="math inline">\(X_2\)</span> adalah undian independen dari distribusi yang sama. Untuk <span class="math inline">\(x≤5\)</span> fungsi distribusi empiris <span class="math inline">\(F_2(x)\)</span> adalah penaksir tak bias dari <span class="math inline">\(F(x)\)</span>. Akan tetapi, untuk <span class="math inline">\(5&lt;x≤10\)</span> pengamatan pertama tidak dapat digunakan untuk fungsi distribusi karena adanya batasan penyensoran. Sebagai gantinya, strategi yang dikembangkan oleh (Kaplan dan Meier 1958) adalah dengan menggunakan <span class="math inline">\(S_2(5)\)</span> sebagai penaksir dari <span class="math inline">\(S(5)\)</span> dan kemudian menggunakan observasi kedua untuk mengestimasi fungsi survival bersyarat pada kelangsungan hidup hingga waktu ke-5, <span class="math inline">\(Pr(X&gt;x|X&gt;5)=\frac{S(x)}{S(5)}\)</span> . Secara khusus, untuk <span class="math inline">\(5&lt;x≤10\)</span> penaksir dari fungsi survival adalah</p>
<p><span class="math display">\[
\begin{aligned}
\hat{S}(x) = S_2(5) \times I(X_2^* &gt; x )
\end{aligned}
\]</span></p>
<p><em>Kaplan-Meier Product Limit Estimator</em></p>
<p>Dengen memperluas ide dalam setiap observasi <code>i</code>,dengan <code>ui</code> menjadi batas atas penyensoran <span class="math inline">\((=∞) jikatidakadapenyensoran\)</span>. Dengan demikian, nilai yang tercatat adalah <code>xi</code> dalam kasus tidak ada penyensoran dan <code>ui</code> jika ada penyensoran. Dengan <span class="math inline">\(t_1&lt;⋯&lt;t_k\)</span>menjadi k titik berbeda di mana kerugian yang tidak disensor terjadi, dan biarkan <span class="math inline">\(s_j\)</span> adalah jumlah kerugian yang tidak tersensor <span class="math inline">\(x_i\)</span> yang tidak tersensor pada <span class="math inline">\(t_j\)</span>. Himpunan risiko yang sesuai adalah jumlah observasi yang aktif (tidak tersensor) pada nilai yang kurang dari <span class="math inline">\(t_j\)</span> yang dinotasikan sebagai
<span class="math inline">\(R_j = \sum_{i=1}^n I(x_i \geq t_{j}) + \sum_{i=1}^n I(u_i \geq t_{j})\)</span></p>
<p>Dengan notasi ini, penaksir product-limit dari fungsi distribusi</p>
<p><span class="math display">\[
\begin{equation}
\hat{F}(x) =
\left\{
\begin{array}{ll}
0 &amp; x&lt;t_{1} \\
1-\prod_{j:t_{j} \leq x}\left( 1-\frac{s_j}{R_{j}}\right) &amp; x \geq t_{1}
\end{array}
\right. .
\tag{4.6}
\end{equation}
\]</span></p>
<p>Sebagai contohnya, jika <code>x</code> lebih kecil dari kerugian terkecil yang tidak tersensor, maka <span class="math inline">\(x&lt;t1\)</span> dan <span class="math inline">\(F^(x)=0\)</span> . Sebagai contoh lain, jika <span class="math inline">\(x\)</span> berada di antara kerugian tersensor terkecil kedua dan ketiga, maka <span class="math inline">\(x∈(t_2,t_3]\)</span> dan <span class="math inline">\(\hat{F}(x) = 1 - \left(1- \frac{s_1}{R_{1}}\right)\left(1- \frac{s_2}{R_{2}}\right)\)</span> .Taksiran yang sesuai dari fungsi survival adalah <span class="math inline">\(\hat{S}(x) = 1 - \hat{F}(x)\)</span></p>
</div>
</div>
<div id="example-4.3.5.-actuarial-exam-question." class="section level3 hasAnchor" number="4.3.3">
<h3><span class="header-section-number">4.3.3</span> Example 4.3.5. Actuarial Exam Question.<a href="model-selection-and-estimation.html#example-4.3.5.-actuarial-exam-question." class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Berikut ini adalah contoh dari 10 pembayaran:</p>
<p><span class="math display">\[
4 \space \space 4 \space \space 5+\space \space 5+ \space\space 5+ \space\space 8 \space\space 10+ \space\space 10+ \space\space 12 \space\space 15
\]</span></p>
<p>dimana + menunjukkan bahwa kerugian telah melebihi batas polis.</p>
<p>Dengan menggunakan estimator batas produk Kaplan-Meier, hitunglah probabilitas bahwa kerugian pada suatu polis melebihi 11, <span class="math inline">\(\hat{S}(11)\)</span></p>
<p>Terdapat empat waktu kejadian (pengamatan yang tidak disensor). Untuk setiap waktu tj kita dapat menghitung jumlah kejadian sj dan himpunan risiko <span class="math inline">\(R_j\)</span> sebagai berikut:</p>
<p><img src="https://github.com/dsciencelabs/Analisa_Resiko/blob/main/images/example4.3.6-1.png?raw=true" width="300" height="300" style="display: block; margin-left: auto; margin-right: auto; margin-top: 10px;"></p>
<p>Dengan demikian, estimasi Kaplan-Meier dari S(11) adalah</p>
<p><span class="math display">\[
\begin{aligned}
\hat{S}(11) &amp;= \prod_{j:t_j\leq 11} \left( 1- \frac{s_j}{R_j} \right) =  \prod_{j=1}^{2} \left( 1- \frac{s_j}{R_j} \right)\\
&amp;= \left(1-\frac{2}{10} \right) \left(1-\frac{1}{5} \right) = (0.8)(0.8)= 0.64. \\
\end{aligned}
\]</span></p>
<p><em>Right-Censored, Left-Truncated Empirical Distribution Function</em></p>
<p>Selain penyensoran kanan, selanjutnya adalah memperluas kerangka kerja untuk memungkinkan data terpotong ke kiri. Seperti sebelumnya, untuk setiap observasi <code>i</code> , dengan <span class="math inline">\(u_i\)</span> menjadi batas penyensoran atas ( <span class="math inline">\(=∞\)</span> jika tidak ada penyensoran). Selanjutnya, <span class="math inline">\(d_i\)</span> merupakan batas pemotongan bawah (0 jika tidak ada pemotongan). Dengan demikian, nilai yang tercatat (jika lebih besar dari <span class="math inline">\(d_i\)</span> ) adalah <span class="math inline">\(x_i\)</span> dalam kasus tidak ada penyensoran dan <span class="math inline">\(u_i\)</span> jika ada penyensoran. Lalu untuk $t_1&lt;⋯&lt;t_k $menjadi <span class="math inline">\(k\)</span> titik-titik yang berbeda di mana sebuah kejadian yang menarik terjadi, dan biarkan <span class="math inline">\(s_j\)</span> adalah jumlah kejadian yang terekam <span class="math inline">\(x_i\)</span> pada titik waktu <span class="math inline">\(t_j\)</span>.</p>
<p>Himpunan risiko yang sesuai adalah</p>
<p><span class="math inline">\(R_j = \sum_{i=1}^n I(x_i \geq t_{j}) + \sum_{i=1}^n I(u_i \geq t_{j}) - \sum_{i=1}^n I(d_i \geq t_{j}).\)</span></p>
<p>Dengan definisi baru dari himpunan risiko ini, penaksir batas hasil kali dari fungsi distribusi adalah seperti pada persamaan product limit estimator.</p>
<p><em>Rumus Greenwood</em> (Greenwood 1926) menurunkan rumus untuk estimasi varians dari penaksir batas-produk menjadi</p>
<p><span class="math inline">\(\widehat{Var}(\hat{F}(x)) = (1-\hat{F}(x))^{2} \sum {j:t{j} \leq x} \dfrac{s_j}{R_{j}(R_{j}-s_j)}.\)</span></p>
<p>Seperti biasa, dapat mengacu pada akar kuadrat dari estimasi varians sebagai kesalahan standar, sebuah kuantitas yang secara rutin digunakan dalam interval kepercayaan dan untuk pengujian hipotesis. Untuk menghitungnya, metode <code>survfit R</code> mengambil sebuah objek data survival dan membuat sebuah objek baru yang berisi estimasi Kaplan-Meier dari fungsi survival bersama dengan interval kepercayaan. Metode Kaplan-Meier <code>(type='kaplan-meier')</code> digunakan secara default untuk membuat estimasi kurva survival. Fungsi survival diskrit yang dihasilkan memiliki massa titik pada waktu kejadian yang diamati (tanggal pelepasan) <span class="math inline">\(t_j\)</span> dimana probabilitas suatu kejadian yang diberi ketahanan hidup pada durasi tersebut diestimasi sebagai jumlah kejadian yang diamati pada durasi sj dibagi dengan jumlah subjek yang terpapar atau ‘berisiko’ sesaat sebelum durasi kejadian <span class="math inline">\(R_j\)</span>.</p>
<p><em>Penaksir Alternatif</em></p>
<p>Dua jenis estimasi alternatif juga tersedia untuk metode <code>survfit</code>. Alternatif pertama (<code>type='fh2'</code>) menangani hubungan, pada dasarnya, dengan mengasumsikan bahwa beberapa kejadian pada durasi yang sama terjadi dalam urutan yang berubah-ubah. Alternatif lain (<code>type='fleming-harrington'</code>) menggunakan estimasi Nelson-Aalen (Aalen 1978) dari fungsi hazard kumulatif untuk mendapatkan estimasi fungsi survival. Estimasi bahaya kumulatif <span class="math inline">\(H^(x)\)</span> dimulai dari nol dan bertambah pada setiap durasi kejadian yang diamati <span class="math inline">\(t_j\)</span> dengan jumlah kejadian <span class="math inline">\(s_j\)</span> dibagi dengan jumlah yang berisiko <span class="math inline">\(R_j\)</span>. Dengan notasi yang sama seperti di atas, penaksir Nelson-Äalen dari fungsi distribusi adalah</p>
<p><span class="math display">\[
\begin{aligned}
\hat{F}_{NA}(x) &amp;=
\left\{
\begin{array}{ll}
0 &amp; x&lt;t_{1} \\
1- \exp \left(-\sum_{j:t_{j} \leq x}\frac{s_j}{R_j} \right) &amp; x \geq t_{1}
\end{array}
\right. .\end{aligned}
\]</span></p>
<p>Itu merupakan hasil dari estimator Nelson-Äalen dari fungsi hazard kumulatif</p>
<p><span class="math inline">\(\hat{H}(x)=\sum_{j:t_j\leq x} \frac{s_j}{R_j}\)</span></p>
<p>dan hubungan antara fungsi survival dan fungsi hazard kumulatif,</p>
<p><span class="math inline">\(\hat{S}_{NA}(x)=e^{-\hat{H}(x)}\)</span></p>
</div>
</div>
<div id="bayesian-inference" class="section level2 hasAnchor" number="4.4">
<h2><span class="header-section-number">4.4</span> Bayesian Inference<a href="model-selection-and-estimation.html#bayesian-inference" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Penjelasan pada subbab ini:</p>
<ul>
<li>Jelaskan model Bayesian sebagai alternatif dari pendekatan frequentist dan rangkum lima komponen dari pendekatan pemodelan ini.</li>
<li>Ringkas distribusi parameter posterior dan gunakan distribusi posterior ini untuk memprediksi hasil baru.</li>
<li>Gunakan distribusi konjugat untuk menentukan distribusi parameter posterior.</li>
</ul>
<div id="introduction-to-bayesian-inference" class="section level3 hasAnchor" number="4.4.1">
<h3><span class="header-section-number">4.4.1</span> Introduction to Bayesian Inference<a href="model-selection-and-estimation.html#introduction-to-bayesian-inference" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Sampai saat ini, metode inferensial kami berfokus pada pengaturan frequentist , di mana sampel diambil berulang kali dari suatu populasi. Vektor parameter θ adalah tetap belum diketahui, sedangkan hasil X adalah realisasi variabel acak.</p>
<p>Sebaliknya, di bawah kerangka Bayesian , kami melihat parameter model dan data sebagai variabel acak. Kami tidak yakin tentang parameternya θ dan gunakan alat probabilitas untuk mencerminkan ketidakpastian ini.</p>
<p>Dibawah ini merupakan rumus aturan bayes:</p>
<p><img src="https://github.com/dsciencelabs/Analisa_Resiko/blob/main/images/4.4.1-1.png?raw=true" width="300" height="300" style="display: block; margin-left: auto; margin-right: auto; margin-top: 10px;"></p>
<p>Di mana,</p>
<ul>
<li>Pr(parameters): adalah distribusi parameter, yang dikenal sebagai distribusi sebelumnya .</li>
<li>Pr(data|parameters): adalah distribusi sampling. Dalam konteks frequentist, ini digunakan untuk membuat kesimpulan tentang parameter dan dikenal sebagai kemungkinan .</li>
<li>Pr(parameters|data):adalah distribusi parameter setelah mengamati data, yang dikenal sebagai distribusi posterior .</li>
<li>Pr(data): adalah distribusi marjinal dari data. Ini umumnya diperoleh dengan mengintegrasikan (atau menjumlahkan) distribusi gabungan data dan parameter di atas nilai parameter.</li>
</ul>
</div>
<div id="bayesian-model" class="section level3 hasAnchor" number="4.4.2">
<h3><span class="header-section-number">4.4.2</span> Bayesian Model<a href="model-selection-and-estimation.html#bayesian-model" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Distribusi Sebelumnya. Secara khusus, pikirkan tentang parameter θ sebagai vektor acak dan biarkan π( θ ) menunjukkan fungsi massa atau kepadatan yang sesuai. Ini adalah pengetahuan yang kita miliki sebelum hasil diamati dan disebut distribusi sebelumnya . Biasanya, distribusi sebelumnya adalah distribusi reguler dan terintegrasi atau dijumlahkan menjadi satu, tergantung pada apakah θ
kontinu atau diskrit. Namun, kami mungkin sangat tidak yakin (atau tidak tahu) tentang distribusinya θ ; mesin Bayesian memungkinkan situasi berikut</p>
<p><span class="math display">\[
\int \pi(\theta) ~d\theta = \infty,
\]</span>
dalam hal ini, <span class="math inline">\(\pi(\cdot)\)</span> disebut priot yang tidak tepat</p>
<p>Distribusi Bersama. Distribusi hasil dan parameter model adalah distribusi gabungan dari dua besaran acak. Fungsi kerapatan persendiannya dilambangkan sebagai</p>
<p><span class="math display">\[
f(x , \boldsymbol \theta) = f(x|\boldsymbol \theta )\pi(\boldsymbol \theta)
\]</span>
Distribusi Hasil Marginal. Distribusi hasil dapat dinyatakan sebagai</p>
<p><span class="math display">\[
f(x) = \int f(x | \boldsymbol \theta)\pi(\boldsymbol \theta) ~d \boldsymbol \theta.
\]</span></p>
<p>Ini analog dengan distribusi campuran frequentist. Dalam distribusi campuran, kami menggabungkan (atau “mencampur”) subpopulasi yang berbeda. Dalam konteks Bayesian, distribusi marjinal adalah kombinasi dari realisasi parameter yang berbeda (dalam beberapa literatur, Anda dapat menganggap ini sebagai kombinasi “keadaan alam” yang berbeda).</p>
<p>Distribusi Parameter Posterior. Setelah hasil diamati (karenanya terminologi “posterior”), seseorang dapat menggunakan teorema Bayes untuk menulis fungsi kerapatan sebagai</p>
<p><span class="math display">\[
\pi(\boldsymbol \theta | x) =\frac{f(x , \boldsymbol \theta)}{f(x)} =\frac{f(x|\boldsymbol \theta )\pi(\boldsymbol \theta)}{f(x)} .
\]</span></p>
</div>
<div id="bayesian-inference-1" class="section level3 hasAnchor" number="4.4.3">
<h3><span class="header-section-number">4.4.3</span> Bayesian Inference<a href="model-selection-and-estimation.html#bayesian-inference-1" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="summarizing-the-posterior-distributiob-of-paremeters" class="section level4 hasAnchor" number="4.4.3.1">
<h4><span class="header-section-number">4.4.3.1</span> Summarizing the Posterior Distributiob of Paremeters<a href="model-selection-and-estimation.html#summarizing-the-posterior-distributiob-of-paremeters" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Salah satu cara untuk meringkas distribusi adalah dengan menggunakan pernyataan tipe interval kepercayaan . Untuk meringkas distribusi parameter posterior , interval <span class="math inline">\([a,b]\)</span> dikatakan sebagai <span class="math inline">\(100(1-\alpha)\%\)</span> interval kredibilitas untuk <span class="math inline">\(\theta\)</span> jika</p>
<p><span class="math display">\[
\Pr (a \le \theta \le b | \mathbf{x}) \ge 1- \alpha.
\]</span></p>
<p>Estimasi Bayes adalah nilai yang meminimalkan kerugian yang diharapkan</p>
<p><span class="math display">\[
\mathrm{E~}[ l(\hat{\theta}, \theta)]
\]</span></p>
</div>
<div id="bayesian-predictive-distribution" class="section level4 hasAnchor" number="4.4.3.2">
<h4><span class="header-section-number">4.4.3.2</span> Bayesian Predictive Distribution<a href="model-selection-and-estimation.html#bayesian-predictive-distribution" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Untuk jenis inferensi statistik lainnya, seringkali menarik untuk “memprediksi” nilai hasil acak yang belum diamati. Khususnya untuk data baru y, distribusi prediktifnya adalah</p>
<p><span class="math display">\[
f(y|x) = \int f(y|\theta) \pi(\theta|x) d\theta .
\]</span></p>
<p>Ini juga kadang-kadang disebut distribusi “prediktif posterior” karena distribusi data baru tergantung pada kumpulan data dasar.</p>
<p>Menggunakan kerugian kesalahan kuadrat untuk fungsi kerugian, prediksi Bayesian dari Y adalah</p>
<p><span class="math display">\[
\begin{aligned}
\mathrm{E}(Y|X) &amp;=  \int ~y f(y|X) dy = \int y \left(\int f(y|\theta) \pi(\theta|X) d\theta \right) dy \\
&amp;= \int \left(\int y f(y|\theta)  ~dy \right) \pi(\theta|X) ~d\theta \\
&amp;=  \int  \mathrm{E}(Y|\theta) \pi(\theta|X) ~d\theta .
\end{aligned}
\]</span></p>
<p>Seperti disebutkan sebelumnya, untuk beberapa situasi distribusi parameter adalah diskrit, tidak kontinu. Memiliki serangkaian kemungkinan parameter yang terpisah memungkinkan kita untuk menganggapnya sebagai “keadaan alam” alternatif, sebuah interpretasi yang membantu.</p>
</div>
</div>
<div id="conjugate-distributions" class="section level3 hasAnchor" number="4.4.4">
<h3><span class="header-section-number">4.4.4</span> Conjugate Distributions<a href="model-selection-and-estimation.html#conjugate-distributions" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Untuk menghubungkan distribusi parameter sebelum dan sesudah, kami memiliki hubungan</p>
<p><span class="math display">\[
\begin{array}{ccc}
\pi(\boldsymbol \theta | x) &amp; = &amp; \frac{f(x|\boldsymbol \theta )\pi(\boldsymbol \theta)}{f(x)}  \\
&amp; \propto  &amp; f(x|\boldsymbol \theta ) \pi(\boldsymbol \theta) \\
\text{Posterior} &amp; \text{is proportional to} &amp; \text{likelihood} \times \text{prior} .
\end{array}
\]</span></p>
<p>Untuk distribusi konjugasi, posterior dan sebelumnya milik keluarga distribusi yang sama. Ilustrasi berikut melihat kasus khusus gamma-Poisson, yang paling terkenal dalam aplikasi aktuaria.</p>

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="modeling-loss-severity.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="aggregate-loss-models.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": true,
"twitter": true,
"linkedin": true,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/dsciencelabs/Analisa_Resiko/edit/master/chapters/04-ModelSelection.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["Analisa_Resiko.pdf", "Analisa_Resiko.epub"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
