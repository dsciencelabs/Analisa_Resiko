<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Bab 7 6.3 Cross Validation | Analisis Resiko</title>
  <meta name="description" content="Loss Data Analytics adalah teks yang interaktif, online, tersedia secara bebas. - Versi online akan berisi banyak objek interaktif (kuis, demonstrasi komputer, grafik interaktif, video, dan sejenisnya) untuk mempromosikan pembelajaran yang lebih dalam. - Sebagian dari buku ini akan tersedia dalam format pdf untuk pencetakan dengan biaya rendah. - Teks online akan tersedia dalam berbagai bahasa untuk mempromosikan akses ke audiens di seluruh dunia." />
  <meta name="generator" content="bookdown 0.34 and GitBook 2.6.7" />

  <meta property="og:title" content="Bab 7 6.3 Cross Validation | Analisis Resiko" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="Loss Data Analytics adalah teks yang interaktif, online, tersedia secara bebas. - Versi online akan berisi banyak objek interaktif (kuis, demonstrasi komputer, grafik interaktif, video, dan sejenisnya) untuk mempromosikan pembelajaran yang lebih dalam. - Sebagian dari buku ini akan tersedia dalam format pdf untuk pencetakan dengan biaya rendah. - Teks online akan tersedia dalam berbagai bahasa untuk mempromosikan akses ke audiens di seluruh dunia." />
  <meta name="github-repo" content="dsciencelabs/Bookdown-Tempalate_R" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Bab 7 6.3 Cross Validation | Analisis Resiko" />
  
  <meta name="twitter:description" content="Loss Data Analytics adalah teks yang interaktif, online, tersedia secara bebas. - Versi online akan berisi banyak objek interaktif (kuis, demonstrasi komputer, grafik interaktif, video, dan sejenisnya) untuk mempromosikan pembelajaran yang lebih dalam. - Sebagian dari buku ini akan tersedia dalam format pdf untuk pencetakan dengan biaya rendah. - Teks online akan tersedia dalam berbagai bahasa untuk mempromosikan akses ke audiens di seluruh dunia." />
  

<meta name="author" content="Bakti Siregar, M.Sc" />


<meta name="date" content="2023-05-22" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="simulation-and-resampling.html"/>
<link rel="next" href="importance-sampling.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />
<link href="libs/bsTable-3.3.7/bootstrapTable.min.css" rel="stylesheet" />
<script src="libs/bsTable-3.3.7/bootstrapTable.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
<link rel="stylesheet" href="toc.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><center><img src="images/Logo.png" alt="logo" width="50%" height="50%"style="margin: 15px 0 0 0"></center></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="kata-pengantar.html"><a href="kata-pengantar.html"><i class="fa fa-check"></i>Kata Pengantar</a>
<ul>
<li class="chapter" data-level="" data-path="kata-pengantar.html"><a href="kata-pengantar.html#deskripsi-buku"><i class="fa fa-check"></i>Deskripsi Buku</a>
<ul>
<li class="chapter" data-level="" data-path="kata-pengantar.html"><a href="kata-pengantar.html#petunjuk-penggunaan"><i class="fa fa-check"></i>Petunjuk Penggunaan</a></li>
<li class="chapter" data-level="" data-path="kata-pengantar.html"><a href="kata-pengantar.html#manfaat"><i class="fa fa-check"></i>Manfaat</a></li>
<li class="chapter" data-level="" data-path="kata-pengantar.html"><a href="kata-pengantar.html#mengapa-analisa-resiko"><i class="fa fa-check"></i>Mengapa Analisa Resiko?</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="kata-pengantar.html"><a href="kata-pengantar.html#ucapan-terima-kasih"><i class="fa fa-check"></i>Ucapan Terima Kasih</a></li>
<li class="chapter" data-level="" data-path="kata-pengantar.html"><a href="kata-pengantar.html#kontributor"><i class="fa fa-check"></i>Kontributor</a></li>
<li class="chapter" data-level="" data-path="kata-pengantar.html"><a href="kata-pengantar.html#kritik-saran"><i class="fa fa-check"></i>Kritik &amp; Saran</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="introduction-to-loss-data-analytics.html"><a href="introduction-to-loss-data-analytics.html"><i class="fa fa-check"></i><b>1</b> Introduction to Loss Data Analytics</a></li>
<li class="chapter" data-level="2" data-path="frequency-modeling.html"><a href="frequency-modeling.html"><i class="fa fa-check"></i><b>2</b> Frequency Modeling</a>
<ul>
<li class="chapter" data-level="2.1" data-path="frequency-modeling.html"><a href="frequency-modeling.html#goodness-of-fit"><i class="fa fa-check"></i><b>2.1</b> Goodness of Fit</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="modeling-loss-severity.html"><a href="modeling-loss-severity.html"><i class="fa fa-check"></i><b>3</b> Modeling Loss Severity</a>
<ul>
<li class="chapter" data-level="3.1" data-path="modeling-loss-severity.html"><a href="modeling-loss-severity.html#mdmmm"><i class="fa fa-check"></i><b>3.1</b> mdmmm</a></li>
<li class="chapter" data-level="3.2" data-path="modeling-loss-severity.html"><a href="modeling-loss-severity.html#mdmem"><i class="fa fa-check"></i><b>3.2</b> mdmem</a></li>
<li class="chapter" data-level="3.3" data-path="modeling-loss-severity.html"><a href="modeling-loss-severity.html#mdmm"><i class="fa fa-check"></i><b>3.3</b> mdmm</a></li>
<li class="chapter" data-level="3.4" data-path="modeling-loss-severity.html"><a href="modeling-loss-severity.html#modifikasi-pertanggungan"><i class="fa fa-check"></i><b>3.4</b> modifikasi pertanggungan</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="model-selection-and-estimation.html"><a href="model-selection-and-estimation.html"><i class="fa fa-check"></i><b>4</b> Model Selection and Estimation</a></li>
<li class="chapter" data-level="5" data-path="aggregate-loss-models.html"><a href="aggregate-loss-models.html"><i class="fa fa-check"></i><b>5</b> Aggregate Loss Models</a></li>
<li class="chapter" data-level="6" data-path="simulation-and-resampling.html"><a href="simulation-and-resampling.html"><i class="fa fa-check"></i><b>6</b> Simulation and Resampling</a></li>
<li class="chapter" data-level="7" data-path="cross-validation.html"><a href="cross-validation.html"><i class="fa fa-check"></i><b>7</b> 6.3 Cross Validation</a>
<ul>
<li class="chapter" data-level="7.1" data-path="cross-validation.html"><a href="cross-validation.html#k-fold-cross-validation"><i class="fa fa-check"></i><b>7.1</b> 6.3.1 k-Fold Cross-Validation</a></li>
<li class="chapter" data-level="7.2" data-path="cross-validation.html"><a href="cross-validation.html#leave-one-out-cross-validation"><i class="fa fa-check"></i><b>7.2</b> 6.3.2 Leave-One-Out Cross-Validation</a></li>
<li class="chapter" data-level="7.3" data-path="cross-validation.html"><a href="cross-validation.html#cross-validation-and-bootstrap"><i class="fa fa-check"></i><b>7.3</b> 6.3.3 Cross-Validation and Bootstrap</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="importance-sampling.html"><a href="importance-sampling.html"><i class="fa fa-check"></i><b>8</b> 6.4 Importance Sampling</a></li>
<li class="chapter" data-level="9" data-path="premium-foundations.html"><a href="premium-foundations.html"><i class="fa fa-check"></i><b>9</b> Premium Foundations</a></li>
<li class="chapter" data-level="10" data-path="risk-classification.html"><a href="risk-classification.html"><i class="fa fa-check"></i><b>10</b> Risk Classification</a></li>
<li class="chapter" data-level="11" data-path="experience-rating-using-credibility-theory.html"><a href="experience-rating-using-credibility-theory.html"><i class="fa fa-check"></i><b>11</b> Experience Rating Using Credibility Theory</a></li>
<li class="chapter" data-level="12" data-path="insurance-portfolio-management-including-reinsurance.html"><a href="insurance-portfolio-management-including-reinsurance.html"><i class="fa fa-check"></i><b>12</b> Insurance Portfolio Management including Reinsurance</a></li>
<li class="chapter" data-level="13" data-path="loss-reserving.html"><a href="loss-reserving.html"><i class="fa fa-check"></i><b>13</b> Loss Reserving</a></li>
<li class="chapter" data-level="14" data-path="experience-rating-using-bonus-malus.html"><a href="experience-rating-using-bonus-malus.html"><i class="fa fa-check"></i><b>14</b> Experience Rating using Bonus-Malus</a></li>
<li class="chapter" data-level="15" data-path="aggregate-loss-models-1.html"><a href="aggregate-loss-models-1.html"><i class="fa fa-check"></i><b>15</b> Aggregate Loss Models</a></li>
<li class="chapter" data-level="16" data-path="dependence-modeling.html"><a href="dependence-modeling.html"><i class="fa fa-check"></i><b>16</b> Dependence Modeling</a></li>
<li class="chapter" data-level="17" data-path="appendix-a-review-of-statistical-inference.html"><a href="appendix-a-review-of-statistical-inference.html"><i class="fa fa-check"></i><b>17</b> Appendix A: Review of Statistical Inference</a></li>
<li class="chapter" data-level="18" data-path="appendix-b-iterated-expectations.html"><a href="appendix-b-iterated-expectations.html"><i class="fa fa-check"></i><b>18</b> Appendix B: Iterated Expectations</a></li>
<li class="chapter" data-level="19" data-path="appendix-c-maximum-likelihood-theory.html"><a href="appendix-c-maximum-likelihood-theory.html"><i class="fa fa-check"></i><b>19</b> Appendix C: Maximum Likelihood Theory</a></li>
<li class="chapter" data-level="20" data-path="appendix-d-summary-of-distributions.html"><a href="appendix-d-summary-of-distributions.html"><i class="fa fa-check"></i><b>20</b> Appendix D: Summary of Distributions</a></li>
<li class="chapter" data-level="21" data-path="appendix-e-conventions-for-notation.html"><a href="appendix-e-conventions-for-notation.html"><i class="fa fa-check"></i><b>21</b> Appendix E: Conventions for Notation</a></li>
<li class="chapter" data-level="" data-path="bibliography.html"><a href="bibliography.html"><i class="fa fa-check"></i>Bibliography</a></li>
<li class="divider"></li>
<li><a href="https://github.com/dsciencelabs/Analisa_Resiko" target="blank">Published with Bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Analisis Resiko</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="cross-validation" class="section level1 hasAnchor" number="7">
<h1><span class="header-section-number">Bab 7</span> 6.3 Cross Validation<a href="cross-validation.html#cross-validation" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>Dalam bagian ini, kita akan mempelajari caranya:</p>
<ul>
<li><p>Membandingkan dan membedakan validasi silang dengan teknik simulasi dan metode bootstrap.</p></li>
<li><p>Menggunakan teknik validasi silang untuk pemilihan model</p></li>
<li><p>Menjelaskan metode jackknife sebagai kasus khusus validasi silang dan menghitung estimasi bias dan kesalahan standar jackknife</p></li>
</ul>
<p>Validasi silang, yang diperkenalkan secara singkat pada Bagian 4.2.4, adalah teknik yang didasarkan pada hasil simulasi. Sekarang kita akan membandingkan dan membedakan validasi silang dengan teknik simulasi lain yang telah diperkenalkan dalam bab ini.”</p>
<ul>
<li><p>Simulasi, atau Monte-Carlo, yang diperkenalkan pada Bagian 6.1, memungkinkan kita untuk menghitung nilai ekspektasi dan rangkuman distribusi statistik lainnya, seperti nilai-p, dengan mudah.</p></li>
<li><p>Bootstrap, dan metode resampling lainnya yang diperkenalkan pada Bagian 6.2, menyediakan estimator presisi, atau variabilitas, statistik.</p></li>
<li><p>Validasi silang penting ketika menilai seberapa akurat model prediktif akan bekerja dalam praktiknya.</p></li>
</ul>
<p>Tumpang tindih memang ada, namun tetap saja akan sangat membantu untuk memikirkan tujuan luas yang terkait dengan setiap metode statistik.</p>
<p>Untuk membahas validasi silang, mari kita ingat kembali dari Bagian 4.2 beberapa ide kunci dari validasi model. Ketika menilai, atau memvalidasi, sebuah model, kita melihat kinerja yang diukur pada data baru, atau setidaknya bukan data yang digunakan untuk mencocokkan model. Pendekatan klasik, yang dijelaskan di Bagian 4.2.3, adalah membagi sampel menjadi dua: satu bagian (dataset pelatihan) digunakan untuk menyesuaikan model dan bagian lainnya (dataset pengujian) digunakan untuk memvalidasi. Namun, keterbatasan dari pendekatan ini adalah bahwa hasilnya bergantung pada pembagian; meskipun keseluruhan sampel tetap, pembagian antara sub-sampel pelatihan dan pengujian bervariasi secara acak. Sampel pelatihan yang berbeda berarti parameter estimasi model akan berbeda. Parameter model yang berbeda dan sampel uji yang berbeda berarti statistik validasi akan berbeda. Dua orang analis dapat menggunakan data yang sama dan model yang sama, namun mencapai kesimpulan yang berbeda tentang kelayakan suatu model (berdasarkan pembagian acak yang berbeda), sebuah situasi yang membuat frustasi.</p>
<div id="k-fold-cross-validation" class="section level2 hasAnchor" number="7.1">
<h2><span class="header-section-number">7.1</span> 6.3.1 k-Fold Cross-Validation<a href="cross-validation.html#k-fold-cross-validation" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Untuk mengurangi kesulitan ini, biasanya digunakan pendekatan validasi silang seperti yang diperkenalkan di Bagian 4.2.4. Ide utamanya adalah meniru pendekatan pengujian/pelatihan dasar untuk validasi model dengan mengulanginya berkali-kali melalui rata-rata dari beberapa bagian data yang berbeda. Keuntungan utamanya adalah bahwa statistik validasi tidak terikat pada model parametrik (atau nonparametrik) tertentu - seseorang dapat menggunakan statistik nonparametrik atau statistik yang memiliki interpretasi ekonomi - sehingga dapat digunakan untuk membandingkan model yang tidak bersarang (tidak seperti prosedur rasio kemungkinan).</p>
<p><strong>Contoh 6.3.1. Dana Properti Wisconsin.</strong> Untuk data dana properti 2010 yang diperkenalkan pada Bagian 1.3, kami mencocokkan distribusi gamma dan Pareto dengan 1.377 data klaim. Untuk rincian kecocokan terkait, lihat Lampiran Bagian 15.4.4. Sekarang kita mempertimbangkan statistik Kolmogorov-Smirnov yang diperkenalkan di Bagian 4.1.2.2. Ketika seluruh dataset telah sesuai, statistik kecocokan Kolmogorov-Smirnov untuk distribusi gamma adalah 0,2639 dan untuk distribusi Pareto adalah 0,0478. Nilai yang lebih rendah untuk distribusi Pareto menunjukkan bahwa distribusi ini lebih cocok daripada gamma.</p>
<p>Untuk melihat bagaimana validasi silang k-lipatan bekerja, kami membagi data secara acak menjadi <span class="math inline">\(k=8\)</span> kelompok, atau lipatan, yang masing-masing memiliki sekitar <span class="math inline">\(1377/8≈172\)</span> pengamatan. Kemudian, kami mencocokkan model gamma dan Pareto pada set data dengan tujuh lipatan pertama (sekitar $172⋅7 = 120$4 pengamatan), menentukan estimasi parameter, dan kemudian menggunakan model-model yang cocok dengan data yang ditahan untuk menentukan statistik Kolmogorov-Smirnov.</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="cross-validation.html#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(VGAM)</span></code></pre></div>
<pre><code>## Loading required package: stats4</code></pre>
<pre><code>## Loading required package: splines</code></pre>
<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb4-1"><a href="cross-validation.html#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(MASS)</span>
<span id="cb4-2"><a href="cross-validation.html#cb4-2" aria-hidden="true" tabindex="-1"></a>claim_lev <span class="ot">&lt;-</span> <span class="fu">read.csv</span>(<span class="st">&quot;data/CLAIMLEVEL.csv&quot;</span>, <span class="at">header =</span> <span class="cn">TRUE</span>) </span>
<span id="cb4-3"><a href="cross-validation.html#cb4-3" aria-hidden="true" tabindex="-1"></a>claim_data <span class="ot">&lt;-</span> <span class="fu">subset</span>(claim_lev, Year <span class="sc">==</span> <span class="dv">2010</span>); </span>
<span id="cb4-4"><a href="cross-validation.html#cb4-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-5"><a href="cross-validation.html#cb4-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Randomly re-order the data - &quot;shuffle it&quot;</span></span>
<span id="cb4-6"><a href="cross-validation.html#cb4-6" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="fu">nrow</span>(claim_data)</span>
<span id="cb4-7"><a href="cross-validation.html#cb4-7" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">12347</span>)</span>
<span id="cb4-8"><a href="cross-validation.html#cb4-8" aria-hidden="true" tabindex="-1"></a>cvdata <span class="ot">&lt;-</span> claim_data[<span class="fu">sample</span>(n), ]</span>
<span id="cb4-9"><a href="cross-validation.html#cb4-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Number of folds</span></span>
<span id="cb4-10"><a href="cross-validation.html#cb4-10" aria-hidden="true" tabindex="-1"></a>k <span class="ot">&lt;-</span> <span class="dv">8</span></span>
<span id="cb4-11"><a href="cross-validation.html#cb4-11" aria-hidden="true" tabindex="-1"></a>cvalvec <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="dv">0</span>,<span class="dv">2</span>,k)</span>
<span id="cb4-12"><a href="cross-validation.html#cb4-12" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>k) {</span>
<span id="cb4-13"><a href="cross-validation.html#cb4-13" aria-hidden="true" tabindex="-1"></a>  indices <span class="ot">&lt;-</span> (((i<span class="dv">-1</span>) <span class="sc">*</span> <span class="fu">round</span>((<span class="dv">1</span><span class="sc">/</span>k)<span class="sc">*</span><span class="fu">nrow</span>(cvdata))) <span class="sc">+</span> <span class="dv">1</span>)<span class="sc">:</span>((i<span class="sc">*</span><span class="fu">round</span>((<span class="dv">1</span><span class="sc">/</span>k) <span class="sc">*</span> <span class="fu">nrow</span>(cvdata))))</span>
<span id="cb4-14"><a href="cross-validation.html#cb4-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Pareto</span></span>
<span id="cb4-15"><a href="cross-validation.html#cb4-15" aria-hidden="true" tabindex="-1"></a>  fit.pareto <span class="ot">&lt;-</span> <span class="fu">vglm</span>(Claim <span class="sc">~</span> <span class="dv">1</span>, paretoII, <span class="at">loc =</span> <span class="dv">0</span>, <span class="at">data =</span> cvdata[<span class="sc">-</span>indices,])</span>
<span id="cb4-16"><a href="cross-validation.html#cb4-16" aria-hidden="true" tabindex="-1"></a>  ksResultPareto <span class="ot">&lt;-</span> <span class="fu">ks.test</span>(cvdata[indices,]<span class="sc">$</span>Claim, <span class="st">&quot;pparetoII&quot;</span>, <span class="at">loc =</span> <span class="dv">0</span>, <span class="at">shape =</span> <span class="fu">exp</span>(<span class="fu">coef</span>(fit.pareto)[<span class="dv">2</span>]), </span>
<span id="cb4-17"><a href="cross-validation.html#cb4-17" aria-hidden="true" tabindex="-1"></a>        <span class="at">scale =</span> <span class="fu">exp</span>(<span class="fu">coef</span>(fit.pareto)[<span class="dv">1</span>]))</span>
<span id="cb4-18"><a href="cross-validation.html#cb4-18" aria-hidden="true" tabindex="-1"></a>  cvalvec[<span class="dv">1</span>,i] <span class="ot">&lt;-</span> ksResultPareto<span class="sc">$</span>statistic</span>
<span id="cb4-19"><a href="cross-validation.html#cb4-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Gamma</span></span>
<span id="cb4-20"><a href="cross-validation.html#cb4-20" aria-hidden="true" tabindex="-1"></a>  fit.gamma <span class="ot">&lt;-</span> <span class="fu">glm</span>(Claim <span class="sc">~</span> <span class="dv">1</span>, <span class="at">data =</span> cvdata[<span class="sc">-</span>indices,], <span class="at">family =</span> <span class="fu">Gamma</span>(<span class="at">link =</span> log)) </span>
<span id="cb4-21"><a href="cross-validation.html#cb4-21" aria-hidden="true" tabindex="-1"></a>  gamma_theta <span class="ot">&lt;-</span> <span class="fu">exp</span>(<span class="fu">coef</span>(fit.gamma)) <span class="sc">*</span> <span class="fu">gamma.dispersion</span>(fit.gamma)  </span>
<span id="cb4-22"><a href="cross-validation.html#cb4-22" aria-hidden="true" tabindex="-1"></a>  alpha <span class="ot">&lt;-</span> <span class="dv">1</span> <span class="sc">/</span> <span class="fu">gamma.dispersion</span>(fit.gamma)</span>
<span id="cb4-23"><a href="cross-validation.html#cb4-23" aria-hidden="true" tabindex="-1"></a>  ksResultGamma <span class="ot">&lt;-</span> <span class="fu">ks.test</span>(cvdata[indices,]<span class="sc">$</span>Claim, <span class="st">&quot;pgamma&quot;</span>, <span class="at">shape =</span> alpha, <span class="at">scale =</span> gamma_theta)</span>
<span id="cb4-24"><a href="cross-validation.html#cb4-24" aria-hidden="true" tabindex="-1"></a>  cvalvec[<span class="dv">2</span>,i] <span class="ot">&lt;-</span> ksResultGamma<span class="sc">$</span>statistic</span>
<span id="cb4-25"><a href="cross-validation.html#cb4-25" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb4-26"><a href="cross-validation.html#cb4-26" aria-hidden="true" tabindex="-1"></a>KScv <span class="ot">&lt;-</span> <span class="fu">rowSums</span>(cvalvec)<span class="sc">/</span>k</span></code></pre></div>
<p>Hasilnya tampak pada Gambar 6.12 di mana sumbu horizontal adalah Fold=1. Proses ini diulangi untuk tujuh lipatan lainnya. Hasil yang dirangkum dalam Gambar 6.12 menunjukkan bahwa Pareto secara konsisten memberikan distribusi prediktif yang lebih dapat diandalkan daripada gamma.</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb5-1"><a href="cross-validation.html#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the statistics</span></span>
<span id="cb5-2"><a href="cross-validation.html#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="fu">matplot</span>(<span class="dv">1</span><span class="sc">:</span>k,<span class="fu">t</span>(cvalvec),<span class="at">type=</span><span class="st">&quot;b&quot;</span>, <span class="at">col=</span><span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">3</span>), <span class="at">lty=</span><span class="dv">1</span><span class="sc">:</span><span class="dv">2</span>, </span>
<span id="cb5-3"><a href="cross-validation.html#cb5-3" aria-hidden="true" tabindex="-1"></a>        <span class="at">ylim=</span><span class="fu">c</span>(<span class="dv">0</span>,<span class="fl">0.4</span>), <span class="at">pch =</span> <span class="dv">0</span>, <span class="at">xlab=</span><span class="st">&quot;Fold&quot;</span>, <span class="at">ylab=</span><span class="st">&quot;KS Statistic&quot;</span>)</span>
<span id="cb5-4"><a href="cross-validation.html#cb5-4" aria-hidden="true" tabindex="-1"></a><span class="fu">legend</span>(<span class="st">&quot;left&quot;</span>, <span class="fu">c</span>(<span class="st">&quot;Pareto&quot;</span>, <span class="st">&quot;Gamma&quot;</span>), <span class="at">col=</span><span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">3</span>),<span class="at">lty=</span><span class="dv">1</span><span class="sc">:</span><span class="dv">2</span>, <span class="at">bty=</span><span class="st">&quot;n&quot;</span>)</span></code></pre></div>
<img src="Analisa_Resiko_files/figure-html/unnamed-chunk-2-1.png" width="672" />
<p class="caption">
“Figure 6.2:”
<strong>
Statistik Kolmogorov-Smirnov (KS) yang telah divalidasi silang untuk Data Klaim Dana Asuransi.
</strong>
Garis hitam solid untuk distribusi Pareto, garis putus-putus hijau untuk distribusi gamma. Statistik KS mengukur deviasi terbesar antara distribusi yang sesuai dengan distribusi empiris untuk masing-masing dari 8 kelompok, atau lipatan, data yang dipilih secara acak.
</p>
</div>
<div id="leave-one-out-cross-validation" class="section level2 hasAnchor" number="7.2">
<h2><span class="header-section-number">7.2</span> 6.3.2 Leave-One-Out Cross-Validation<a href="cross-validation.html#leave-one-out-cross-validation" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Kasus khusus di mana <span class="math inline">\(k=n\)</span> dikenal sebagai validasi silang tinggalkan-satu-keluar. Kasus ini secara historis sangat menonjol dan terkait erat dengan jackknifestatistik yang merupakan pendahulu dari teknik bootstrap.</p>
<p>Meskipun kita menyajikannya sebagai kasus khusus validasi silang, akan sangat membantu jika kami memberikan definisi eksplisit. Pertimbangkan sebuah statistik umum <span class="math inline">\(θˆ = t(x)\)</span> yang merupakan penaksir untuk sebuah parameter yang diminati <span class="math inline">\(θ\)</span>. Ide dari jackknife adalah menghitung n nilai <span class="math inline">\(θˆ_{-i} = t(x-i)\)</span>, di mana <span class="math inline">\(x-i\)</span> adalah subsampel dari <span class="math inline">\(x\)</span> dengan nilai <span class="math inline">\(ke-i\)</span> dihilangkan. Rata-rata dari nilai-nilai ini dilambangkan sebagai</p>
<p><span class="math display">\[\overline{\widehat{\theta}}_{(\cdot)}=\frac{1}{n}\sum_{i=1}^n \widehat{\theta}_{-i} .\]</span></p>
<p>Nilai-nilai ini dapat digunakan untuk membuat estimasi bias dari statistik <span class="math inline">\(\hatθ\)</span></p>
<p><span class="math display">\[\begin{equation}
Bias_{jack} = (n-1) \left(\overline{\widehat{\theta}}_{(\cdot)} - \widehat{\theta}\right)
\tag{6.3}
\end{equation}\]</span></p>
<p>serta estimasi standar deviasi</p>
<p><span class="math display">\[\begin{equation}
s_{jack} =\sqrt{\frac{n-1}{n}\sum_{i=1}^n \left(\widehat{\theta}_{-i} -\overline{\widehat{\theta}}_{(\cdot)}\right)^2} ~.
\tag{6.4}
\end{equation}\]</span></p>
<p><strong>Contoh 6.3.2. Koefisien Variasi.</strong> Sebagai ilustrasi, pertimbangkan sebuah sampel fiktif kecil <span class="math inline">\(x = {x_1,...,x_n}\)</span> dengan realisasi</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb6-1"><a href="cross-validation.html#cb6-1" aria-hidden="true" tabindex="-1"></a>sample_x <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fl">2.46</span>,<span class="fl">2.80</span>,<span class="fl">3.28</span>,<span class="fl">3.86</span>,<span class="fl">2.85</span>,<span class="fl">3.67</span>,<span class="fl">3.37</span>,<span class="fl">3.40</span>,</span>
<span id="cb6-2"><a href="cross-validation.html#cb6-2" aria-hidden="true" tabindex="-1"></a>              <span class="fl">5.22</span>,<span class="fl">2.55</span>,<span class="fl">2.79</span>,<span class="fl">4.50</span>,<span class="fl">3.37</span>,<span class="fl">2.88</span>,<span class="fl">1.44</span>,<span class="fl">2.56</span>,<span class="fl">2.00</span>,<span class="fl">2.07</span>,<span class="fl">2.19</span>,<span class="fl">1.77</span>)</span></code></pre></div>
<p>Misalkan kita tertarik dengan <span class="math inline">\(\theta = CV = \sqrt{\mathrm{Var~}[X]}/\mathrm{E~}[X]\)</span></p>
<p>Dengan dataset ini, estimator koefisien variasi menjadi 0,31196. Namun, seberapa handalkah estimasi tersebut? Untuk menjawab pertanyaan ini, kita dapat menghitung estimator pisau lipat dari bias dan deviasi standarnya. Kode berikut ini menunjukkan bahwa penaksir jackknife untuk bias adalah <span class="math inline">\(Bias_{jack} = -0,00627\)</span> dan standar deviasi jackknife adalah <span class="math inline">\(s_{jack} = 0,01293\)</span>.</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb7-1"><a href="cross-validation.html#cb7-1" aria-hidden="true" tabindex="-1"></a>CVar <span class="ot">&lt;-</span> <span class="cf">function</span>(x) <span class="fu">sqrt</span>(<span class="fu">var</span>(x))<span class="sc">/</span><span class="fu">mean</span>(x)</span>
<span id="cb7-2"><a href="cross-validation.html#cb7-2" aria-hidden="true" tabindex="-1"></a>JackCVar <span class="ot">&lt;-</span> <span class="cf">function</span>(i) <span class="fu">sqrt</span>(<span class="fu">var</span>(sample_x[<span class="sc">-</span>i]))<span class="sc">/</span><span class="fu">mean</span>(sample_x[<span class="sc">-</span>i])</span>
<span id="cb7-3"><a href="cross-validation.html#cb7-3" aria-hidden="true" tabindex="-1"></a>JackTheta <span class="ot">&lt;-</span> <span class="fu">Vectorize</span>(JackCVar)(<span class="dv">1</span><span class="sc">:</span><span class="fu">length</span>(sample_x))</span>
<span id="cb7-4"><a href="cross-validation.html#cb7-4" aria-hidden="true" tabindex="-1"></a>BiasJack <span class="ot">&lt;-</span> (<span class="fu">length</span>(sample_x)<span class="sc">-</span><span class="dv">1</span>)<span class="sc">*</span>(<span class="fu">mean</span>(JackTheta) <span class="sc">-</span> <span class="fu">CVar</span>(sample_x))</span>
<span id="cb7-5"><a href="cross-validation.html#cb7-5" aria-hidden="true" tabindex="-1"></a><span class="fu">sd</span>(JackTheta)</span></code></pre></div>
<pre><code>## [1] 0.01293001</code></pre>
<p><strong>Contoh 6.3.3. Klaim Cidera Badan dan Rasio Eliminasi Kerugian.</strong> Pada Contoh 6.2.1, kita telah menunjukkan bagaimana menghitung estimasi bootstrap dari bias dan deviasi standar untuk rasio eliminasi kerugian dengan menggunakan data klaim cedera badan pada Contoh 4.1.11. Sekarang kita menindaklanjuti dengan memberikan jumlah yang sebanding dengan menggunakan statistik jackknife.</p>
<p>Tabel 6.7 merangkum hasil estimasi jackknife. Tabel ini menunjukkan bahwa estimasi jackknife terhadap bias dan deviasi standar dari rasio eliminasi kerugian <span class="math inline">\(E [min (X, d)]/E [X]\)</span> sebagian besar konsisten dengan metodologi bootstrap. Selain itu, kita dapat menggunakan standar deviasi untuk membangun interval kepercayaan berbasis normal, yang berpusat di sekitar penaksir yang dikoreksi bias. Sebagai contoh, pada <span class="math inline">\(d = 14000\)</span>, kita melihat pada Contoh 4.1.11 bahwa estimasi nonparametrik dari <span class="math inline">\(LER\)</span> adalah 0.97678. Estimasi ini memiliki bias sebesar 0,00010, sehingga menghasilkan estimator terkoreksi-bias sebesar 0,97688. Interval kepercayaan 95% dihasilkan dengan membuat interval dua kali panjang 1,96 deviasi standar jackknife, yang berpusat pada estimator terkoreksi bias (1,96 adalah perkiraan kuantil ke-97,5 dari distribusi normal standar).</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb9-1"><a href="cross-validation.html#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(boot)</span></code></pre></div>
<pre><code>## 
## Attaching package: &#39;boot&#39;</code></pre>
<pre><code>## The following objects are masked from &#39;package:VGAM&#39;:
## 
##     logit, simplex</code></pre>
<div class="sourceCode" id="cb12"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb12-1"><a href="cross-validation.html#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Example from Derrig et al</span></span>
<span id="cb12-2"><a href="cross-validation.html#cb12-2" aria-hidden="true" tabindex="-1"></a>BIData <span class="ot">&lt;-</span> <span class="fu">read.csv</span>(<span class="st">&quot;data/DerrigResampling.csv&quot;</span>, <span class="at">header =</span>T)</span>
<span id="cb12-3"><a href="cross-validation.html#cb12-3" aria-hidden="true" tabindex="-1"></a>BIData<span class="sc">$</span>Censored <span class="ot">&lt;-</span> <span class="dv">1</span><span class="sc">*</span>(BIData<span class="sc">$</span>AmountPaid <span class="sc">&gt;=</span> BIData<span class="sc">$</span>PolicyLimit)</span>
<span id="cb12-4"><a href="cross-validation.html#cb12-4" aria-hidden="true" tabindex="-1"></a>BIDataUncensored <span class="ot">&lt;-</span> <span class="fu">subset</span>(BIData, Censored <span class="sc">==</span> <span class="dv">0</span>)</span>
<span id="cb12-5"><a href="cross-validation.html#cb12-5" aria-hidden="true" tabindex="-1"></a>LER.boot <span class="ot">&lt;-</span> <span class="cf">function</span>(ded, data, indices){</span>
<span id="cb12-6"><a href="cross-validation.html#cb12-6" aria-hidden="true" tabindex="-1"></a>  resample.data <span class="ot">&lt;-</span> data[indices,]</span>
<span id="cb12-7"><a href="cross-validation.html#cb12-7" aria-hidden="true" tabindex="-1"></a>  sumClaims <span class="ot">&lt;-</span> <span class="fu">sum</span>(resample.data<span class="sc">$</span>AmountPaid)</span>
<span id="cb12-8"><a href="cross-validation.html#cb12-8" aria-hidden="true" tabindex="-1"></a>  sumClaims_d <span class="ot">&lt;-</span> <span class="fu">sum</span>(<span class="fu">pmin</span>(resample.data<span class="sc">$</span>AmountPaid,ded))</span>
<span id="cb12-9"><a href="cross-validation.html#cb12-9" aria-hidden="true" tabindex="-1"></a>  LER <span class="ot">&lt;-</span>   sumClaims_d<span class="sc">/</span>sumClaims</span>
<span id="cb12-10"><a href="cross-validation.html#cb12-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(LER)  </span>
<span id="cb12-11"><a href="cross-validation.html#cb12-11" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb12-12"><a href="cross-validation.html#cb12-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-13"><a href="cross-validation.html#cb12-13" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> BIDataUncensored<span class="sc">$</span>AmountPaid</span>
<span id="cb12-14"><a href="cross-validation.html#cb12-14" aria-hidden="true" tabindex="-1"></a>LER.jack<span class="ot">&lt;-</span> <span class="cf">function</span>(ded,i){</span>
<span id="cb12-15"><a href="cross-validation.html#cb12-15" aria-hidden="true" tabindex="-1"></a>  LER <span class="ot">&lt;-</span>   <span class="fu">sum</span>(<span class="fu">pmin</span>(x[<span class="sc">-</span>i],ded))<span class="sc">/</span><span class="fu">sum</span>(x[<span class="sc">-</span>i])</span>
<span id="cb12-16"><a href="cross-validation.html#cb12-16" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(LER)  </span>
<span id="cb12-17"><a href="cross-validation.html#cb12-17" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb12-18"><a href="cross-validation.html#cb12-18" aria-hidden="true" tabindex="-1"></a>LER <span class="ot">&lt;-</span> <span class="cf">function</span>(ded) <span class="fu">sum</span>(<span class="fu">pmin</span>(x,ded))<span class="sc">/</span><span class="fu">sum</span>(x)</span>
<span id="cb12-19"><a href="cross-validation.html#cb12-19" aria-hidden="true" tabindex="-1"></a><span class="do">##Derrig et al</span></span>
<span id="cb12-20"><a href="cross-validation.html#cb12-20" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">2019</span>)</span>
<span id="cb12-21"><a href="cross-validation.html#cb12-21" aria-hidden="true" tabindex="-1"></a>dVec2 <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">4000</span>, <span class="dv">5000</span>, <span class="dv">10500</span>, <span class="dv">11500</span>, <span class="dv">14000</span>, <span class="dv">18500</span>)</span>
<span id="cb12-22"><a href="cross-validation.html#cb12-22" aria-hidden="true" tabindex="-1"></a>OutJack <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="dv">0</span>,<span class="fu">length</span>(dVec2),<span class="dv">8</span>)</span>
<span id="cb12-23"><a href="cross-validation.html#cb12-23" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> (j <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="fu">length</span>(dVec2)) {</span>
<span id="cb12-24"><a href="cross-validation.html#cb12-24" aria-hidden="true" tabindex="-1"></a>OutJack[j,<span class="dv">1</span>] <span class="ot">&lt;-</span> dVec2[j]</span>
<span id="cb12-25"><a href="cross-validation.html#cb12-25" aria-hidden="true" tabindex="-1"></a>results <span class="ot">&lt;-</span> <span class="fu">boot</span>(<span class="at">data=</span>BIDataUncensored, <span class="at">statistic=</span>LER.boot, <span class="at">R=</span><span class="dv">1000</span>, <span class="at">ded=</span>dVec2[j])</span>
<span id="cb12-26"><a href="cross-validation.html#cb12-26" aria-hidden="true" tabindex="-1"></a>OutJack[j,<span class="dv">2</span>] <span class="ot">&lt;-</span> results<span class="sc">$</span>t0</span>
<span id="cb12-27"><a href="cross-validation.html#cb12-27" aria-hidden="true" tabindex="-1"></a>biasboot <span class="ot">&lt;-</span> <span class="fu">mean</span>(results<span class="sc">$</span>t)<span class="sc">-</span>results<span class="sc">$</span>t0 <span class="ot">-&gt;</span> OutJack[j,<span class="dv">3</span>]</span>
<span id="cb12-28"><a href="cross-validation.html#cb12-28" aria-hidden="true" tabindex="-1"></a>sdboot <span class="ot">&lt;-</span> <span class="fu">sd</span>(results<span class="sc">$</span>t) <span class="ot">-&gt;</span> OutJack[j,<span class="dv">4</span>]</span>
<span id="cb12-29"><a href="cross-validation.html#cb12-29" aria-hidden="true" tabindex="-1"></a>temp <span class="ot">&lt;-</span> <span class="fu">boot.ci</span>(results)</span>
<span id="cb12-30"><a href="cross-validation.html#cb12-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-31"><a href="cross-validation.html#cb12-31" aria-hidden="true" tabindex="-1"></a>LER.jack.ded<span class="ot">&lt;-</span> <span class="cf">function</span>(i) <span class="fu">LER.jack</span>(<span class="at">ded=</span>dVec2[j],i)</span>
<span id="cb12-32"><a href="cross-validation.html#cb12-32" aria-hidden="true" tabindex="-1"></a>JackTheta.ded <span class="ot">&lt;-</span> <span class="fu">Vectorize</span>(LER.jack.ded)(<span class="dv">1</span><span class="sc">:</span><span class="fu">length</span>(x))</span>
<span id="cb12-33"><a href="cross-validation.html#cb12-33" aria-hidden="true" tabindex="-1"></a>OutJack[j,<span class="dv">5</span>] <span class="ot">&lt;-</span> BiasJack.ded <span class="ot">&lt;-</span> (<span class="fu">length</span>(x)<span class="sc">-</span><span class="dv">1</span>)<span class="sc">*</span>(<span class="fu">mean</span>(JackTheta.ded) <span class="sc">-</span> <span class="fu">LER</span>(<span class="at">ded=</span>dVec2[j]))</span>
<span id="cb12-34"><a href="cross-validation.html#cb12-34" aria-hidden="true" tabindex="-1"></a>OutJack[j,<span class="dv">6</span>] <span class="ot">&lt;-</span> <span class="fu">sd</span>(JackTheta.ded)</span>
<span id="cb12-35"><a href="cross-validation.html#cb12-35" aria-hidden="true" tabindex="-1"></a>OutJack[j,<span class="dv">7</span><span class="sc">:</span><span class="dv">8</span>] <span class="ot">&lt;-</span> <span class="fu">mean</span>(JackTheta.ded)<span class="sc">+</span><span class="fu">qt</span>(<span class="fu">c</span>(<span class="fl">0.025</span>,<span class="fl">0.975</span>),<span class="fu">length</span>(x)<span class="sc">-</span><span class="dv">1</span>)<span class="sc">*</span>OutJack[j,<span class="dv">6</span>]</span>
<span id="cb12-36"><a href="cross-validation.html#cb12-36" aria-hidden="true" tabindex="-1"></a>  }</span></code></pre></div>
<p><a id=tab:67></a></p>
<p>Table 6.7. <strong>Estimasi Jackknife dari LER pada Deductible yang Dipilih</strong></p>
<table class="table table-striped table-hover table-condensed table-responsive" style="font-size: 10px; margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:right;">
d
</th>
<th style="text-align:right;">
NP Estimate
</th>
<th style="text-align:right;">
Bootstrap Bias
</th>
<th style="text-align:right;">
Bootstrap SD
</th>
<th style="text-align:right;">
Jackknife Bias
</th>
<th style="text-align:right;">
Jackknife SD
</th>
<th style="text-align:right;">
Lower Jackknife 95% CI
</th>
<th style="text-align:right;">
Upper Jackknife 95% CI
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right;">
4000
</td>
<td style="text-align:right;">
0.54113
</td>
<td style="text-align:right;">
0.00011
</td>
<td style="text-align:right;">
0.01237
</td>
<td style="text-align:right;">
0.00031
</td>
<td style="text-align:right;">
0.00061
</td>
<td style="text-align:right;">
0.53993
</td>
<td style="text-align:right;">
0.54233
</td>
</tr>
<tr>
<td style="text-align:right;">
5000
</td>
<td style="text-align:right;">
0.64960
</td>
<td style="text-align:right;">
0.00027
</td>
<td style="text-align:right;">
0.01412
</td>
<td style="text-align:right;">
0.00033
</td>
<td style="text-align:right;">
0.00068
</td>
<td style="text-align:right;">
0.64825
</td>
<td style="text-align:right;">
0.65094
</td>
</tr>
<tr>
<td style="text-align:right;">
10500
</td>
<td style="text-align:right;">
0.93563
</td>
<td style="text-align:right;">
0.00004
</td>
<td style="text-align:right;">
0.01017
</td>
<td style="text-align:right;">
0.00019
</td>
<td style="text-align:right;">
0.00053
</td>
<td style="text-align:right;">
0.93460
</td>
<td style="text-align:right;">
0.93667
</td>
</tr>
<tr>
<td style="text-align:right;">
11500
</td>
<td style="text-align:right;">
0.95281
</td>
<td style="text-align:right;">
-0.00003
</td>
<td style="text-align:right;">
0.00941
</td>
<td style="text-align:right;">
0.00016
</td>
<td style="text-align:right;">
0.00047
</td>
<td style="text-align:right;">
0.95189
</td>
<td style="text-align:right;">
0.95373
</td>
</tr>
<tr>
<td style="text-align:right;">
14000
</td>
<td style="text-align:right;">
0.97678
</td>
<td style="text-align:right;">
0.00016
</td>
<td style="text-align:right;">
0.00687
</td>
<td style="text-align:right;">
0.00010
</td>
<td style="text-align:right;">
0.00034
</td>
<td style="text-align:right;">
0.97612
</td>
<td style="text-align:right;">
0.97745
</td>
</tr>
<tr>
<td style="text-align:right;">
18500
</td>
<td style="text-align:right;">
0.99382
</td>
<td style="text-align:right;">
0.00014
</td>
<td style="text-align:right;">
0.00331
</td>
<td style="text-align:right;">
0.00003
</td>
<td style="text-align:right;">
0.00017
</td>
<td style="text-align:right;">
0.99350
</td>
<td style="text-align:right;">
0.99415
</td>
</tr>
</tbody>
</table>
<p>Diskusi. Salah satu dari banyak hal menarik tentang kasus khusus leave-one-out adalah kemampuan untuk mereplikasi estimasi dengan tepat. Artinya, ketika ukuran lipatan hanya satu, maka tidak ada ketidakpastian tambahan yang disebabkan oleh validasi silang. Ini berarti bahwa para analis dapat mereplikasi pekerjaan satu sama lain dengan tepat, sebuah pertimbangan yang penting.</p>
<p>Statistik Jackknife dikembangkan untuk memahami ketepatan estimator, menghasilkan estimator bias dan deviasi standar pada persamaan (6.3) dan (6.4). Hal ini sesuai dengan tujuan yang telah kita kaitkan dengan teknik bootstrap, bukan metode validasi silang. Hal ini menunjukkan bagaimana teknik statistik dapat digunakan untuk mencapai tujuan yang berbeda.</p>
</div>
<div id="cross-validation-and-bootstrap" class="section level2 hasAnchor" number="7.3">
<h2><span class="header-section-number">7.3</span> 6.3.3 Cross-Validation and Bootstrap<a href="cross-validation.html#cross-validation-and-bootstrap" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Bootstrap berguna untuk memberikan estimator presisi, atau variabilitas, dari statistik. Hal ini juga berguna untuk validasi model. Pendekatan bootstrap untuk validasi model mirip dengan prosedur validasi leave-one-out dan <em>k</em>-fold:</p>
<ul>
<li><p>Buat sampel bootstrap dengan mengambil sampel ulang (dengan penggantian) <span class="math inline">\(n\)</span> indeks dalam <span class="math inline">\({1, ⋯, n}\)</span>. Ini akan menjadi sampel pelatihan kita. Perkirakan model yang sedang dipertimbangkan berdasarkan sampel ini.</p></li>
<li><p><em>Uji</em>, atau <em>sampel validasi</em>, terdiri dari pengamatan yang tidak dipilih untuk pelatihan. Mengevaluasi model yang cocok (berdasarkan data pelatihan) dengan menggunakan data uji.</p></li>
</ul>
<p>Ulangi proses ini beberapa kali (katakanlah <span class="math inline">\(B\)</span>). Ambil rata-rata dari hasil-hasilnya dan pilih model berdasarkan statistik evaluasi rata-rata.</p>
<p><strong>Contoh 6.3.4. Dana Properti Wisconsin</strong>. Kembali ke Contoh 6.3.1 di mana kita menyelidiki kecocokan distribusi gamma dan Pareto pada data dana properti. Kita kembali membandingkan kinerja prediksi menggunakan statistik Kolmogorov-Smirnov (KS), namun kali ini menggunakan prosedur bootstrap untuk membagi data antara sampel pelatihan dan pengujian. Berikut ini adalah kode ilustrasinya.</p>
<div class="sourceCode" id="cb13"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb13-1"><a href="cross-validation.html#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(goftest)</span>
<span id="cb13-2"><a href="cross-validation.html#cb13-2" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="fu">nrow</span>(claim_data)</span>
<span id="cb13-3"><a href="cross-validation.html#cb13-3" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">12347</span>)</span>
<span id="cb13-4"><a href="cross-validation.html#cb13-4" aria-hidden="true" tabindex="-1"></a>indices <span class="ot">&lt;-</span> <span class="dv">1</span><span class="sc">:</span>n</span>
<span id="cb13-5"><a href="cross-validation.html#cb13-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Number of Bootstrap Samples</span></span>
<span id="cb13-6"><a href="cross-validation.html#cb13-6" aria-hidden="true" tabindex="-1"></a>B <span class="ot">&lt;-</span> <span class="dv">100</span></span>
<span id="cb13-7"><a href="cross-validation.html#cb13-7" aria-hidden="true" tabindex="-1"></a>cvalvec <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="dv">0</span>,<span class="dv">2</span>,B)</span>
<span id="cb13-8"><a href="cross-validation.html#cb13-8" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>B) {</span>
<span id="cb13-9"><a href="cross-validation.html#cb13-9" aria-hidden="true" tabindex="-1"></a>  bootindex <span class="ot">&lt;-</span> <span class="fu">unique</span>(<span class="fu">sample</span>(indices, <span class="at">size=</span>n, <span class="at">replace=</span> <span class="cn">TRUE</span>))</span>
<span id="cb13-10"><a href="cross-validation.html#cb13-10" aria-hidden="true" tabindex="-1"></a>  traindata <span class="ot">&lt;-</span> claim_data[bootindex,]</span>
<span id="cb13-11"><a href="cross-validation.html#cb13-11" aria-hidden="true" tabindex="-1"></a>  testdata  <span class="ot">&lt;-</span> claim_data[<span class="sc">-</span>bootindex,]</span>
<span id="cb13-12"><a href="cross-validation.html#cb13-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Pareto</span></span>
<span id="cb13-13"><a href="cross-validation.html#cb13-13" aria-hidden="true" tabindex="-1"></a>  fit.pareto <span class="ot">&lt;-</span> <span class="fu">vglm</span>(Claim <span class="sc">~</span> <span class="dv">1</span>, paretoII, <span class="at">loc =</span> <span class="dv">0</span>, <span class="at">data =</span> traindata)</span>
<span id="cb13-14"><a href="cross-validation.html#cb13-14" aria-hidden="true" tabindex="-1"></a>  ksResultPareto <span class="ot">&lt;-</span> <span class="fu">ks.test</span>(testdata<span class="sc">$</span>Claim, <span class="st">&quot;pparetoII&quot;</span>, <span class="at">loc =</span> <span class="dv">0</span>, <span class="at">shape =</span> <span class="fu">exp</span>(<span class="fu">coef</span>(fit.pareto)[<span class="dv">2</span>]), </span>
<span id="cb13-15"><a href="cross-validation.html#cb13-15" aria-hidden="true" tabindex="-1"></a>        <span class="at">scale =</span> <span class="fu">exp</span>(<span class="fu">coef</span>(fit.pareto)[<span class="dv">1</span>]))</span>
<span id="cb13-16"><a href="cross-validation.html#cb13-16" aria-hidden="true" tabindex="-1"></a>  cvalvec[<span class="dv">1</span>,i] <span class="ot">&lt;-</span> ksResultPareto<span class="sc">$</span>statistic</span>
<span id="cb13-17"><a href="cross-validation.html#cb13-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Gamma</span></span>
<span id="cb13-18"><a href="cross-validation.html#cb13-18" aria-hidden="true" tabindex="-1"></a>  fit.gamma <span class="ot">&lt;-</span> <span class="fu">glm</span>(Claim <span class="sc">~</span> <span class="dv">1</span>, <span class="at">data =</span> traindata, <span class="at">family =</span> <span class="fu">Gamma</span>(<span class="at">link =</span> log)) </span>
<span id="cb13-19"><a href="cross-validation.html#cb13-19" aria-hidden="true" tabindex="-1"></a>  gamma_theta <span class="ot">&lt;-</span> <span class="fu">exp</span>(<span class="fu">coef</span>(fit.gamma)) <span class="sc">*</span> <span class="fu">gamma.dispersion</span>(fit.gamma)  </span>
<span id="cb13-20"><a href="cross-validation.html#cb13-20" aria-hidden="true" tabindex="-1"></a>  alpha <span class="ot">&lt;-</span> <span class="dv">1</span> <span class="sc">/</span> <span class="fu">gamma.dispersion</span>(fit.gamma)</span>
<span id="cb13-21"><a href="cross-validation.html#cb13-21" aria-hidden="true" tabindex="-1"></a>  ksResultGamma <span class="ot">&lt;-</span> <span class="fu">ks.test</span>(testdata<span class="sc">$</span>Claim, <span class="st">&quot;pgamma&quot;</span>, <span class="at">shape =</span> alpha, <span class="at">scale =</span> gamma_theta)</span>
<span id="cb13-22"><a href="cross-validation.html#cb13-22" aria-hidden="true" tabindex="-1"></a>  cvalvec[<span class="dv">2</span>,i] <span class="ot">&lt;-</span> ksResultGamma<span class="sc">$</span>statistic</span>
<span id="cb13-23"><a href="cross-validation.html#cb13-23" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb13-24"><a href="cross-validation.html#cb13-24" aria-hidden="true" tabindex="-1"></a>KSBoot <span class="ot">&lt;-</span> <span class="fu">rowSums</span>(cvalvec)<span class="sc">/</span>B</span></code></pre></div>
<p>Kami melakukan pengambilan sampel dengan menggunakan B= 100 ulangan. Statistik KS rata-rata untuk distribusi Pareto adalah 0,058 dibandingkan dengan rata-rata untuk distribusi gamma, 0,262. Hal ini konsisten dengan hasil sebelumnya dan memberikan bukti lain bahwa Pareto adalah model yang lebih baik untuk data ini dibandingkan dengan gamma.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="simulation-and-resampling.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="importance-sampling.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": true,
"twitter": true,
"linkedin": true,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/dsciencelabs/Analisa_Resiko/edit/master/chapters/06-SimulationNoKableExtra.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["Analisa_Resiko.pdf", "Analisa_Resiko.epub"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
